{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimConfig.__init__() got an unexpected keyword argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m\n\u001b[0;32m     91\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Run all scenarios\u001b[39;00m\n\u001b[0;32m     94\u001b[0m scenarios \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 95\u001b[0m     \u001b[43mSimConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidator_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_separation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m             \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGood Generator, Bad Validator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     97\u001b[0m     SimConfig(generator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, class_separation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     98\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad Generator, Good Validator\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     99\u001b[0m     SimConfig(generator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, validator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, class_separation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    100\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGood Generator, Good Validator\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    101\u001b[0m     SimConfig(generator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validator_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, class_separation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m    102\u001b[0m              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad Generator, Bad Validator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m ]\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m scenarios:\n\u001b[0;32m    106\u001b[0m     analyze_scenario(config, config\u001b[38;5;241m.\u001b[39mname)\n",
      "\u001b[1;31mTypeError\u001b[0m: SimConfig.__init__() got an unexpected keyword argument 'name'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SimConfig:\n",
    "    generator_std: float  # How variable the generator is\n",
    "    validator_std: float  # How variable the validator is\n",
    "    class_separation: float  # How far apart the true means are\n",
    "    n_samples: int = 10  # Number of generator samples\n",
    "    n_validations: int = 30  # Number of validator runs per sample\n",
    "\n",
    "def generate_samples(config: SimConfig, class_mean: float):\n",
    "    \"\"\"Generate samples for one class\"\"\"\n",
    "    # Generate the true values from generator\n",
    "    true_values = np.random.normal(\n",
    "        class_mean, \n",
    "        config.generator_std, \n",
    "        config.n_samples\n",
    "    )\n",
    "    \n",
    "    # For each true value, run validator multiple times\n",
    "    all_validations = []\n",
    "    for true_value in true_values:\n",
    "        validations = np.random.normal(\n",
    "            true_value, \n",
    "            config.validator_std, \n",
    "            config.n_validations\n",
    "        )\n",
    "        all_validations.append(validations)\n",
    "    \n",
    "    return np.array(all_validations)\n",
    "\n",
    "def analyze_scenario(config: SimConfig, name: str):\n",
    "    \"\"\"Run and analyze one complete scenario\"\"\"\n",
    "    # Generate samples for two classes\n",
    "    j1_samples = generate_samples(config, 100)  # base mean of 100\n",
    "    j2_samples = generate_samples(config, 100 - config.class_separation)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    j1_means = j1_samples.mean(axis=1)\n",
    "    j2_means = j2_samples.mean(axis=1)\n",
    "    \n",
    "    j1_validator_stds = j1_samples.std(axis=1)\n",
    "    j2_validator_stds = j2_samples.std(axis=1)\n",
    "    \n",
    "    # Flatten for pooled analysis\n",
    "    j1_flat = j1_samples.flatten()\n",
    "    j2_flat = j2_samples.flatten()\n",
    "    \n",
    "    # Calculate Mann-Whitney U test\n",
    "    stat, p_value = stats.mannwhitneyu(j1_flat, j2_flat, alternative='greater')\n",
    "    \n",
    "    # Calculate Cliff's Delta\n",
    "    n1, n2 = len(j1_flat), len(j2_flat)\n",
    "    wins = sum(i > j for i in j1_flat for j in j2_flat)\n",
    "    losses = sum(i < j for i in j1_flat for j in j2_flat)\n",
    "    cliffs_delta = (wins - losses) / (n1 * n2)\n",
    "    \n",
    "    print(f\"\\nScenario: {name}\")\n",
    "    print(f\"Generator means - J1: {j1_means.mean():.2f} ± {j1_means.std():.2f}\")\n",
    "    print(f\"Generator means - J2: {j2_means.mean():.2f} ± {j2_means.std():.2f}\")\n",
    "    print(f\"Validator std - J1: {j1_validator_stds.mean():.2f}\")\n",
    "    print(f\"Validator std - J2: {j2_validator_stds.mean():.2f}\")\n",
    "    print(f\"Mann-Whitney p-value: {p_value:.4f}\")\n",
    "    print(f\"Cliff's Delta: {cliffs_delta:.4f}\")\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot generator means\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(np.ones_like(j1_means), j1_means, alpha=0.5, label='J1')\n",
    "    plt.scatter(np.ones_like(j2_means) * 2, j2_means, alpha=0.5, label='J2')\n",
    "    plt.title('Generator Means')\n",
    "    plt.xticks([1, 2], ['J1', 'J2'])\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot all validations\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.violinplot([j1_flat, j2_flat])\n",
    "    plt.title('All Validations')\n",
    "    plt.xticks([1, 2], ['J1', 'J2'])\n",
    "    plt.ylabel('Score')\n",
    "    \n",
    "    plt.suptitle(name)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run all scenarios\n",
    "scenarios = [\n",
    "    SimConfig(generator_std=1, validator_std=5, class_separation=10,\n",
    "             name=\"Good Generator, Bad Validator\"),\n",
    "    SimConfig(generator_std=5, validator_std=1, class_separation=10,\n",
    "             name=\"Bad Generator, Good Validator\"),\n",
    "    SimConfig(generator_std=1, validator_std=1, class_separation=10,\n",
    "             name=\"Good Generator, Good Validator\"),\n",
    "    SimConfig(generator_std=5, validator_std=5, class_separation=10,\n",
    "             name=\"Bad Generator, Bad Validator\")\n",
    "]\n",
    "\n",
    "for config in scenarios:\n",
    "    analyze_scenario(config, config.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of ell.stores.sql failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\jpeng\\Documents\\projects\\useful\\ell-forked\\src\\ell\\stores\\sql.py\", line 20, in <module>\n",
      "    class SQLStore(ell.store.Store):\n",
      "AttributeError: module 'ell' has no attribute 'store'. Did you mean: 'Store'?\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from ell.api import get_invocations_by_lmp_name, get_invocations_contents\n",
    "import ell\n",
    "\n",
    "ell.init(store=\"../../../ell_storage/chunk_alt\")\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_invocation_content(invocation):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SQLiteStore' object has no attribute 'get_invocations_contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mget_invocations_contents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerate_clusters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\projects\\useful\\ell-forked\\src\\ell\\api.py:124\u001b[0m, in \u001b[0;36mget_invocations_contents\u001b[1;34m(fqn)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03mRetrieve invocation contents for a given LMP ID and fully qualified name.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m:return: A list of Invocation objects containing the invocation contents.\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Session(config\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mengine) \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_invocations_contents\u001b[49m(session, fqn)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SQLiteStore' object has no attribute 'get_invocations_contents'"
     ]
    }
   ],
   "source": [
    "contents = get_invocations_contents(\"generate_clusters\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
