{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\starlette\\config.py:66: UserWarning: Config file '.env' not found.\n",
      "  warnings.warn(f\"Config file '{env_file}' not found.\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "from src.cluster.cluster import (\n",
    "    generate_full_code_clusters, \n",
    "    generate_full_code_clustersv2,\n",
    "    generate_summarized_clusters,\n",
    "    generate_graph_clusters,\n",
    "    generate_random_clusters\n",
    ")\n",
    "\n",
    "\n",
    "from src.cluster.types import (\n",
    "    CodeChunk,\n",
    "    SummaryChunk,\n",
    "    ClusterInput,\n",
    "    ClusteredTopic,\n",
    "    ClusterInputType,\n",
    "    LMClusteredTopicList\n",
    ")\n",
    "\n",
    "from src.cluster.chunk_repo import ChunkStrat\n",
    "\n",
    "# repo_name = \"ell\"\n",
    "repo_name = \"ell\"\n",
    "repo_path = Path(\"../../src/cluster/repos\") / repo_name\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# AutoSearching for n, k:\n",
    "# Goal: want to automatically find the values of n and k given that\n",
    "# the cohere_score evaluation function is probably gonna be changed in the\n",
    "# future\n",
    "#\n",
    "# Add a function that automatically recalculates n and k in:\n",
    "# n * cohere_score\n",
    "# num_files ** k / num_clusters (for cross_file)\n",
    "# This should be a simple search for increasing values of k over a range \n",
    "# R (of length ... 7?) such that the following condition holds:\n",
    "# For the first half (1, R/2]\n",
    "# The ranking of the score is: (Fullcode, Cgraph, ..., Random)\n",
    "# For the second half (R/2 + 1, R)\n",
    "# The ranking of the score is: (Cgraph, Fullcode, ..., Random)\n",
    "# \n",
    "# Then once the lowest value of n is found\n",
    "# R is found that satisfies above, take k to be R / 2 and call it a day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating full code clusters...\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[1]:  109\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[2]:  51\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[3]:  4\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[Summarize Chunk] Chunk too long: 8743, continuing...\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "Summary tokens: 8509,           Code tokens: 60918,           Ratio: 0.13967956925703404\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[1]:  131\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[2]:  73\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[3]:  8\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[4]:  0\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "Generating full code clusters...\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['Configuration Management Cluster', 'Provider Interface Cluster', 'Simple LMP Decorator Cluster', 'Persistent Storage Cluster', 'Model Usage Logging Cluster', 'OpenAI Model Registration Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Core Configuration and Registry Cluster', 'Provider Interface and API Integration Cluster', 'Language Model Program Decorators and Execution Cluster', 'Execution Tracing and Tracking Cluster', 'SQL Store for Data Persistency Cluster', 'Studio Server and API Cluster']\n",
      "Chunk Name: ell\\lmp._track.py::1 hallucinated, skipping...\n",
      "Chunk Name: utils\\verbosity.py::6 hallucinated, skipping...\n",
      "Chunk Name: utils\\verbosity.py::1 hallucinated, skipping...\n",
      "Chunk Name: utils\\verbosity.py::3 hallucinated, skipping...\n",
      "Chunk Name: utils\\verbosity.py::5 hallucinated, skipping...\n",
      "Unclassified chunks, iter:1: 174 / 212\n",
      "Unique chunks: 38\n",
      "Total clustered chunks: 49\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['Initialization and Core Setup Cluster', 'Configuration Management Cluster', 'Caching and Store Operations Cluster', 'Tool Definition and Usage Cluster', 'Messaging and Content Management Cluster', 'Serialization and Data Preparation Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Build and Deployment Cluster', 'Reinforcement Learning Cluster', 'Message and Content Handling Cluster', 'Code Serialization and Closure Cluster', 'Text and Data Transformation Cluster', 'Provider Integration Cluster']\n",
      "Chunk Name: build.py::2 hallucinated, skipping...\n",
      "Unclassified chunks, iter:2: 125 / 212\n",
      "Unique chunks: 49\n",
      "Total clustered chunks: 54\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['Build and Automation Cluster', 'OpenAI Realtime Integration Cluster', 'Invocation Management and Serialization Cluster', 'Logging and Verbosity Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Build and Environment Setup Cluster', 'Reinforcement Learning and Elite Selection Cluster', 'Real-time Client and Event Management Cluster', 'Lexical Closure and Dependency Management Cluster', 'String Operations with Metadata Cluster', 'Asynchronous Database and Web Server Cluster']\n",
      "Chunk Name: build.py::2 hallucinated, skipping...\n",
      "Chunk Name: build.py::2 hallucinated, skipping...\n",
      "Chunk Name: lmp_track.py::1 hallucinated, skipping...\n",
      "Chunk Name: utils\\closure_util.py::1 hallucinated, skipping...\n",
      "Unclassified chunks, iter:3: 88 / 212\n",
      "Unique chunks: 38\n",
      "Total clustered chunks: 42\n",
      "Total Cost: 0.3768038\n",
      "Cached Savings: 66.66599434506763 %\n",
      "Execution Time: 176.08107400000003 s\n",
      "Generating full code clusters...\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False[ELL] use_cache for summarize_chunk: False\n",
      "\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "Summary tokens: 8386,             Code tokens: 60918,             Ratio: 0.13766046160412357\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['Configuration Management Cluster', 'Reinforcement Learning Training Loop Cluster', 'Execution Enhancement Cluster', 'Lexical Closure Management Cluster', 'Language Model API Management Cluster', 'Real-Time API Interaction Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Tool Interaction Cluster', 'Content Management Cluster', 'Message Handling Cluster', 'LMP Management Cluster', 'Invocation Tracking Cluster', 'Content Conversion Cluster']\n",
      "Unclassified chunks, iter:1: 166 / 211\n",
      "Unique chunks: 45\n",
      "Total clustered chunks: 48\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['OpenAI API Streaming and Configuration Cluster', 'Reinforcement Learning Trajectory Management Cluster', 'ELL Configuration and Initialization Cluster', 'Function Invocation and Caching Cluster', 'Real-time Messaging and Audio Processing Cluster', 'Logging and Output Management Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Message Parsing and Data Management Cluster', 'SQLModel Data Relationship and Dependency Management Cluster', 'Invocation Content Management Cluster', 'Model Configuration and Management Cluster', 'Source Code Processing and Organization Cluster', 'Version Control and Collaboration Enhancement Cluster']\n",
      "Chunk Name: build.py::2 hallucinated, skipping...\n",
      "Chunk Name: store\\sql.py::5 hallucinated, skipping...\n",
      "Unclassified chunks, iter:2: 127 / 211\n",
      "Unique chunks: 39\n",
      "Total clustered chunks: 42\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{code\\}: ['Real-time Interaction Cluster', 'AI Model Provider Management Cluster', 'Invocation Tracking and Management Cluster', 'Reinforcement Learning Cluster', 'Custom String Class and Context Management Cluster', 'FastAPI and Database Interaction Cluster']\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "[ELL] use_cache for generate_clusters_raw: False\n",
      "[ELL] use_cache for identify_key_chunks: False\n",
      "Generated clusters for type \\{data_structure\\}: ['Custom String Management Cluster', 'Data Models and Management Cluster', 'Database Interaction and Timestamp Management Cluster', 'API Call Parameters and Management Cluster', 'Structured Data Models and Message Handling Cluster', 'Complex Data Serialization Cluster']\n",
      "Chunk Name: types\\lstr.py::3 hallucinated, skipping...\n",
      "Chunk Name: types\\lstr.py::1 hallucinated, skipping...\n",
      "Chunk Name: types\\lstr.py::5 hallucinated, skipping...\n",
      "Chunk Name: types\\lstr.py::9 hallucinated, skipping...\n",
      "Chunk Name: types\\lstr.py::17 hallucinated, skipping...\n",
      "Unclassified chunks, iter:3: 80 / 211\n",
      "Unique chunks: 47\n",
      "Total clustered chunks: 55\n",
      "Total Cost: 0.10330154999999999\n",
      "Cached Savings: 46.62079126595875 %\n",
      "Execution Time: 306.142116 s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from src.config import GRAPH_ROOT, REPOS_ROOT\n",
    "from rtfs.chunk_resolution.chunk_graph import ChunkGraph\n",
    "from rtfs.transforms.cluster import cluster\n",
    "\n",
    "def generate_cgraph_clusters() -> List[ClusteredTopic]:\n",
    "    ell_json = json.loads(open(GRAPH_ROOT / \"MadcowD_ell_standard.json\", \"r\").read())\n",
    "    cg = ChunkGraph.from_json(REPOS_ROOT / \"MadcowD_ell\", ell_json)\n",
    "\n",
    "    cluster(cg)\n",
    "\n",
    "    return [\n",
    "        ClusteredTopic(\n",
    "            name=\"Graph Cluster\",\n",
    "            chunks=[\n",
    "                CodeChunk(\n",
    "                    id=chunk.og_id,\n",
    "                    content=chunk.content,\n",
    "                    filepath=chunk.file_path,\n",
    "                    input_type=ClusterInputType.CHUNK,\n",
    "                ).dict() for chunk in cluster.chunks\n",
    "            ],\n",
    "        ) \n",
    "        for cluster in cg.get_clusters()\n",
    "    ]\n",
    "\n",
    "# Generate clusters\n",
    "full_code_clusters = generate_full_code_clusters(repo_path)\n",
    "summary_clusters = generate_summarized_clusters(repo_path)\n",
    "graph_clusters = generate_graph_clusters(repo_path)\n",
    "full_code_clustersv2 = generate_full_code_clustersv2(repo_path)\n",
    "summary_clustersv2 = generate_full_code_clustersv2(repo_path, summarize=True)\n",
    "\n",
    "# cgraph_clusters = generate_cgraph_clusters()\n",
    "# random_clusters = generate_random_clusters(repo_path, num_clusters = 10)\n",
    "# rsummarized_clusters = generate_summarized_clusters(repo_path, chunk_strat=ChunkStrat.RANDOM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full code clusters: 43\n",
      "Summary clusters: 21\n",
      "Graph clusters: 10\n",
      "Full code clusters v2: 35\n",
      "Summary clusters v2: 33\n"
     ]
    }
   ],
   "source": [
    "print(f\"Full code clusters: {len(full_code_clusters)}\")\n",
    "print(f\"Summary clusters: {len(summary_clusters)}\")\n",
    "print(f\"Graph clusters: {len(graph_clusters)}\")\n",
    "print(f\"Full code clusters v2: {len(full_code_clustersv2)}\")\n",
    "print(f\"Summary clusters v2: {len(summary_clustersv2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### EVALS ###################\n",
    "from src.llm.evals.eval_cluster import eval_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.llm.evals.eval_cluster failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\jpeng\\Documents\\projects\\codesearch-backend\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 309, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: eval_coherence_single() requires a code object with 0 free vars, not 4\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [13.0, 15.0, 14.0, 4.0, 9.0, 15.0, 14.0, 11.0, 15.0, 11.0, 16.0, 11.0, 13.0, 15.0, 11.0, 11.0, 11.0, 14.0, 14.0, 14.0, 13.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [14.0, 15.0, 5.0, 8.0, 12.0, 15.0, 15.0, 9.0, 14.0, 11.0, 15.0, 14.0, 13.0, 13.0, 11.0, 15.0, 14.0, 12.0, 14.0, 14.0, 14.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [15.0, 15.0, 9.0, 12.0, 14.0, 12.0, 15.0, 11.0, 15.0, 12.0, 11.0, 11.0, 8.0, 11.0, 14.0, 15.0, 14.0, 13.0, 13.0, 15.0, 13.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [14.0, 14.0, 15.0, 14.0, 14.0, 7.0, 14.0, 14.0, 15.0, 14.0, 12.0, 4.0, 11.0, 15.0, 14.0, 13.0, 15.0, 15.0, 14.0, 15.0, 14.0, 13.0, 11.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [14.0, 14.0, 16.0, 13.0, 14.0, 14.0, 5.0, 11.0, 14.0, 14.0, 6.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 13.0, 12.0, 11.0, 13.0, 13.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [13.0, 15.0, 15.0, 14.0, 13.0, 15.0, 13.0, 13.0, 13.0, 4.0, 14.0, 7.0, 12.0, 11.0, 14.0, 12.0, 15.0, 15.0, 15.0, 14.0, 16.0, 12.0, 9.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "CLuster scores:  [14.0, 10.0, 13.0, 13.0, 11.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CLuster scores:  [13.0, 15.0, 14.0, 14.0, 11.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "CLuster scores:  [14.0, 12.0, 15.0, 14.0, 9.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [12.0, 13.0, 15.0, 12.0, 14.0, 14.0, 14.0, 14.0, 12.0, 14.0, 13.0, 14.0, 11.0, 4.0, 14.0, 14.0, 14.0, 12.0, 15.0, 11.0, 13.0, 15.0, 15.0, 14.0, 12.0, 12.0, 12.0, 15.0, 14.0, 13.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [13.0, 13.0, 15.0, 10.0, 14.0, 14.0, 13.0, 12.0, 15.0, 14.0, 15.0, 13.0, 12.0, 13.0, 11.0, 12.0, 15.0, 12.0, 5.0, 15.0, 14.0, 15.0, 12.0, 14.0, 15.0, 11.0, 13.0, 14.0, 14.0, 12.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [14.0, 14.0, 13.0, 15.0, 13.0, 12.0, 14.0, 11.0, 13.0, 14.0, 14.0, 14.0, 12.0, 13.0, 13.0, 14.0, 14.0, 14.0, 6.0, 14.0, 15.0, 14.0, 13.0, 15.0, 12.0, 13.0, 15.0, 12.0, 15.0, 14.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [11.0, 14.0, 15.0, 12.0, 10.0, 13.0, 12.0, 11.0, 12.0, 12.0, 14.0, 8.0, 10.0, 11.0, 13.0, 15.0, 15.0, 12.0, 14.0, 11.0, 12.0, 12.0, 12.0, 12.0, 11.0, 14.0, 14.0, 6.0, 10.0]\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [9.0, 14.0, 14.0, 8.0, 12.0, 14.0, 13.0, 13.0, 9.0, 12.0, 7.0, 12.0, 12.0, 9.0, 12.0, 13.0, 11.0, 12.0, 12.0, 14.0, 14.0, 14.0, 12.0, 14.0, 9.0, 7.0, 6.0, 14.0, 12.0]\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "CLuster scores:  [12.0, 13.0, 12.0, 14.0, 9.0, 11.0, 8.0, 15.0, 12.0, 14.0, 8.0, 11.0, 12.0, 12.0, 15.0, 14.0, 8.0, 14.0, 11.0, 11.0, 13.0, 14.0, 13.0, 14.0, 13.0, 14.0, 7.0, 12.0, 11.0]\n"
     ]
    }
   ],
   "source": [
    "from src.llm.evals.eval_cluster import eval_coherence_clusters\n",
    "\n",
    "iters = 3\n",
    "full_code_coherence, full_code_var = eval_coherence_clusters(full_code_clusters, iters, \"full_code\", subdir=\"full_code\")\n",
    "summary_coherence, sum_var = eval_coherence_clusters(summary_clusters, iters, \"summary\", subdir=\"summary\")\n",
    "graph_coherence, graph_var = eval_coherence_clusters(graph_clusters, iters, \"graph\", subdir=\"graph\")\n",
    "full_code_coherence_v2, full_code_var2 = eval_coherence_clusters(full_code_clustersv2, iters, \"full_code_v2\", subdir=\"full_code_v2\")\n",
    "summary_coherence_v2, sum_var2 = eval_coherence_clusters(summary_clustersv2, iters, \"summary_v2\", subdir=\"summary_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "Generating full code clusters...\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[1]:  180\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[2]:  65\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[3]:  4\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[Summarize Chunk] Chunk too long: 8743, continuing...\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "[ELL] use_cache for summarize_chunk: False\n",
      "Summary tokens: 8386,           Code tokens: 60918,           Ratio: 0.13766046160412357\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[1]:  148\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[2]:  105\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[3]:  29\n",
      "[ELL] use_cache for generate_clusters: False\n",
      "Unclassified chunks, iter:[4]:  0\n",
      "Saving chunks to file:  C:\\Users\\jpeng\\AppData\\Local\\Temp\\index\\ell\n",
      "[Chunker]: 212 chunks used\n"
     ]
    }
   ],
   "source": [
    "cgraph_clusters = generate_cgraph_clusters()\n",
    "random_clusters = generate_random_clusters(repo_path, num_clusters = 10)\n",
    "full_code_clusters = generate_full_code_clusters(repo_path)\n",
    "summary_clusters = generate_summarized_clusters(repo_path)\n",
    "graph_clusters = generate_graph_clusters(repo_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring range differences\n",
    "full_code_coherence, full_code_var = eval_coherence_clusters(full_code_clusters, iters, \"full_code\", subdir=\"full_code\")\n",
    "summary_coherence, sum_var = eval_coherence_clusters(summary_clusters, iters, \"summary\", subdir=\"summary\")\n",
    "graph_coherence, graph_var = eval_coherence_clusters(graph_clusters, iters, \"graph\", subdir=\"graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n",
      "[ELL] use_cache for eval_coherence_single: False\n"
     ]
    }
   ],
   "source": [
    "full_code_coherence, full_code_std = eval_coherence_clusters(full_code_clusters, iters, \"full_code\", subdir=\"full_code\")\n",
    "summary_coherence, sum_std = eval_coherence_clusters(summary_clusters, iters, \"summary\", subdir=\"summary\")\n",
    "cgraph_coherence, cgraph_std = eval_coherence_clusters(cgraph_clusters, 1, \"cgraph\", subdir=\"cgraph\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full code coherence:  12.794871794871796 Variance:  0.1188925448140479\n",
      "Summary coherence:  13.277777777777777 Variance:  0.15947444549341497\n",
      "Graph coherence:  12.363636363636363 Variance:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Full code coherence: \", full_code_coherence, \"Variance: \", full_code_std)\n",
    "print(\"Summary coherence: \", summary_coherence, \"Variance: \", sum_std)\n",
    "print(\"Graph coherence: \", cgraph_coherence, \"Variance: \", cgraph_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_coherence, variance = eval_coherence_clusters(graph_clusters, iters, \"graph\", subdir=\"graph\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph coherence:  4.3999999999999995 Variance:  0.0799999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"Graph coherence: \", graph_coherence, \"Variance: \", variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full code coherence:  12.682539682539684 Variance:  0.08093681767607624\n",
      "Graph coherence:  12.800000000000002 Variance:  0.18217108826052958\n",
      "Summary coherence:  12.840579710144928 Variance:  0.48989794855663604\n",
      "Full code coherence v2:  13.111111111111109 Variance:  0.13425606637327336\n",
      "Summary coherence v2:  11.82758620689655 Variance:  0.2198980053989536\n"
     ]
    }
   ],
   "source": [
    "print(\"Full code coherence: \", full_code_coherence, \"Variance: \", full_code_var)\n",
    "print(\"Graph coherence: \", graph_coherence, \"Variance: \", sum_var)\n",
    "print(\"Summary coherence: \", summary_coherence, \"Variance: \", graph_var)\n",
    "print(\"Full code coherence v2: \", full_code_coherence_v2, \"Variance: \", full_code_var2)\n",
    "print(\"Summary coherence v2: \", summary_coherence_v2, \"Variance: \", sum_var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_cross_file_single(cluster: ClusteredTopic, f_const: float = 2.0) -> float:\n",
    "    # Calculate the number of unique files in the cluster\n",
    "    unique_files = set(chunk.filepath for chunk in cluster.chunks \n",
    "                       if chunk.filepath is not None)\n",
    "    num_files = len(unique_files)\n",
    "    num_chunks = len(cluster.chunks)\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if num_chunks == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate the ratio of files to chunks\n",
    "    score = num_files ** f_const / num_chunks\n",
    "\n",
    "    return num_files, num_chunks, score\n",
    "    \n",
    "\n",
    "def eval_cross_file_cluster(clusters: List[ClusteredTopic], f_const: float = 2.0, min_chunks: int = 3) -> float:\n",
    "    cross_file_scores = [eval_cross_file_single(cluster, f_const = f_const)[2] for cluster in clusters \n",
    "                         if len(cluster.chunks) >= min_chunks]\n",
    "\n",
    "    # Calculate the average cross-file score\n",
    "    if len(cross_file_scores) > 0:\n",
    "        avg_cross_file_score = sum(cross_file_scores) / len(cross_file_scores)\n",
    "    else:\n",
    "        avg_cross_file_score = 0.0\n",
    "\n",
    "    return avg_cross_file_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for f_const:  1.1\n",
      "1.Full Code v2: 21.548820429112983\n",
      "2.Summary: 21.00977809006482\n",
      "3.Graph: 21.001129182189327\n",
      "4.Full Code: 20.746782709948008\n",
      "5.Summary v2: 19.71247438816813\n",
      "Results for f_const:  1.2\n",
      "1.Full Code v2: 21.604519240704107\n",
      "2.Graph: 21.062710162788452\n",
      "3.Summary: 21.054679832333846\n",
      "4.Full Code: 20.79364647167846\n",
      "5.Summary v2: 19.808426960228143\n",
      "Results for f_const:  1.3\n",
      "1.Full Code v2: 21.666825806588232\n",
      "2.Graph: 21.132867229768564\n",
      "3.Summary: 21.105471721714512\n",
      "4.Full Code: 20.847562275133033\n",
      "5.Summary v2: 19.91743357965807\n",
      "Results for f_const:  1.4\n",
      "1.Full Code v2: 21.736578215466086\n",
      "2.Graph: 21.212980013709863\n",
      "3.Summary: 21.162991662826375\n",
      "4.Full Code: 20.909741937475875\n",
      "5.Summary v2: 20.0413641793772\n"
     ]
    }
   ],
   "source": [
    "f_const_vals = [1.1, 1.2, 1.3, 1.4]\n",
    "cohere_scores = [full_code_coherence, graph_coherence, summary_coherence, full_code_coherence_v2, summary_coherence_v2]\n",
    "clusters = [full_code_clusters, graph_clusters, summary_clusters, full_code_clustersv2, summary_clustersv2]\n",
    "labels = [\"Full Code\", \"Graph\", \"Summary\", \"Full Code v2\", \"Summary v2\"]\n",
    "\n",
    "for f_const in f_const_vals:\n",
    "    cross_file_scores = [\n",
    "        eval_cross_file_cluster(cluster, f_const=f_const) for cluster in clusters\n",
    "    ] \n",
    "    final_eval = [( 1.6 * cohere_score + cross_score, label) for cohere_score, cross_score, label\n",
    "                   in zip(cohere_scores, cross_file_scores, labels)]\n",
    "    final_eval = sorted(final_eval, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    print(\"Results for f_const: \", f_const)\n",
    "\n",
    "    for i, (score, label) in enumerate(final_eval, 1):\n",
    "        print(f\"{i}.{label}: {score}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for f_const:  1.1\n",
      "1.Cgraph:  3.66908428888863\n",
      "2.Random:  3.1063030944654573\n",
      "3.Graph:  2.1887425651951635\n",
      "4.Summary:  1.153433756963121\n",
      "5.Full Code:  1.0975553433087866\n",
      "Results for f_const:  1.2\n",
      "1.Cgraph:  4.277417041378886\n",
      "2.Random:  3.5351195526567887\n",
      "3.Graph:  2.4473826837114787\n",
      "4.Summary:  1.204088543733182\n",
      "5.Full Code:  1.203226037791274\n",
      "Results for f_const:  1.3\n",
      "1.Cgraph:  4.990188003405217\n",
      "2.Random:  4.023858296036403\n",
      "3.Graph:  2.742042365027961\n",
      "4.Full Code:  1.3273836158934431\n",
      "5.Summary:  1.2612605737913545\n",
      "Results for f_const:  1.4\n",
      "1.Cgraph:  5.8259049576920106\n",
      "2.Random:  4.580983522660869\n",
      "3.Graph:  3.0785160575814134\n",
      "4.Full Code:  1.4732854973306773\n",
      "5.Summary:  1.325887593155681\n"
     ]
    }
   ],
   "source": [
    "f_const_vals = [1.1, 1.2, 1.3, 1.4]\n",
    "cohere_scores = [full_code_coherence, graph_coherence, cgraph_coherence, random_coherence, summary_coherence]\n",
    "clusters = [full_code_clusters, graph_clusters, cgraph_clusters, random_clusters, summary_clusters]\n",
    "labels = [\"Full Code\", \"Graph\", \"Cgraph\", \"Random\", \"Summary\"]\n",
    "\n",
    "for f_const in f_const_vals:\n",
    "    cross_file_scores = [\n",
    "        eval_cross_file_cluster(cluster, f_const=f_const) for cluster in clusters\n",
    "    ]\n",
    "    final_eval = [(cohere_sore * cross_score, label) for cohere_sore, cross_score, label\n",
    "                   in zip(cohere_scores, cross_file_scores, labels)]\n",
    "    final_eval = sorted(final_eval, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    print(\"Results for f_const: \", f_const)\n",
    "\n",
    "    print(f\"1.{final_eval[0][1]}: \", final_eval[0][0])\n",
    "    print(f\"2.{final_eval[1][1]}: \", final_eval[1][0])\n",
    "    print(f\"3.{final_eval[2][1]}: \", final_eval[2][0])\n",
    "    print(f\"4.{final_eval[3][1]}: \", final_eval[3][0])\n",
    "    print(f\"5.{final_eval[4][1]}: \", final_eval[4][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-Time API and Client Management | Conversation APIs and Real-time Communication | 7\n",
      "Web Application and Server Setup | Interactive CLI with Visual Representation | 6\n",
      "Factorial Calculation | Interactive CLI with Visual Representation | 5\n",
      "Store and Database Management | SQL Store and Query Operations | 5\n",
      "Store Management and Configuration | Configuration and Initialization | 4\n",
      "User Input Validation and Formatting | OpenAI and LLM Capabilities | 3\n",
      "Reinforcement Learning Environment Setup and Evaluation | RL Training Using Gym | 3\n",
      "Data Collection and Processing in Reinforcement Learning | CBPO Reinforcement Learning Algorithm | 3\n",
      "Model Registration and Handling | Ell Language Modeling | 3\n",
      "Language Model and Prompt Handling | Language Model Decorator Utilities | 3\n",
      "Main Application and Serving | Studio Command-Line Interface | 3\n",
      "String and Data Manipulation | Basic Classes and Methods | 3\n",
      "Real-time Audio Handling | Real-time Client and Event Handling | 3\n",
      "Content and Message Processing | Model of Language Models | 3\n",
      "Logging and Debugging | Environment Settings and Commands | 3\n",
      "Real-Time Client and Communication | Conversation APIs and Real-time Communication | 3\n",
      "Policy Networks in Reinforcement Learning | CBPO Reinforcement Learning Algorithm | 2\n",
      "String and Factorial Operations | Basic Classes and Methods | 2\n",
      "Data Processing and Serialization | Persistent Storage and Serialization | 2\n",
      "Client and Provider Management | Basic APIs and Util Functions | 2\n",
      "Function Tracking and Invocation Logging | Invocation and Tracking | 2\n",
      "API Interactions and Middleware | Anthropic Interaction Implementation | 2\n",
      "Real-time Communication and Event Handling | Real-time API Client | 2\n",
      "Event Callback Management | Real-time Event Dispatch and Utilities | 2\n",
      "Data Serialization and Transformation | Persistent Storage and Serialization | 2\n",
      "Model and Invocation Management | Basic Classes and Methods | 2\n",
      "Custom Data Structures and String Operations | Processing and Mapping Functions | 2\n",
      "Configuration and Dependency Management | Lexical Closure and Dependency Management | 2\n",
      "Image and Graphics Processing | Plotting ASCII Art | 2\n",
      "NPM Operations and Testing | Build Process and Commands | 1\n",
      "OpenAI API Interaction | Real-time API Client | 1\n",
      "Abstract Syntax Tree (AST) Manipulation | Context Versioning Using AST | 1\n",
      "Code Cloning and Updation | Configuration and Initialization | 1\n",
      "Testing and Validation | Basic APIs and Util Functions | 1\n",
      "Network Connections and Logging | Markov Decision Process | 1\n",
      "Configuration Management | Interactive CLI with Visual Representation | 1\n",
      "Content Transformation and Serialization | Anthropic Interaction Implementation | 1\n",
      "Tool and Invocation Management | Basic Classes and Methods | 1\n"
     ]
    }
   ],
   "source": [
    "# full_code_ids contain the superset of all code chunks\n",
    "id_map = {chunk_id: i for i, chunk_id in enumerate(full_code_ids)}\n",
    "\n",
    "# match clusters to find ones with the most shared chunks\n",
    "def compare_clusters(cluster_a: List[ClusteredTopic], \n",
    "                 cluster_b: List[ClusteredTopic]) -> List[Tuple[ClusteredTopic, ClusteredTopic, int]]:\n",
    "    \"\"\"\n",
    "    Loops through all clusters to find the best match for each cluster in the other set.\n",
    "    \"\"\"\n",
    "    seen = []\n",
    "    matched_clusters = []\n",
    "    for i, a in enumerate(cluster_a):\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "        for b in cluster_b:\n",
    "            # if b.name in seen:\n",
    "            #     continue\n",
    "            \n",
    "            a_chunk_ids = [id_map[chunk.id] for chunk in a.chunks]\n",
    "            b_chunk_ids = [id_map[chunk.id] for chunk in b.chunks]\n",
    "            score = len(set(a_chunk_ids) & set(b_chunk_ids))\n",
    "\n",
    "            # if i == 12:\n",
    "            #     print(\"a chunks: \", [id_map[chunk.id] for chunk in a.chunks])\n",
    "            #     print(\"b chunks: \", [id_map[chunk.id] for chunk in b.chunks])\n",
    "            #     print(score)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = b\n",
    "        \n",
    "        if best_match: \n",
    "            matched_clusters.append((a, best_match, best_score))\n",
    "            seen.append(best_match.name)\n",
    "\n",
    "    return matched_clusters\n",
    "\n",
    "matched_clusters = compare_clusters(summary_clusters, full_code_clusters)\n",
    "for c1, c2, score in sorted(matched_clusters, key=lambda x: x[2], reverse=True):\n",
    "    print(f\"{c1.name} | {c2.name} | {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
