Chunk ID: moatless/__init__.py::2
Filepath: moatless\__init__.py
Content:
from moatless.repository import FileRepository
from moatless.workspace import Workspace
from moatless.transition_rules import TransitionRules
from moatless.loop import AgenticLoop
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::1
Filepath: moatless\benchmark\claude_evaluation.py
Content:
import json
import logging
from typing import Optional

import instructor

from moatless.transition_rules import TransitionRules
from moatless.benchmark.evaluation import create_evaluation_name, Evaluation
from moatless.edit.edit import EditCode
from moatless.edit.plan import PlanToCode
from moatless.find.decide import DecideRelevance
from moatless.find.identify import IdentifyCode
from moatless.find.search import SearchCode
from moatless.transition_rules import TransitionRule
from moatless.state import Finished, Rejected
from moatless.transitions import (
    search_and_code_transitions,
    search_transitions,
    code_transitions,
)

# model = "claude-3-5-sonnet-20240620"

# model = "gpt-4o-2024-05-13"
model = "azure/gpt-4o"

# model = "openrouter/anthropic/claude-3.5-sonnet"

global_params = {
    "model": model,
    "temperature": 0.2,
    "max_tokens": 2000,
    "max_prompt_file_tokens": 8000,
}

state_params = {
    SearchCode: {
        "provide_initial_context": True,
        "max_search_results": 75,
        "initial_context_tokens": 6000,
        "initial_search_results": 100,
        "initial_context_spans_per_file": 5,
    },
    IdentifyCode: {"expand_context": True},
    DecideRelevance: {
        "finish_after_relevant_count": 1,
    },
    PlanToCode: {
        "max_tokens_in_edit_prompt": 750,
        "expand_context_with_related_spans": False,
        "finish_on_review": True,
    },
    EditCode: {
        "chain_of_thought": False,
        "show_file_context": False,
        "max_prompt_file_tokens": 8000,
    },
}

index_store_dir = f"/home/albert/20240522-voyage-code-2"
repo_base_dir = "/tmp/repos"
evaluations_dir = "/home/albert/repos/albert/moatless/evaluations"

search_and_code = search_and_code_transitions(
    global_params=global_params, state_params=state_params
)
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::2
Filepath: moatless\benchmark\claude_evaluation.py
Content:
identified_spans_but_failed_implementation = [
    "django__django-11583",
    "django__django-11179",
    "django__django-12286",
    "django__django-12700",
    "django__django-12708",
    "django__django-13315",
    "django__django-13933",
    "django__django-14382",
    "django__django-14608",
    "django__django-14787",
    "django__django-14999",
    "django__django-15347",
    "django__django-15789",
    "django__django-16041",
    "django__django-16046",
    "django__django-16595",
    "matplotlib__matplotlib-26020",
    "matplotlib__matplotlib-24149",
    "mwaskom__seaborn-3190",
    "psf__requests-3362",
    "pytest-dev__pytest-5692",
    "scikit-learn__scikit-learn-11281",
    "django__django-2708",
    "scikit-learn__scikit-learn-13241",
    "scikit-learn__scikit-learn-13779",
    "scikit-learn__scikit-learn-14894",
    "scikit-learn__scikit-learn-15535",
    "scikit-learn__scikit-learn-25570",
    "sympy__sympy-18621",
    "sympy__sympy-23117",
    "sympy__sympy-22714",
    "sympy__sympy-24213",
]

coding_test_set = [
    "django__django-11848",
    "django__django-12308",
    "django__django-12497",
    "django__django-13551",
    "django__django-13660",
    "django__django-14238",
    "django__django-14411",
    "django__django-14787",
    "django__django-16041",
    "django__django-17051",
    "matplotlib__matplotlib-24149",
    "mwaskom__seaborn-3190",
    "psf__requests-1963",
    "pylint-dev__pylint-6506",
    "pylint-dev__pylint-7993",
    "pytest-dev__pytest-7432",
    "scikit-learn__scikit-learn-13142",
    "scikit-learn__scikit-learn-25570",
    "sphinx-doc__sphinx-7975",
    "sympy__sympy-12481",
    "sympy__sympy-14396",
    "sympy__sympy-14817",
    "sympy__sympy-15609",
    "sympy__sympy-16988",
    "sympy__sympy-18189",
    "sympy__sympy-18532",
    "sympy__sympy-21847",
    "sympy__sympy-22005",
    "sympy__sympy-22714",
    "sympy__sympy-24066",
]
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::3
Filepath: moatless\benchmark\claude_evaluation.py
Content:
search_and_identify_set = [
    "matplotlib__matplotlib-25442",
    "matplotlib__matplotlib-23562",
    "pytest-dev__pytest-11148",
    "sphinx-doc__sphinx-8721",
    "sphinx-doc__sphinx-10325",
    "scikit-learn__scikit-learn-15535",
    "scikit-learn__scikit-learn-11281",
    "astropy__astropy-6938",
    "sympy__sympy-17022",
    "sympy__sympy-17139",
    "sympy__sympy-13031",
    "django__django-15814",
    "django__django-15498",
    "django__django-12125",
    "django__django-13964",
    "django__django-11964",
    "django__django-14580",
    "django__django-17087",
]


def run_evaluation():
    max_file_context_lines = 1000

    transitions = search_and_code_transitions(
        state_params={
            PlanToCode: {
                "max_prompt_file_tokens": 16000,
                "max_tokens_in_edit_prompt": 500,
                "max_file_context_lines": max_file_context_lines,
            }
        },
    )
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::4
Filepath: moatless\benchmark\claude_evaluation.py
Content:
def evaluate_search():
    transitions = TransitionRules(
        global_params=global_params,
        state_params={
            SearchCode: {"max_search_results": 50, "provide_initial_context": True},
        },
        initial_state=SearchCode,
        transitions=[
            TransitionRule(source=SearchCode, dest=Finished, trigger="did_search"),
            TransitionRule(source=SearchCode, dest=Finished, trigger="finish"),
        ],
    )

    evaluation_name = create_evaluation_name(model, "search")

    evaluation = Evaluation(
        transitions=transitions,
        evaluations_dir=evaluations_dir + "/search",
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_base_dir,
        max_file_context_tokens=16000,
        litellm_callback="langfuse",
        detailed_report=True,
    )

    evaluation.run_evaluation_with_moatless_dataset(use_test_subset=True)
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::5
Filepath: moatless\benchmark\claude_evaluation.py
Content:
def evaluate_search_and_identify(
    resolved_by: Optional[int] = 4,
    previous_trajectory_dir: Optional[str] = None,
    instance_ids: Optional[list] = None,
):
    transitions = search_transitions(
        global_params=global_params,
        state_params=state_params,
    )

    evaluation_name = create_evaluation_name("search_and_identify_3", model)
    # evaluation_name = "20240624_search_and_identify_claude-3-5-sonnet-20240620"

    evaluation = Evaluation(
        transitions=transitions,
        evaluations_dir=evaluations_dir + "/search_and_identify",
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_base_dir,
        previous_trajectory_dir=previous_trajectory_dir,
        max_file_context_tokens=16000,
        litellm_callback="langfuse",
        detailed_report=True,
    )

    evaluation.run_evaluation_with_moatless_dataset(
        resolved_by=resolved_by, instance_ids=instance_ids
    )
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::6
Filepath: moatless\benchmark\claude_evaluation.py
Content:
def evaluate_search_and_code(
    resolved_by: Optional[int],
    previous_trajectory_dir: Optional[str] = None,
    retry_state: Optional[str] = None,
    instance_ids: Optional[list] = None,
):
    evaluation_name = create_evaluation_name("search_and_code", model)
    # evaluation_name = "20240624_search_and_code_2_claude-3-5-sonnet-20240620"
    # evaluation_name = "20240623_moatless_claude-3.5-sonnet"

    evaluation = Evaluation(
        transitions=search_and_code,
        evaluations_dir=evaluations_dir + "/search_and_code",
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_base_dir,
        previous_trajectory_dir=previous_trajectory_dir,
        retry_state=retry_state,
        max_file_context_tokens=16000,
        num_workers=3,
        litellm_callback="langfuse",
        detailed_report=True,
    )

    evaluation.run_evaluation_with_moatless_dataset(
        resolved_by=resolved_by,
        instance_ids=instance_ids,
    )
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::7
Filepath: moatless\benchmark\claude_evaluation.py
Content:
def evaluate_coding():
    evaluation_name = create_evaluation_name("coding", model)
    # evaluation_name = "20240623_coding_2_claude-3.5-sonnet"

    evaluation = Evaluation(
        transitions=code_transitions(
            global_params=global_params, state_params=state_params
        ),
        use_expected_file_context=True,
        evaluations_dir=evaluations_dir + "/coding",
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_base_dir,
        max_file_context_tokens=16000,
        litellm_callback="langfuse",
        detailed_report=True,
    )

    df = evaluation.run_evaluation_with_moatless_dataset(instance_ids=coding_test_set)
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::8
Filepath: moatless\benchmark\claude_evaluation.py
Content:
def evaluate_plan(previous_trajectory_dir: Optional[str] = None):
    transitions = TransitionRules(
        global_params=global_params,
        state_params={
            SearchCode: {
                "provide_initial_context": True,
                "max_search_results": 75,
                "initial_context_tokens": 6000,
                "initial_search_results": 100,
                "initial_context_spans_per_file": 5,
            },
            PlanToCode: {
                "max_prompt_file_tokens": 16000,
                "max_tokens_in_edit_prompt": 750,
                "expand_context_with_related_spans": False,
            },
        },
        initial_state=SearchCode,
        transitions=[
            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger="did_search"),
            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger="search"),
            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger="finish"),
            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger="search"),
            TransitionRule(
                source=DecideRelevance,
                dest=PlanToCode,
                trigger="finish",
                exclude_fields={"message"},
            ),
            TransitionRule(source=PlanToCode, dest=Finished, trigger="edit_code"),
            TransitionRule(source=PlanToCode, dest=Rejected, trigger="finish"),
            TransitionRule(source=PlanToCode, dest=Rejected, trigger="reject"),
        ],
    )

    evaluation_name = create_evaluation_name("search_and_plan_2", model)

    evaluation = Evaluation(
        transitions=transitions,
        evaluations_dir=evaluations_dir + "/search_and_plan",
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_base_dir,
        previous_trajectory_dir=previous_trajectory_dir,
        retry_state="PlanToCode",
        max_file_context_tokens=16000,
        litellm_callback="langfuse",
        detailed_report=True,
    )

    df = evaluation.run_evaluation_with_moatless_dataset(
        instance_ids=identified_spans_but_failed_implementation
    )

    # print out instance id and if planned
    for instance_id in df.index:
        print(df.loc[instance_id, "instance_id"], df.loc[instance_id, "planned"])
--------------------------------------------------------------------------------
Chunk ID: benchmark/claude_evaluation.py::9
Filepath: moatless\benchmark\claude_evaluation.py
Content:
if __name__ == "__main__":
    logging.basicConfig(
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        level=logging.INFO,
    )
    logging.getLogger().setLevel(logging.INFO)
    logging.getLogger("LiteLLM").setLevel(logging.WARNING)
    logging.getLogger("Evaluator").setLevel(logging.INFO)

    # evaluate_coding()
    # evaluate_search_and_identify()
    evaluate_search_and_code(
        1,
        "/home/albert/repos/albert/moatless/evaluations/20240623_moatless_claude-3.5-sonnet/trajs",
        retry_state="PlanToCode",
    )
    # evaluate_search_and_code()
    # evaluate_search_and_code(
    #    # "/home/albert/repos/albert/moatless/evaluations/search_and_code/20240622_search_and_code_6_claude-3.5-sonnet/trajs"
    # )

--------------------------------------------------------------------------------
Chunk ID: benchmark/create_dataset.py::1
Filepath: moatless\benchmark\create_dataset.py
Content:
import json

import pandas as pd

from moatless.benchmark.swebench import setup_swebench_repo, sorted_instances
from moatless.benchmark.utils import get_file_spans_from_patch
from moatless.repository import FileRepository

experiments_runs = [
    "20240402_sweagent_claude3opus",
    "20240402_sweagent_gpt4",
    "20240509_amazon-q-developer-agent-20240430-dev",
    "20240523_aider",
    "20240524_opencsg_starship_gpt4",
    "20240530_autocoderover-v20240408",
    "20240604_CodeR",
    "20240612_IBM_Research_Agent101",
    "20240612_marscode-agent-dev",
    "20240612_MASAI_gpt4o",
    "20240615_appmap-navie_gpt4o",
    "20240617_factory_code_droid",
    "20240617_moatless_gpt4o",
]

dataset_path = (
    "/home/albert/repos/albert/moatless/datasets/swebench_lite_all_evaluations.json"
)


def read_predictions(pred_path: str):
    predictions = {}
    with open(pred_path) as f:
        for line in f.readlines():
            prediction = json.loads(line)
            predictions[prediction["instance_id"]] = prediction["model_patch"]
    return predictions
--------------------------------------------------------------------------------
Chunk ID: benchmark/create_dataset.py::2
Filepath: moatless\benchmark\create_dataset.py
Content:
def generate_report():
    results = {}

    experiments_dir = "/home/albert/repos/stuffs/experiments/evaluation/lite"

    runs = []
    for run_name in experiments_runs:
        runs.append(
            (
                run_name,
                f"{experiments_dir}/{run_name}/all_preds.jsonl",
                f"{experiments_dir}/{run_name}/results/results.json",
            )
        )

    runs.append(
        (
            "autocoderover_v20240620",
            "/home/albert/repos/stuffs/acr-experiments/evaluation/lite/20240621_autocoderover-v20240620/all_preds.jsonl",
            "/home/albert/repos/stuffs/acr-experiments/evaluation/lite/20240621_autocoderover-v20240620/results.json",
        )
    )

    runs.append(
        (
            "20240622_Lingma_Agent",
            "/home/albert/repos/stuffs/alibaba-experiments/evaluation/lite/20240622_Lingma_Agent/all_preds.jsonl",
            "/home/albert/repos/stuffs/alibaba-experiments/evaluation/lite/20240622_Lingma_Agent/results.json",
        )
    )

    for run_name, prediction_file, result_file in runs:
        with open(result_file) as file:
            final_report = json.load(file)

        resolved_tasks = final_report["resolved"]
        predictions_by_id = read_predictions(prediction_file)

        results[run_name] = {
            "resolved_tasks": resolved_tasks,
            "predictions": predictions_by_id,
        }

    evaluation_dataset = []

    report = []

    instances = sorted_instances(
        split="test", dataset_name="princeton-nlp/SWE-bench_Lite"
    )
    for instance in instances:
        instance_id = instance["instance_id"]
        expected_patch = instance["patch"]
        repo_dir = setup_swebench_repo(instance, repo_base_dir="/tmp/repos_2")
        file_repo = FileRepository(repo_dir)

        expected_file_spans = get_file_spans_from_patch(file_repo, expected_patch)

        evaluation_instance = {
            "instance_id": instance_id,
            "repo": instance["repo"],
            "base_commit": instance["base_commit"],
            "problem_statement": instance["problem_statement"],
            "golden_patch": instance["patch"],
            "expected_spans": expected_file_spans,
            "resolved_by": [],
            "alternative_spans": [],
        }

        for run_name, _, _ in runs:
            prediction = results[run_name]["predictions"].get(instance_id)

            if instance_id not in results[run_name]["resolved_tasks"]:
                continue

            file_spans = get_file_spans_from_patch(file_repo, prediction)

            is_different = False
            alternative_spans = {}
            for file_path, span_ids in file_spans.items():
                if file_path in expected_file_spans:
                    alternative_spans[file_path] = span_ids

                    if set(expected_file_spans[file_path]).difference(set(span_ids)):
                        is_different = True

            if is_different:
                evaluation_instance["alternative_spans"].append(
                    {"run_name": run_name, "spans": alternative_spans}
                )

            resolved = {
                "name": run_name,
                "patch": prediction,
                "updated_spans": file_spans,
                "alternative_spans": alternative_spans,
            }

            evaluation_instance["resolved_by"].append(resolved)

        report.append(
            {
                "instance_id": instance_id,
                "resolved_by": len(evaluation_instance["resolved_by"]),
            }
        )

        evaluation_dataset.append(evaluation_instance)

        with open(dataset_path, "w") as f:
            json.dump(evaluation_dataset, f, indent=2)

    return pd.DataFrame(report)


if __name__ == "__main__":
    df = generate_report()
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::1
Filepath: moatless\benchmark\evaluation.py
Content:
import concurrent.futures
import json
import logging
import os
import subprocess
import time
import traceback
from collections import defaultdict
from datetime import datetime, timezone
from typing import Optional, Tuple

import instructor
import litellm
import pandas as pd
from tqdm.auto import tqdm

from moatless.benchmark.report_v2 import to_result, generate_md_report
from moatless.trajectory import Trajectory
from moatless.transition_rules import TransitionRules
from moatless.benchmark.swebench import (
    found_in_alternative_spans,
    found_in_expected_spans,
    get_repo_dir_name,
    load_instance,
    setup_swebench_repo,
    sorted_instances,
)
from moatless.benchmark.utils import (
    get_missing_files,
    trace_metadata,
)
from moatless.file_context import FileContext
from moatless.loop import AgenticLoop
from moatless.repository import FileRepository, GitRepository
from moatless.workspace import Workspace

logger = logging.getLogger(__name__)

TEST_SUBSET = [
    "astropy__astropy-14995",
    "django__django-10914",
    "django__django-11039",
    "django__django-11179",
    "django__django-12286",
    "django__django-12453",
    "django__django-12983",
    "django__django-13230",
    "django__django-13710",
    "django__django-13757",
    "django__django-14915",
    "django__django-14999",
    "django__django-15789",
    "matplotlib__matplotlib-23913",
    "matplotlib__matplotlib-23964",
    "pydata__xarray-5131",
    "pytest-dev__pytest-11143",
    "pytest-dev__pytest-5692",
    "pytest-dev__pytest-7373",
    "scikit-learn__scikit-learn-13142",
    "scikit-learn__scikit-learn-13241",
    "scikit-learn__scikit-learn-13439",
    "scikit-learn__scikit-learn-13496",
    "scikit-learn__scikit-learn-13779",
    "scikit-learn__scikit-learn-14894",
    "scikit-learn__scikit-learn-25570",
    "sympy__sympy-13480",
    "sympy__sympy-13647",
    "sympy__sympy-20212",
    "sympy__sympy-24213",
]
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::2
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:
    def __init__(
        self,
        index_store_dir: str,
        repo_base_dir: str,
        evaluations_dir: str,
        evaluation_name: str,
        transitions: TransitionRules,
        instructor_mode: instructor.Mode | None = None,
        max_cost: float = 0.5,
        max_transitions: int = 25,
        max_expansions: int = 2,
        max_file_context_tokens: int = 16000,
        markdown_report: bool = False,
        litellm_callback: Optional[str] = None,
        previous_trajectory_dir: Optional[str] = None,
        retry_state: Optional[str] = None,
        num_workers: int = 1,
        detailed_report: bool = False,
    ):
        self.index_store_dir = index_store_dir
        self.repo_base_dir = repo_base_dir
        self.evaluations_dir = evaluations_dir
        self.num_workers = num_workers
        self.detailed_report = detailed_report
        self.markdown_report = markdown_report

        self.evaluation_name = evaluation_name
        self.max_file_context_tokens = max_file_context_tokens
        self.max_cost = max_cost
        self.max_expansions = max_expansions
        self.max_transitions = max_transitions
        self.instructor_mode = instructor_mode

        self.transitions = transitions

        litellm.drop_params = True

        self.evaluation_dir = f"{evaluations_dir}/{evaluation_name}"
        self.trajectory_dir = f"{self.evaluations_dir}/{evaluation_name}/trajs"
        self.logs_dir = f"{self.evaluations_dir}/{evaluation_name}/prompt_logs"
        self.predictions_path = f"{self.evaluation_dir}/all_preds.jsonl"

        self.previous_trajectory_dir = previous_trajectory_dir
        self.retry_state = retry_state

        logger.info(f"Save trajectories to directory: {self.trajectory_dir}")
        if not os.path.exists(self.trajectory_dir):
            os.makedirs(self.trajectory_dir)

        logger.info(f"Save logs to directory: {self.logs_dir}")
        if not os.path.exists(self.logs_dir):
            os.makedirs(self.logs_dir)

        if litellm_callback:
            litellm.success_callback = [litellm_callback]
            litellm.failure_callback = [litellm_callback]

        # This is only to set instances as resolved after all evaluations have been run to generate the report
        # TODO: Run swe-bench-docker after the prediction is generated
        result_file = f"{self.evaluation_dir}/result.json"
        if os.path.exists(result_file):
            with open(os.path.join(result_file)) as f:
                self.report = json.load(f)
        else:
            self.report = {"resolved_ids": []}
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::3
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def run_evaluation_with_moatless_dataset(
        self,
        resolved_by: Optional[int] = None,
        use_test_subset: bool = False,
        instance_ids: list[str] | None = None,
    ):
        file_path = os.path.join(
            os.path.dirname(__file__), "swebench_lite_all_evaluations.json"
        )
        with open(file_path) as f:
            instances = json.load(f)

        instances = sorted(instances, key=lambda x: len(x["resolved_by"]), reverse=True)

        if use_test_subset:
            instances = [
                instance
                for instance in instances
                if instance["instance_id"] in TEST_SUBSET
            ]

        if instance_ids:
            instances = [
                instance
                for instance in instances
                if instance["instance_id"] in instance_ids
            ]

        if resolved_by:
            instances = [
                instance
                for instance in instances
                if len(instance["resolved_by"]) >= resolved_by
            ]

        return self._run_evaluation(instances)
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::4
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def run_swebench_evaluation(
        self,
        dataset: str = "princeton-nlp/SWE-bench_Lite",
        split="test",
        instance_ids: list[str] | None = None,
    ):
        instances = sorted_instances(dataset, split)

        if instance_ids:
            instances = [
                instance
                for instance in instances
                if instance["instance_id"] in instance_ids
            ]

        return self._run_evaluation_simple(instances)

    def run_single_instance(
        self,
        instance_id: str,
        dataset: str = "princeton-nlp/SWE-bench_Lite",
        split="test",
    ) -> dict:
        instance = load_instance(instance_id, dataset, split)
        trajectory = self._evaluate_instance(instance)
        return to_result(instance, trajectory, self.report)
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::5
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def _evaluate_instance(self, instance: dict, retry: bool = False) -> Trajectory:
        instance_id = instance["instance_id"]
        trajectory_path = os.path.join(self.trajectory_dir, f"{instance_id}.json")
        prompt_log_dir = os.path.join(self.logs_dir, f"{instance_id}")
        if not os.path.exists(prompt_log_dir):
            os.makedirs(prompt_log_dir)

        if os.path.exists(trajectory_path) and not retry:
            # TODO: Retry when failed or not finished?
            return Trajectory.load(trajectory_path)

        repo_dir = setup_swebench_repo(instance)
        persist_dir = os.path.join(self.index_store_dir, get_repo_dir_name(instance_id))
        workspace = Workspace.from_dirs(
            repo_path=repo_dir, index_dir=persist_dir, max_file_context_tokens=16000
        )

        problem_statement = instance["problem_statement"]

        previous_actions = []
        if self.previous_trajectory_dir:
            previous_trajectory_path = os.path.join(
                self.previous_trajectory_dir, f"{instance_id}.json"
            )
            previous_trajectory = self.read_trajectory(previous_trajectory_path)
            if previous_trajectory:
                previous_actions = self.get_actions(previous_trajectory)

        metadata = trace_metadata(
            instance_id=instance_id,
            session_id=self.evaluation_name,
            trace_name="moatless",
        )

        loop = AgenticLoop(
            transition_rules=self.transitions,
            workspace=workspace,
            metadata=metadata,
            mocked_actions=previous_actions,
            reset_mocks_at_state=self.retry_state,
            trajectory_path=trajectory_path,
            prompt_log_dir=prompt_log_dir,
            max_cost=self.max_cost,
            max_transitions=self.max_transitions,
            max_actions=self.max_expansions,
            instructor_mode=self.instructor_mode,
        )

        info = {
            "evaluation_name": self.evaluation_name,
            "instance_id": instance["instance_id"],
        }

        start_time = time.time()
        try:
            response = loop.run(problem_statement)
            info["status"] = response.status
        except Exception:
            info["error"] = traceback.format_exc()
            info["status"] = "error"
            logging.exception(f"Error in evaluation of {instance['instance_id']} ")

        info["duration"] = time.time() - start_time
        info["total_cost"] = loop.total_cost()

        if isinstance(workspace.file_repo, GitRepository):
            diff = workspace.file_repo.diff()
        else:
            workspace.save()

            output = subprocess.run(
                ["git", "diff"],
                capture_output=True,
                text=True,
                cwd=repo_dir,
            )

            if output:
                diff = output.stdout
            else:
                diff = None

        info["submission"] = diff

        loop.trajectory.save_info(info)
        return loop.trajectory
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::6
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def _process_instance(self, instance) -> Tuple[dict, str]:
        trajectory = self._evaluate_instance(instance)

        result = to_result(instance, trajectory, self.report)
        submission = trajectory.info.get("submission", "")

        if self.markdown_report:
            try:
                md_report = generate_md_report(trajectory, instance)
                if not os.path.exists(f"{self.evaluation_dir}/reports"):
                    os.makedirs(f"{self.evaluation_dir}/reports")
                with open(
                    f"{self.evaluation_dir}/reports/{instance['instance_id']}.md",
                    "w",
                ) as file:
                    file.write(md_report)
            except Exception:
                logging.exception(
                    f"Error in generating report for {instance['instance_id']} "
                )

        return result, submission
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::7
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def _process_repo_group(self, repo, instances):
        results = []
        transition_results = []
        for i, instance in enumerate(instances):
            logger.info(
                f"Processing {instance['instance_id']} ({i+1}/{len(instances)} in {repo})"
            )

            trajectory = self._evaluate_instance(instance)
            if not trajectory:
                return None, None

            result = to_result(instance, trajectory, report=self.report)
            results.append(result)

            try:
                md_report = generate_md_report(trajectory, instance)
                if not os.path.exists(f"{self.evaluation_dir}/reports"):
                    os.makedirs(f"{self.evaluation_dir}/reports")
                with open(
                    f"{self.evaluation_dir}/reports/{instance['instance_id']}.md",
                    "w",
                ) as file:
                    file.write(md_report)
            except Exception:
                logging.exception(
                    f"Error in generating report for {instance['instance_id']} "
                )

            prediction = {
                "model_name_or_path": self.evaluation_name,
                "instance_id": result["instance_id"],
                "model_patch": trajectory["info"].get("submission", ""),
            }

            with open(self.predictions_path, "a") as file:
                json_string = json.dumps(prediction)
                file.write(json_string + "\n")

        return results, transition_results

    def _run_evaluation(self, instances: list[dict]):
        if self.detailed_report or self.num_workers > 1:
            self._run_evaluation_detailed(instances)
        else:
            self._run_evaluation_simple(instances)
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::8
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def _run_evaluation_detailed(self, instances: list[dict]):
        error = 0

        with open(self.predictions_path, "w") as file:
            file.write("")

        repo_groups = defaultdict(list)
        for instance in instances:
            repo_groups[instance.get("repo")].append(instance)

        results = []
        transition_results = []

        logger.info(f"Processing {len(instances)} instances with {len(repo_groups)} repos with {self.num_workers} workers")

        with concurrent.futures.ProcessPoolExecutor(
            max_workers=self.num_workers
        ) as executor:
            futures = []
            for repo, group in repo_groups.items():
                futures.append(executor.submit(self._process_repo_group, repo, group))

            pbar = tqdm(concurrent.futures.as_completed(futures), total=len(futures))

            for future in pbar:
                try:
                    group_results, group_transition_results = future.result()
                    if not group_results:
                        logger.warning("Error in processing repo group")
                        error += 1
                        continue
                except Exception:
                    error += 1
                    logger.exception("Error in processing repo group")
                    continue

                results.extend(group_results)
                transition_results.extend(group_transition_results)

                df = pd.DataFrame(results)
                df.to_csv(
                    f"{self.evaluation_dir}/result.csv",
                    index=False,
                    sep=",",
                    decimal=",",
                    quoting=1,
                )

                avg_duration = df["duration"].mean()
                avg_cost = df["total_cost"].mean()
                total_identified = df["identified"].sum()
                total_processed = len(df)

                logger.info(f"Average duration: {avg_duration:.2f} seconds")
                logger.info(f"Average cost: ${avg_cost:.4f}")
                logger.info(f"Total identified: {total_identified}")
                logger.info(f"Total processed: {total_processed}")
                logger.info(f"Error count: {error}")

                if transition_results:
                    df_search = pd.DataFrame(transition_results)
                    df_search.to_csv(
                        f"{self.evaluation_dir}/transition_results.csv",
                        index=False,
                        sep=",",
                        decimal=",",
                        quoting=1,
                    )
--------------------------------------------------------------------------------
Chunk ID: benchmark/evaluation.py::9
Filepath: moatless\benchmark\evaluation.py
Content:
class Evaluation:

    def _run_evaluation_simple(self, instances: list[dict]):
        with open(self.predictions_path, "w") as file:
            file.write("")

        count = 0
        identified = 0
        generated = 0
        error = 0

        sum_duration = 0
        sum_total_cost = 0

        stats = {}
        pbar = tqdm(instances)
        for instance in pbar:
            trajectory = self._evaluate_instance(instance)
            if not trajectory:
                continue

            result, transition_result = to_result(instance, trajectory, report=self.report)

            sum_duration += result["duration"]
            sum_total_cost += result["total_cost"]

            if result["status"] == "error":
                error += 1

            if result["status"] in ["generated", "failed", "resolved"]:
                generated += 1

            if result["identified"] is not None:
                identified += 1

            count += 1

            if sum_duration > 0:
                stats["avg_duration"] = sum_duration / count

            if sum_total_cost > 0:
                stats["avg_cost"] = sum_total_cost / count
                stats["total_cost"] = sum_total_cost

            if identified > 0:
                success_rate = (identified / count) * 100
                stats["identified"] = f"{success_rate:.2f}%"

            if generated > 0:
                success_rate = (generated / count) * 100
                stats["generated"] = f"{success_rate:.2f}%"

            stats["error"] = error

            pbar.set_postfix(stats)

            prediction = {
                "model_name_or_path": self.evaluation_name,
                "instance_id": instance["instance_id"],
                "model_patch": trajectory["info"].get("submission", ""),
            }

            with open(self.predictions_path, "a") as file:
                json_string = json.dumps(prediction)
                file.write(json_string + "\n")


    def read_trajectory(self, path) -> Optional[dict]:
        if os.path.exists(path):
            with open(path) as f:
                return json.load(f)
        else:
            return None

    def get_actions(self, trajectory: dict):
        actions = []
        for transition in trajectory["transitions"]:
            for action in transition["actions"]:
                actions.append(action)
        return actions


def create_evaluation_name(
    name: str,
    model: str,
):
    date_str = datetime.now(tz=timezone.utc).strftime("%Y%m%d")
    model_name = model.split("/")[-1]
    return f"{date_str}_{name}_{model_name}"
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v1.py::1
Filepath: moatless\benchmark\report_v1.py
Content:
import json
import logging
import os

from moatless import FileRepository
from moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo
from moatless.benchmark.utils import get_missing_files
from moatless.file_context import FileContext

logger = logging.getLogger(__name__)


def to_result(instance: dict, trajectory: dict, report: dict | None) -> tuple[dict, list]:
    """
    Generate reports from saved trajectories with version 1 format.
    """

    info = trajectory["info"]

    resolved = report and info.get("instance_id", "") in report["resolved"]

    try:
        transitions = []
        result = {
            "instance_id": instance["instance_id"],
            "duration": info.get("duration", 0),
            "total_cost": info.get("total_cost", 0),
            "resolved_by": (len(instance.get("resolved_by", []))),
            "status": None,
            "transitions": len(trajectory["transitions"]),
            "edited": False,
            "planned": False,
            "identified": None,
            "expected_identified": None,
            "alt_identified": None,
            "found_in_search": None,
            "file_identified": None,
            "file_in_search": None,
            "edit_retries": 0,
            "has_diff": False,
            "lint_codes": None,
            "review": False,
            "p_query": 0,
            "p_file": 0,
            "p_code": 0,
            "p_class": 0,
            "p_function": 0,
            "lints": "",
        }

        lint_codes = set()
        search_results_spans = {}
        identified_spans = {}
        planned_spans = {}
        edited_spans = {}

        id_iterations = 0
        search_iterations = 0

        if instance.get("expected_spans"):
            # ... other code
    # ... other code
    # ... other code
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v1.py::2
Filepath: moatless\benchmark\report_v1.py
Content:
def to_result(instance: dict, trajectory: dict, report: dict | None) -> tuple[dict, list]:

    try:

        if instance.get("expected_spans"):
            for transition in trajectory["transitions"]:
                if transition["name"] not in result:
                    result[transition["name"]] = 0
                    result[f"{transition['name']}_cost"] = 0

                result[transition["name"]] += 1

                expected_span_str = ""
                for file_path, span_ids in instance["expected_spans"].items():
                    expected_span_str += f"{file_path}: {span_ids} "

                transition_result = {
                    "instance_id": instance["instance_id"],
                    "resolved": resolved,
                    "name": transition["name"],
                    "cost": 0,
                    "expected_spans": expected_span_str,
                    "actual_spans": "",
                }

                if not transition["actions"]:
                    continue

                for traj_action in transition["actions"]:
                    result[f"{transition['name']}_cost"] += traj_action.get(
                        "completion_cost", 0
                    )
                    transition_result["cost"] += traj_action.get(
                        "completion_cost", 0
                    )

                if transition["name"] == "SearchCode":
                    search_iterations += 1

                    action = transition["actions"][-1]

                    if "search_requests" in action["action"]:
                        for search_request in action["action"]["search_requests"]:
                            if search_request.get("query"):
                                result["p_query"] += 1

                            if search_request.get("file_pattern"):
                                result["p_file"] += 1

                            if search_request.get("code_snippet"):
                                result["p_code"] += 1

                            if search_request.get(
                                    "class_name"
                            ) or search_request.get("class_names"):
                                result["p_class"] += 1

                            if search_request.get(
                                    "function_name"
                            ) or search_request.get("function_names"):
                                result["p_function"] += 1

                    if "output" in action and action.get("output"):
                        output = action["output"]

                        if "query" in output:
                            result["p_query"] += 1

                        if "file_pattern" in output:
                            result["p_file"] += 1

                        if "code_snippet" in output:
                            result["p_code"] += 1

                        if "class_name" in output or "class_names" in output:
                            result["p_class"] += 1

                        if "function_name" in output or "function_names" in output:
                            result["p_function"] += 1

                        if output.get("ranked_spans"):
                            for ranked_span in output["ranked_spans"]:
                                if (
                                        ranked_span["file_path"]
                                        not in search_results_spans
                                ):
                                    search_results_spans[
                                        ranked_span["file_path"]
                                    ] = []
                                search_results_spans[
                                    ranked_span["file_path"]
                                ].append(ranked_span["span_id"])

                            if not result["found_in_search"] and (
                                    found_in_expected_spans(
                                        instance, search_results_spans
                                    )
                                    or found_in_alternative_spans(
                                instance, search_results_spans
                            )
                            ):
                                result["found_in_search"] = search_iterations

                            if not result["file_in_search"]:
                                missing_files = get_missing_files(
                                    instance["expected_spans"],
                                    search_results_spans,
                                )
                                if not missing_files:
                                    result["file_in_search"] = search_iterations

                if transition["name"] == "IdentifyCode":
                    id_iterations += 1

                    action = transition["actions"][-1]
                    if action.get("action"):
                        identified_str = ""
                        if action["action"].get("identified_spans"):
                            for span in action["action"]["identified_spans"]:
                                identified_str += (
                                    f"{span['file_path']}: {span['span_ids']} "
                                )
                                if span["file_path"] not in identified_spans:
                                    identified_spans[span["file_path"]] = []

                                transition_result["actual_spans"] += (
                                    f"{span['file_path']}: {','.join(span['span_ids'])} "
                                )
                                for span_id in span["span_ids"]:
                                    identified_spans[span["file_path"]].append(
                                        span_id
                                    )
                        result["identified_spans"] = identified_str

                    if not result["file_identified"]:
                        missing_files = get_missing_files(
                            instance["expected_spans"],
                            identified_spans,
                        )
                        if not missing_files:
                            result["file_identified"] = id_iterations

                    if result[
                        "expected_identified"
                    ] is None and found_in_expected_spans(
                        instance, identified_spans
                    ):
                        result["expected_identified"] = id_iterations

                    if result[
                        "alt_identified"
                    ] is None and found_in_alternative_spans(
                        instance, identified_spans
                    ):
                        result["alt_identified"] = id_iterations

                    if result.get("alt_identified") or result.get(
                            "expected_identified"
                    ):
                        result["identified"] = min(
                            result.get("alt_identified") or 1000,
                            result.get("expected_identified") or 1000,
                        )

                if transition["name"] == "PlanToCode":
                    action = transition["actions"][-1]["action"]
                    if action.get("action") == "review":
                        result["review"] = True

                    if "file_path" in action:
                        if "span_id" not in action:
                            logger.warning(
                                f"Span id missing in planning action in {instance['instance_id']}"
                            )
                        else:
                            file_path = action["file_path"]
                            if file_path not in planned_spans:
                                planned_spans[file_path] = []
                            planned_spans[file_path].append(action["span_id"])
                            transition_result["actual_spans"] = (
                                f"{file_path}: {action['span_id']} "
                            )

                    if not result.get("planned") and (
                            found_in_expected_spans(
                                instance,
                                planned_spans,
                            )
                            or found_in_alternative_spans(instance, planned_spans)
                    ):
                        result["planned"] = True

                if transition["name"] == "EditCode":
                    result["edit_retries"] = len(transition["actions"]) - 1

                    action = transition["actions"][-1]
                    output = action.get("output", {})

                    if output:
                        edited = output.get("diff")

                        if edited:
                            result["has_diff"] = True

                        for lint in output.get("verification_errors", []):
                            lint_codes.add(lint["code"])

                        if edited and "file_path" in transition["state"]:
                            file_path = transition["state"]["file_path"]
                            if file_path not in edited_spans:
                                edited_spans[file_path] = []
                            edited_spans[file_path].append(
                                transition["state"]["span_id"]
                            )
                            transition_result["actual_spans"] = (
                                f"{file_path}: {transition['state']['span_id']} "
                            )

                        if not result.get("edited") and (
                                found_in_expected_spans(
                                    instance,
                                    edited_spans,
                                )
                                or found_in_alternative_spans(instance, edited_spans)
                        ):
                            result["edited"] = True

                transitions.append(transition_result)

            if result.get("alt_identified") or result.get("expected_identified"):
                result["identified"] = min(
                    result.get("alt_identified") or 1000,
                    result.get("expected_identified") or 1000,
                )

            result["expected_files"] = list(instance["expected_spans"].keys())
            result["edited_files"] = list(edited_spans.keys())
            result["identified_spans"] = sum(
                [len(v) for v in identified_spans.values()]
            )
    # ... other code
    # ... other code
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v1.py::3
Filepath: moatless\benchmark\report_v1.py
Content:
def to_result(instance: dict, trajectory: dict, report: dict | None) -> tuple[dict, list]:

    try:
        # ... other code

        result["lints"] = ",".join(lint_codes)

        if report and info.get("instance_id", "") in report["resolved"]:
            result["status"] = "resolved"
        elif result["edited"]:
            result["status"] = "edited"
        elif result["identified"]:
            result["status"] = "identified"
        elif result["found_in_search"]:
            result["status"] = "found_in_search"
        elif result["file_identified"]:
            result["status"] = "file_identified"
        else:
            result["status"] = ""

        if "error" in info:
            result["error"] = info["error"].split("\n")[0]
        else:
            result["error"] = ""

    except Exception as e:
        raise e

    return result, transitions
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v1.py::4
Filepath: moatless\benchmark\report_v1.py
Content:
def generate_md_report(trajectory: dict, instance: dict):
    info = trajectory["info"]
    markdown = f"# {instance['instance_id']}\n"

    markdown += "\n## Problem statement\n"
    markdown += f"```\n{instance['problem_statement']}\n```\n"

    if "error" in trajectory["info"]:
        markdown += "\n## Error\n"
        markdown += f"```\n{trajectory['info']['error']}\n```\n"
    else:
        markdown += "\n## Prediction\n"
        markdown += f"```diff\n{info['submission']}\n```\n"

    markdown += "\n## Golden patch\n"
    markdown += f"```diff\n{instance['golden_patch']}\n```\n"

    markdown += "\n## Trajectory\n"

    repo_dir = setup_swebench_repo(instance)
    file_repo = FileRepository(repo_dir)

    for j, step in enumerate(trajectory["transitions"]):
        for i, traj_action in enumerate(step["actions"]):
            state_name = step['state']
            markdown += f"### {j+1} {state_name} ({i+1})\n\n"

            if not traj_action.get("action"):
                continue
            action = traj_action["action"]

            if state_name == "PlanToCode":
                if action.get("scratch_pad"):
                    markdown += "*" + action["scratch_pad"] + "*"

                if action.get("instructions"):
                    markdown += f"\n\n * {action['instructions']}"

                if action.get("file_path"):
                    markdown += f"\n * {action['file_path']}"

                if action.get("span_id"):
                    markdown += f"\n * {action['span_id']}"

                if action.get("file_path") and action.get("span_id"):
                    markdown += "\n\n#### File context \n\n"
                    try:
                        file_context = FileContext(file_repo)
                        file_context.add_span_to_context(
                            action.get("file_path"),
                            action.get("span_id"),
                        )
                        markdown += file_context.create_prompt(
                            show_outcommented_code=True
                        )
                    except Exception as e:
                        logger.error(e)

            if state_name == "EditCode":
                markdown += "#### LLM Response\n\n"
                markdown += f"```\n{action.get('content', '')}\n```\n"

                output = traj_action.get("output")
                if output:
                    if output.get("diff"):
                        markdown += "#### Diff\n\n"
                        markdown += f"```diff\n{output['diff']}\n```\n"

                    if output.get("errors"):
                        markdown += "#### Errors\n\n"
                        markdown += f"{output['errors']}\n\n"

                    if output.get("message"):
                        markdown += "#### Message\n\n"
                        markdown += f"{output['message']}\n\n"

            if state_name == "ClarifyCodeChange":
                if action.get("thoughts"):
                    markdown += "*" + action["thoughts"] + "*"

                if action.get("output") and action.get("output").get("start_line"):
                    markdown += f"\n* Start Line: {action['output']['start_line']}\n"
                    markdown += f"\n* End Line: {action['output']['end_line']}\n"

            if state_name == "Finished":
                markdown += f"*{action['properties']['message']}*\n"

            if state_name == "Rejected":
                markdown += f"*{action['properties']['message']}*\n"

    markdown += "## Alternative patches\n"
    for alternative in instance["resolved_by"]:
        markdown += f"### {alternative['name']}\n"
        markdown += f"```diff\n{alternative['patch']}\n```\n"

    return markdown
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v2.py::1
Filepath: moatless\benchmark\report_v2.py
Content:
import logging

from moatless import FileRepository
from moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo
from moatless.benchmark.utils import get_missing_files
from moatless.edit.plan import ApplyChange
from moatless.file_context import FileContext
from moatless.find.search import SearchRequest

logger = logging.getLogger(__name__)

import logging

from moatless import FileRepository
from moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo
from moatless.benchmark.utils import get_missing_files
from moatless.file_context import FileContext

logger = logging.getLogger(__name__)

import logging
from typing import Dict, List, Tuple, Optional

from moatless import FileRepository
from moatless.benchmark.swebench import found_in_expected_spans, found_in_alternative_spans, setup_swebench_repo
from moatless.benchmark.utils import get_missing_files
from moatless.file_context import FileContext
from moatless.trajectory import Trajectory
from moatless.types import ActionTransaction, Usage, Content
from moatless.state import AgenticState

logger = logging.getLogger(__name__)


def to_result(instance: Dict, trajectory: Trajectory, report: Optional[Dict] = None) -> Dict:
    info = trajectory._info

    if report and "resolved_ids" in report and instance["instance_id"] in report["resolved_ids"]:
        result_status = "resolved"
    else:
        result_status = info.get("status")

    resolved = result_status == "resolved"

    try:
    # ... other code
    # ... other code
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v2.py::2
Filepath: moatless\benchmark\report_v2.py
Content:
def to_result(instance: Dict, trajectory: Trajectory, report: Optional[Dict] = None) -> Dict:

    try:
        result = {
            "instance_id": instance["instance_id"],
            "duration": info.get("duration", 0),
            "total_cost": info.get("total_cost", 0),
            "resolved_by": (len(instance.get("resolved_by", []))),
            "status": None,
            "result_status": result_status,
            "transitions": len(trajectory.transitions),
            "edited": False,
            "planned": False,
            "identified": None,
            "expected_identified": None,
            "alt_identified": None,
            "found_in_search": None,
            "file_identified": None,
            "file_in_search": None,
            "edit_retries": 0,
            "has_diff": False,
            "lint_codes": None,
            "review": False,
            "p_query": 0,
            "p_file": 0,
            "p_code": 0,
            "p_class": 0,
            "p_function": 0,
            "lints": "",
        }

        lint_codes = set()
        search_results_spans: Dict[str, List[str]] = {}
        identified_spans: Dict[str, List[str]] = {}
        planned_spans: Dict[str, List[str]] = {}
        edited_spans: Dict[str, List[str]] = {}

        id_iterations = 0
        search_iterations = 0

        selected_transition_ids = []
        current_state = trajectory.get_current_state()
        while current_state:
            selected_transition_ids.append(current_state.id)
            current_state = current_state.previous_state

        logger.info(f"Selected transitions: {selected_transition_ids}")

        if instance.get("expected_spans"):
            for transition in trajectory.transitions:
                if selected_transition_ids and transition.id not in selected_transition_ids:
                    continue

                state: AgenticState = transition.state
                state_name = state.name

                if state_name not in result:
                    result[state_name] = 0
                    result[f"{state_name}_cost"] = 0

                result[state_name] += 1

                expected_span_str = ""
                for file_path, span_ids in instance["expected_spans"].items():
                    expected_span_str += f"{file_path}: {span_ids} "

                if not state._actions:
                    continue

                for action in state._actions:
                    result[f"{state_name}_cost"] += action.usage.completion_cost if action.usage else 0

                if state_name == "SearchCode":
                    search_iterations += 1

                    action = state._actions[-1]

                    if isinstance(action.request, SearchRequest):
                        for search_request in action.request.search_requests:
                            if search_request.query:
                                result["p_query"] += 1
                            if search_request.file_pattern:
                                result["p_file"] += 1
                            if search_request.code_snippet:
                                result["p_code"] += 1
                            if search_request.class_name or search_request.class_names:
                                result["p_class"] += 1
                            if search_request.function_name or search_request.function_names:
                                result["p_function"] += 1

                if state_name == "IdentifyCode":
                    id_iterations += 1

                    if state.ranked_spans:
                        for ranked_span in state.ranked_spans:
                            if ranked_span.file_path not in search_results_spans:
                                search_results_spans[ranked_span.file_path] = []
                            search_results_spans[ranked_span.file_path].append(ranked_span.span_id)

                        if not result["found_in_search"] and (
                                found_in_expected_spans(instance, search_results_spans)
                                or found_in_alternative_spans(instance, search_results_spans)
                        ):
                            result["found_in_search"] = search_iterations

                        if not result["file_in_search"]:
                            missing_files = get_missing_files(
                                instance["expected_spans"],
                                search_results_spans,
                            )
                            if not missing_files:
                                result["file_in_search"] = search_iterations

                    if state._actions:
                        action = state._actions[-1]
                        identified_str = ""
                        if action.request.identified_spans:
                            for span in action.request.identified_spans:
                                identified_str += f"{span.file_path}: {span.span_ids} "
                                if span.file_path not in identified_spans:
                                    identified_spans[span.file_path] = []

                                for span_id in span.span_ids:
                                    identified_spans[span.file_path].append(span_id)
                        result["identified_spans"] = identified_str

                    if not result["file_identified"]:
                        missing_files = get_missing_files(
                            instance["expected_spans"],
                            identified_spans,
                        )
                        if not missing_files:
                            result["file_identified"] = id_iterations

                    if result["expected_identified"] is None and found_in_expected_spans(instance, identified_spans):
                        result["expected_identified"] = id_iterations

                    if result["alt_identified"] is None and found_in_alternative_spans(instance, identified_spans):
                        result["alt_identified"] = id_iterations

                    if result.get("alt_identified") or result.get("expected_identified"):
                        result["identified"] = min(
                            result.get("alt_identified") or 1000,
                            result.get("expected_identified") or 1000,
                        )

                if state_name == "PlanToCode":
                    action = state._actions[-1]

                    if action.request.action == "review":
                        result["review"] = True

                    if action.request.file_path:
                        file_path = action.request.file_path
                        if file_path not in planned_spans:
                            planned_spans[file_path] = []
                        planned_spans[file_path].append(action.request.span_id)

                    if not result.get("planned") and (
                            found_in_expected_spans(instance, planned_spans)
                            or found_in_alternative_spans(instance, planned_spans)
                    ):
                        result["planned"] = True

                if state_name == "EditCode":
                    result["edit_retries"] = len(state._actions) - 1

                    action = state._actions[-1]
                    edited = action.response and action.response.trigger == "finish"

                    if edited and hasattr(state, 'file_path'):
                        file_path = state.file_path
                        if file_path not in edited_spans:
                            edited_spans[file_path] = []
                        edited_spans[file_path].append(state.span_id)

                    if not result.get("edited") and (
                            found_in_expected_spans(instance, edited_spans)
                            or found_in_alternative_spans(instance, edited_spans)
                    ):
                        result["edited"] = True

                    if action.response and action.response.output:
                        output = action.response.output
                        if edited:
                            result["has_diff"] = True

                        for lint in output.get("verification_errors", []):
                            lint_codes.add(lint["code"])

            if result.get("alt_identified") or result.get("expected_identified"):
                result["identified"] = min(
                    result.get("alt_identified") or 1000,
                    result.get("expected_identified") or 1000,
                )

            result["expected_files"] = list(instance["expected_spans"].keys())
            result["edited_files"] = list(edited_spans.keys())
            result["identified_spans"] = sum(len(v) for v in identified_spans.values())

        result["lints"] = ",".join(lint_codes)

        if result["edited"]:
            result["status"] = "edited"
        elif result["identified"]:
            result["status"] = "identified"
        elif result["found_in_search"]:
            result["status"] = "found_in_search"
        elif result["file_identified"]:
            result["status"] = "file_identified"
        else:
            result["status"] = ""

        if "error" in info:
            result["error"] = info["error"].split("\n")[0]
        else:
            result["error"] = ""

    except Exception as e:
        raise e

    return result
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v2.py::3
Filepath: moatless\benchmark\report_v2.py
Content:
def generate_md_report(trajectory: Trajectory, instance: Dict) -> str:
    info = trajectory._info
    markdown = f"# {instance['instance_id']}\n"

    markdown += "\n## Problem statement\n"
    markdown += f"```\n{instance['problem_statement']}\n```\n"

    if "error" in trajectory._info:
        markdown += "\n## Error\n"
        markdown += f"```\n{trajectory._info['error']}\n```\n"
    else:
        markdown += "\n## Prediction\n"
        markdown += f"```diff\n{info['submission']}\n```\n"

    markdown += "\n## Golden patch\n"
    markdown += f"```diff\n{instance['golden_patch']}\n```\n"

    markdown += "\n## Trajectory\n"

    repo_dir = setup_swebench_repo(instance)
    file_repo = FileRepository(repo_dir)

    for j, transition in enumerate(trajectory.transitions):
        state = transition.state
        for i, action in enumerate(state._actions):
            markdown += f"### {j+1} {state.name} ({i+1})\n\n"

            if state.name == "PlanToCode":
                if action.request.file_path:
                    if action.request.instructions:
                        markdown += f"\n\n * {action.request.instructions}"
                    markdown += f"\n * {action.request.file_path}"
                    markdown += f"\n * {action.request.span_id}"

                    markdown += "\n\n#### File context \n\n"
                    try:
                        file_context = FileContext(file_repo)
                        file_context.add_span_to_context(
                            action.request.file_path,
                            action.request.span_id,
                        )
                        markdown += file_context.create_prompt(
                            show_outcommented_code=True
                        )
                    except Exception as e:
                        logger.error(e)

            if state.name == "EditCode":
                markdown += "#### LLM Response\n\n"
                markdown += f"```\n{action.request.content if isinstance(action.request, Content) else ''}\n```\n"

                if action.response and action.response.output:
                    output = action.response.output
                    if output.get("diff"):
                        markdown += "#### Diff\n\n"
                        markdown += f"```diff\n{output['diff']}\n```\n"

                    if output.get("errors"):
                        markdown += "#### Errors\n\n"
                        markdown += f"{output['errors']}\n\n"

                    if output.get("message"):
                        markdown += "#### Message\n\n"
                        markdown += f"{output['message']}\n\n"

            if state.name == "ClarifyCodeChange":

                if action.request.scratch_pad:
                    markdown += f"*{action.request.scratch_pad}*"

                if action.response and action.response.output:
                    output = action.response.output
                    if output.get("start_line"):
                        markdown += f"\n* Start Line: {output['start_line']}\n"
                        markdown += f"\n* End Line: {output['end_line']}\n"

            if state.name == "Finished":
                markdown += f"*{action.request.thoughts}*\n"

            if state.name == "Rejected":
                markdown += f"*{action.request.thoughts}*\n"

    markdown += "## Alternative patches\n"
    for alternative in instance["resolved_by"]:
        markdown += f"### {alternative['name']}\n"
        markdown += f"```diff\n{alternative['patch']}\n```\n"

    return markdown
--------------------------------------------------------------------------------
Chunk ID: benchmark/report_v2.py::4
Filepath: moatless\benchmark\report_v2.py
Content:
def generate_md_report(trajectory: dict, instance: dict):
    info = trajectory["info"]
    markdown = f"# {instance['instance_id']}\n"

    markdown += "\n## Problem statement\n"
    markdown += f"```\n{instance['problem_statement']}\n```\n"

    if "error" in trajectory["info"]:
        markdown += "\n## Error\n"
        markdown += f"```\n{trajectory['info']['error']}\n```\n"
    else:
        markdown += "\n## Prediction\n"
        markdown += f"```diff\n{info['submission']}\n```\n"

    markdown += "\n## Golden patch\n"
    markdown += f"```diff\n{instance['golden_patch']}\n```\n"

    markdown += "\n## Trajectory\n"

    repo_dir = setup_swebench_repo(instance)
    file_repo = FileRepository(repo_dir)

    for j, step in enumerate(trajectory["transitions"]):
        for i, traj_action in enumerate(step["actions"]):
            state_name = step['state']
            markdown += f"### {j+1} {state_name} ({i+1})\n\n"

            if not traj_action.get("action"):
                continue
            action = traj_action["action"]

            if state_name == "PlanToCode":
                if action.get("scratch_pad"):
                    markdown += "*" + action["scratch_pad"] + "*"

                if action.get("instructions"):
                    markdown += f"\n\n * {action['instructions']}"

                if action.get("file_path"):
                    markdown += f"\n * {action['file_path']}"

                if action.get("span_id"):
                    markdown += f"\n * {action['span_id']}"

                if action.get("file_path") and action.get("span_id"):
                    markdown += "\n\n#### File context \n\n"
                    try:
                        file_context = FileContext(file_repo)
                        file_context.add_span_to_context(
                            action.get("file_path"),
                            action.get("span_id"),
                        )
                        markdown += file_context.create_prompt(
                            show_outcommented_code=True
                        )
                    except Exception as e:
                        logger.error(e)

            if state_name == "EditCode":
                markdown += "#### LLM Response\n\n"
                markdown += f"```\n{action.get('content', '')}\n```\n"

                output = traj_action.get("output")
                if output:
                    if output.get("diff"):
                        markdown += "#### Diff\n\n"
                        markdown += f"```diff\n{output['diff']}\n```\n"

                    if output.get("errors"):
                        markdown += "#### Errors\n\n"
                        markdown += f"{output['errors']}\n\n"

                    if output.get("message"):
                        markdown += "#### Message\n\n"
                        markdown += f"{output['message']}\n\n"

            if state_name == "ClarifyCodeChange":
                if action.get("thoughts"):
                    markdown += "*" + action["thoughts"] + "*"

                if action.get("output") and action.get("output").get("start_line"):
                    markdown += f"\n* Start Line: {action['output']['start_line']}\n"
                    markdown += f"\n* End Line: {action['output']['end_line']}\n"

            if state_name == "Finished":
                markdown += f"*{action['properties']['message']}*\n"

            if state_name == "Rejected":
                markdown += f"*{action['properties']['message']}*\n"

    markdown += "## Alternative patches\n"
    for alternative in instance["resolved_by"]:
        markdown += f"### {alternative['name']}\n"
        markdown += f"```diff\n{alternative['patch']}\n```\n"

    return markdown
--------------------------------------------------------------------------------
Chunk ID: swebench/__init__.py::1
Filepath: moatless\benchmark\swebench\__init__.py
Content:
from moatless.benchmark.swebench.utils import *  # noqa

--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::1
Filepath: moatless\benchmark\swebench\utils.py
Content:
import logging
import os
from typing import Optional

from datasets import load_dataset

from moatless.benchmark.utils import (
    file_spans_to_dict,
    get_missing_files,
    get_missing_spans,
)
from moatless.file_context import FileContext
from moatless.index import CodeIndex
from moatless.repository import FileRepository, GitRepository
from moatless.utils.repo import setup_github_repo
from moatless.workspace import Workspace


logger = logging.getLogger(__name__)


def load_instances(
    dataset_name: str = "princeton-nlp/SWE-bench_Lite", split: str = "test"
):
    data = load_dataset(dataset_name, split=split)
    return {d["instance_id"]: d for d in data}


def load_instance(
    instance_id: str,
    dataset_name: str = "princeton-nlp/SWE-bench_Lite",
    split: str = "test",
):
    data = load_instances(dataset_name, split=split)
    return data[instance_id]


def sorted_instances(
    dataset_name: str = "princeton-nlp/SWE-bench_Lite",
    split: str = "test",
    sort_by: str = "created_at",
):
    data = load_dataset(dataset_name, split=split)
    instances = list(data)
    instances = sorted(instances, key=lambda x: x[sort_by])
    return instances


def get_repo_dir_name(repo: str):
    return repo.replace("/", "_")


def found_in_expected_spans(instance: dict, spans: dict):
    for file_path, span_ids in instance["expected_spans"].items():
        if not span_ids:
            logging.warning(
                f"{instance['instance_id']} Expected spans for {file_path} is empty"
            )
    missing_spans = get_missing_spans(instance["expected_spans"], spans)
    return not missing_spans
--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::2
Filepath: moatless\benchmark\swebench\utils.py
Content:
def found_in_alternative_spans(instance: dict, spans: dict):
    if "alternative_spans" not in instance:
        return False
    for alternative_spans in instance["alternative_spans"]:
        for file_path, span_ids in alternative_spans["spans"].items():
            if not span_ids:
                logging.warning(
                    f"{instance['instance_id']} Alternative spans for {file_path} is empty"
                )

        missing_spans = get_missing_spans(alternative_spans["spans"], spans)
        if not missing_spans:
            return True

    return False


def sync_file_context_with_search_trajectory(workspace: Workspace, trajectory: dict):
    for transition in trajectory["transitions"]:
        for action in transition["actions"]:
            if action["action"].get("identified_spans"):
                for span in action["action"]["identified_spans"]:
                    workspace.file_context.add_spans_to_context(
                        span["file_path"], span["span_ids"]
                    )
--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::3
Filepath: moatless\benchmark\swebench\utils.py
Content:
def verify_search_trajectory(
    trajectory: dict, instance: dict, workspace: Workspace
) -> dict:
    result = {
        "transitions": len(trajectory["transitions"]),
        "identifieed": None,
        "expected_identified": None,
        "alt_identified": None,
        "identified": None,
        "file_identified": None,
        "found_in_search": None,
        "tokens": 0,
        "expanded_imports": False,
        "expanded_related": False,
        "expanded_small_classes": False,
        "expanded_tokens": 0,
    }

    file_context = workspace.create_file_context()
    search_file_context = workspace.create_file_context()

    iterations = 0
    for transition in trajectory["transitions"]:
        if transition["name"] == "SearchCode":
            iterations += 1

        for action in transition["actions"]:
            if (
                "output" in action
                and action.get("output")
                and action["output"].get("ranked_spans")
            ):
                for ranked_span in action["output"]["ranked_spans"]:
                    search_file_context.add_spans_to_context(
                        ranked_span["file_path"], [ranked_span["span_id"]]
                    )

            if action["action"].get("identified_spans"):
                for span in action["action"]["identified_spans"]:
                    file_context.add_spans_to_context(
                        span["file_path"], span["span_ids"]
                    )

            if result["found_in_search"] is None and (
                found_in_expected_spans(
                    instance,
                    file_spans_to_dict(search_file_context.to_files_with_spans()),
                )
                or found_in_alternative_spans(
                    instance, file_spans_to_dict(file_context.to_files_with_spans())
                )
            ):
                result["found_in_search"] = iterations

            if result["file_identified"] is None:
                missing_files = get_missing_files(
                    instance["expected_spans"],
                    file_spans_to_dict(file_context.to_files_with_spans()),
                )
                if not missing_files:
                    result["file_identified"] = iterations

            if result["expected_identified"] is None and found_in_expected_spans(
                instance, file_spans_to_dict(file_context.to_files_with_spans())
            ):
                result["expected_identified"] = iterations

            if result["alt_identified"] is None and found_in_alternative_spans(
                instance, file_spans_to_dict(file_context.to_files_with_spans())
            ):
                result["alt_identified"] = iterations

    if result["expected_identified"] is not None:
        result["identified"] = result["expected_identified"]

    if result["alt_identified"] is not None and (
        result["identified"] is None or result["alt_identified"] < result["identified"]
    ):
        result["identified"] = result["alt_identified"]

    result["tokens"] = file_context.context_size()

    file_context.expand_context_with_init_spans()
    actual_span_dicts = file_spans_to_dict(file_context.to_files_with_spans())

    if found_in_expected_spans(
        instance, actual_span_dicts
    ) or found_in_alternative_spans(instance, actual_span_dicts):
        result["expanded_imports"] = True

    file_context.expand_context_with_related_spans(max_tokens=8000)
    if found_in_expected_spans(
        instance, file_spans_to_dict(file_context.to_files_with_spans())
    ) or found_in_alternative_spans(
        instance, file_spans_to_dict(file_context.to_files_with_spans())
    ):
        result["expanded_related"] = True

    file_context.expand_small_classes(max_tokens=500)
    if found_in_expected_spans(
        instance, file_spans_to_dict(file_context.to_files_with_spans())
    ) or found_in_alternative_spans(
        instance, file_spans_to_dict(file_context.to_files_with_spans())
    ):
        result["expanded_small_classes"] = True

    result["expanded_tokens"] = file_context.context_size()

    result["iterations"] = iterations
    return result
--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::4
Filepath: moatless\benchmark\swebench\utils.py
Content:
def generate_md_report(trajectory: dict, instance: dict):
    info = trajectory["info"]
    markdown = f"# {info['instance_id']}\n"

    markdown += "\n## Problem statement\n"
    markdown += f"```\n{instance['problem_statement']}\n```\n"

    if "error" in trajectory["info"]:
        markdown += "\n## Error\n"
        markdown += f"```\n{trajectory['info']['error']}\n```\n"
    else:
        markdown += "\n## Prediction\n"
        markdown += f"```diff\n{info['submission']}\n```\n"

    markdown += "\n## Golden patch\n"
    markdown += f"```diff\n{instance['golden_patch']}\n```\n"

    markdown += "\n## Trajectory\n"

    repo_dir = setup_swebench_repo(instance)
    file_repo = FileRepository(repo_dir)

    for step in trajectory["transitions"]:
        for i, action in enumerate(step["actions"]):
            markdown += f"### {step['name']} ({i})\n\n"

            if step["name"] == "PlanToCode":
                if action.get("action").get("thoughts"):
                    markdown += "*" + action["action"]["thoughts"] + "*"

                if action.get("action", {}).get("action", {}).get("description"):
                    markdown += f"\n\n * {action['action']['action']['description']}"

                if action.get("action", {}).get("action", {}).get("file_path"):
                    markdown += f"\n * {action['action']['action']['file_path']}"

                if action.get("action", {}).get("action", {}).get("span_id"):
                    markdown += f"\n * {action['action']['action']['span_id']}"

                    markdown += "\n\n#### File context \n\n"

                    file_context = FileContext(file_repo)
                    file_context.add_span_to_context(
                        action["action"]["action"]["file_path"],
                        action["action"]["action"]["span_id"],
                    )

                    markdown += file_context.create_prompt(show_outcommented_code=True)

            if step["name"] == "EditCode":
                markdown += "#### LLM Response\n\n"
                markdown += f"```\n{action['action']['content']}\n```\n"

                if action.get("output", {}).get("message"):
                    markdown += "#### Output\n\n"
                    markdown += f"{action['output']['message']}\n\n"

            if step["name"] == "ClarifyCodeChange":
                if action.get("thoughts"):
                    markdown += "*" + action["thoughts"] + "*"

                if action.get("output", {}).get("start_line"):
                    markdown += f"\n* Start Line: {action['output']['start_line']}\n"
                    markdown += f"\n* End Line: {action['output']['end_line']}\n"

            if step["name"] == "Finished":
                markdown += f"*{action['properties']['message']}*\n"

            if step["name"] == "Rejected":
                markdown += f"*{action['properties']['message']}*\n"

    markdown += "## Alternative patches\n"
    for alternative in instance["resolved_by"]:
        markdown += f"### {alternative['name']}\n"
        markdown += f"```diff\n{alternative['patch']}\n```\n"

    return markdown
--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::5
Filepath: moatless\benchmark\swebench\utils.py
Content:
def setup_swebench_repo(
    instance_data: Optional[dict] = None,
    instance_id: str = None,
    repo_base_dir: Optional[str] = None,
) -> str:
    assert (
        instance_data or instance_id
    ), "Either instance_data or instance_id must be provided"
    if not instance_data:
        instance_data = load_instance(instance_id)

    if not repo_base_dir:
        repo_base_dir = os.getenv("REPO_DIR", "/tmp/repos")

    repo_dir_name = instance_data["repo"].replace("/", "__")
    github_repo_path = f"swe-bench/{repo_dir_name}"
    return setup_github_repo(
        repo=github_repo_path,
        base_commit=instance_data["base_commit"],
        base_dir=repo_base_dir,
    )
--------------------------------------------------------------------------------
Chunk ID: swebench/utils.py::6
Filepath: moatless\benchmark\swebench\utils.py
Content:
def create_workspace(
    instance: Optional[dict] = None,
    instance_id: Optional[str] = None,
    repo_base_dir: Optional[str] = None,
    index_store_dir: Optional[str] = None,
):
    """
    Create a workspace for the given SWE-bench instance.
    """
    assert instance or instance_id, "Either instance or instance_id must be provided"
    if not instance:
        instance = load_instance(instance_id)

    if not index_store_dir:
        index_store_dir = os.getenv("INDEX_STORE_DIR", "/tmp/index_store")

    if not repo_base_dir:
        repo_base_dir = os.getenv("REPO_DIR", "/tmp/repos")

    repo_dir_name = instance["repo"].replace("/", "__")
    repo_url = f"https://github.com/swe-bench/{repo_dir_name}.git"
    repo_dir = f"{repo_base_dir}/swe-bench_{repo_dir_name}"
    repo = GitRepository.from_repo(
        git_repo_url=repo_url, repo_path=repo_dir, commit=instance["base_commit"]
    )

    code_index = CodeIndex.from_index_name(
        instance["instance_id"], index_store_dir=index_store_dir, file_repo=repo
    )

    return Workspace(
        file_repo=repo,
        code_index=code_index,
    )
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::1
Filepath: moatless\benchmark\utils.py
Content:
import logging
import re
import time

from moatless.codeblocks.module import Module
from moatless.repository import FileRepository
from moatless.types import FileWithSpans

logger = logging.getLogger(__name__)


def find_relevant_spans(original_block: Module, updated_block: Module):
    """Find relevant spans in test content. Used for finding the "perfect" context in benchmark instances."""

    relevant_spans = set()

    for span in updated_block.spans_by_id.values():
        if span.span_id in relevant_spans:
            continue

        if original_block.has_span(span.span_id):
            updated_content = updated_block.to_prompt(
                span_ids=set(span.span_id), show_outcommented_code=False
            ).strip()
            original_content = original_block.to_prompt(
                span_ids=set(span.span_id), show_outcommented_code=False
            ).strip()
            if original_content != updated_content:
                relevant_spans.add(span.span_id)

            # TODO: Second prio after token count
            related_span_ids = original_block.find_related_span_ids(span.span_id)
            relevant_spans.update(related_span_ids)
        else:
            parent_block = updated_block.find_first_by_span_id(span.span_id).parent
            original_parent_block = original_block.find_by_path(
                parent_block.full_path()
            )
            span_ids = list(original_parent_block.belongs_to_span.span_id)

            related_span_ids = updated_block.find_related_span_ids(span.span_id)
            for related_span_id in related_span_ids:
                if original_block.has_span(related_span_id):
                    span_ids.append(related_span_id)

    return relevant_spans
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::2
Filepath: moatless\benchmark\utils.py
Content:
def get_diff_lines(diff_input):
    if not diff_input:
        return []
    file_name_re = re.compile(r"diff --git a/(.+) b/.+")
    file_name_no_git_re = re.compile(r"--- a/(.+)")

    line_change_re = re.compile(r"^@@ -(\d+),(\d+) \+(\d+),(\d+) @@")

    changes = []

    current_file = None
    for line in diff_input.splitlines():
        file_match = file_name_re.match(line)
        if file_match:
            current_file = file_match.group(1)
            continue

        if not current_file:
            file_match = file_name_no_git_re.match(line)
            if file_match:
                current_file = file_match.group(1)

            continue

        line_change_match = line_change_re.match(line)
        if line_change_match:
            old_start, old_length, new_start, new_length = map(
                int, line_change_match.groups()
            )

            adjustment_start = max(1, min(3, old_start - 3))
            adjusted_start = old_start + adjustment_start

            relevant_diff_lines = max(0, old_length - 7)
            adjusted_end = adjusted_start + relevant_diff_lines

            changes.append((current_file, adjusted_start, adjusted_end))

    return changes
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::3
Filepath: moatless\benchmark\utils.py
Content:
def compare_patches(expected_patch, actual_patch):
    expected_diffs = get_diff_lines(expected_patch)
    actual_diffs = get_diff_lines(actual_patch)

    expected_files = set()
    file_hits = set()
    line_hits = 0

    for patch_diff in expected_diffs:
        change_file, change_start, change_end = patch_diff

        for actual_diff in actual_diffs:
            actual_change_file, actual_change_start, actual_change_end = actual_diff
            expected_files.add(change_file)
            if change_file == actual_change_file:
                file_hits.add(change_file)
                if (
                    change_start >= actual_change_start
                    and change_end <= actual_change_end
                ):
                    line_hits += 1
                    continue

    return len(expected_files) - len(file_hits), len(expected_diffs) - line_hits


def create_file_spans_from_patch(repo_dir: str, patch: str) -> list[FileWithSpans]:
    repository = FileRepository(repo_dir)
    files_with_spans = []
    for file_path, span_ids in get_file_spans_from_patch(repository, patch).items():
        file_with_spans = FileWithSpans(
            file_path=file_path,
            span_ids=span_ids,
        )
        files_with_spans.append(file_with_spans)

    return files_with_spans
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::4
Filepath: moatless\benchmark\utils.py
Content:
def get_file_spans_from_patch(
    repository: FileRepository, patch: str
) -> dict[str, list[str]]:
    expected_diff_lines = get_diff_lines(patch)
    expected_files_with_spans = {}

    for diff_line in expected_diff_lines:
        file = repository.get_file(diff_line[0])

        if file is None or file.module is None:
            continue

        if file.file_path not in expected_files_with_spans:
            expected_files_with_spans[file.file_path] = []

        spans = file.module.find_spans_by_line_numbers(diff_line[1], diff_line[2])
        for span in spans:
            if span.span_id not in expected_files_with_spans[file.file_path]:
                expected_files_with_spans[file.file_path].append(span.span_id)
    return expected_files_with_spans
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::5
Filepath: moatless\benchmark\utils.py
Content:
def get_files_from_patch(patch: str) -> list[str]:
    diff_lines = get_diff_lines(patch)
    return [diff_line[0] for diff_line in diff_lines]


def file_spans_to_dict(files_with_spans: list[FileWithSpans]) -> dict[str, list[str]]:
    span_dict = {}
    if not files_with_spans:
        return span_dict

    for file_with_spans in files_with_spans:
        if file_with_spans.file_path not in span_dict:
            span_dict[file_with_spans.file_path] = []

        for span_id in file_with_spans.span_ids:
            if span_id not in span_dict[file_with_spans.file_path]:
                span_dict[file_with_spans.file_path].append(span_id)
    return span_dict
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::6
Filepath: moatless\benchmark\utils.py
Content:
def get_missing_files(
    expected_files_with_spans: dict[str, list[str]],
    actual_files_with_spans: dict[str, list[str]],
) -> list[str]:
    misses = list(expected_files_with_spans.keys())
    for actual_file in actual_files_with_spans:
        if actual_file in misses:
            misses.remove(actual_file)
    return misses


def get_missing_spans(
    expected_files_with_spans: dict[str, list[str]],
    actual_files_with_spans: dict[str, list[str]],
) -> dict[str, list[str]]:
    misses = {}
    for expected_file, span_ids in expected_files_with_spans.items():
        if expected_file not in actual_files_with_spans:
            misses[expected_file] = span_ids
            continue

        for span_id in span_ids:
            if span_id not in actual_files_with_spans[expected_file]:
                if expected_file not in misses:
                    misses[expected_file] = []
                misses[expected_file].append(span_id)

    return misses
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::7
Filepath: moatless\benchmark\utils.py
Content:
def calculate_estimated_context_window(instance, results):
    patch_diffs = get_diff_lines(instance["patch"])
    expected_changes = []

    for patch_diff in patch_diffs:
        change_file, change_start, change_end = patch_diff
        expected_changes.append(
            {
                "file_path": change_file,
                "start_line": change_start,
                "end_line": change_end,
                "closest_match_context_window": None,
                "closest_match_lines": None,
                "position": None,
                "distance": None,
                "context_window": None,
            }
        )

    sum_tokens = 0

    for i, result in enumerate(results):
        sum_tokens += result.tokens
        for change in expected_changes:
            if result.file_path == change["file_path"]:
                if (
                    result.start_line - 1 <= change["start_line"]
                    and result.end_line + 1 >= change["end_line"]
                ):
                    change["distance"] = result.distance
                    change["context_window"] = sum_tokens
                    change["position"] = i

                    if all(
                        context["context_window"] is not None
                        for context in expected_changes
                    ):
                        return expected_changes, sum_tokens
                else:
                    closest_match_lines = change.get("closest_match_lines")
                    if (
                        not closest_match_lines
                        or abs(result.start_line - change["start_line"])
                        < abs(closest_match_lines[0] - change["start_line"])
                    ) or (
                        abs(result.end_line - change["end_line"])
                        == abs(closest_match_lines[0] - change["end_line"])
                    ):
                        change["closest_match_lines"] = (
                            result.start_line,
                            result.end_line,
                        )
                        change["closest_match_context_window"] = sum_tokens

    return expected_changes, sum_tokens
--------------------------------------------------------------------------------
Chunk ID: benchmark/utils.py::8
Filepath: moatless\benchmark\utils.py
Content:
def get_total_cost(trace_id):
    try:
        import langfuse
    except ImportError:
        logger.info("Langfuse not installed, can't get total cost")
        return 0

    langfuse = langfuse.Langfuse()
    trace = langfuse.get_trace(trace_id)

    return trace.total_cost


def trace_metadata(instance_id: str, session_id: str, trace_name: str):
    date_time_str = time.strftime("%Y%m%d-%H%M%S")
    trace_id = f"coder_{instance_id}_{date_time_str}"
    return {
        "session_id": session_id,
        "name": trace_name,
        "trace": trace_name,
        "trace_id": trace_id,
        "tags": [instance_id],
    }
--------------------------------------------------------------------------------
Chunk ID: codeblocks/__init__.py::1
Filepath: moatless\codeblocks\__init__.py
Content:
from moatless.codeblocks.codeblocks import CodeBlock, CodeBlockType
from moatless.codeblocks.parser.create import create_parser
from moatless.codeblocks.parser.java import JavaParser
from moatless.codeblocks.parser.parser import CodeParser
from moatless.codeblocks.parser.python import PythonParser


def supports_codeblocks(path: str):
    return path.endswith(".py")


def get_parser_by_path(file_path: str) -> CodeParser | None:
    if file_path.endswith(".py"):
        return PythonParser()
    elif file_path.endswith(".java"):
        return JavaParser()
    else:
        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::1
Filepath: moatless\codeblocks\codeblocks.py
Content:
import re
from enum import Enum
from typing import Optional

from pydantic import BaseModel, ConfigDict, Field, model_validator, field_validator
from typing_extensions import deprecated

from moatless.codeblocks.parser.comment import get_comment_symbol
from moatless.utils.colors import Colors

BlockPath = list[str]


class SpanMarker(Enum):
    TAG = 1
    COMMENT = 2


class CodeBlockTypeGroup(str, Enum):
    STRUCTURE = "Structures"
    IMPLEMENTATION = "Implementation"
    IMPORT = "Imports"

    BLOCK_DELIMITER = "BlockDelimiter"
    SPACE = "Space"

    COMMENT = "Comment"

    ERROR = "Error"
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::2
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlockType(Enum):
    MODULE = (
        "Module",
        CodeBlockTypeGroup.STRUCTURE,
    )  # TODO: Module shouldn't be a STRUCTURE
    CLASS = ("Class", CodeBlockTypeGroup.STRUCTURE)
    FUNCTION = ("Function", CodeBlockTypeGroup.STRUCTURE)

    # TODO: Remove and add sub types to functions and classes
    CONSTRUCTOR = ("Constructor", CodeBlockTypeGroup.STRUCTURE)
    TEST_SUITE = ("TestSuite", CodeBlockTypeGroup.STRUCTURE)
    TEST_CASE = ("TestCase", CodeBlockTypeGroup.STRUCTURE)

    IMPORT = ("Import", CodeBlockTypeGroup.IMPORT)

    EXPORT = ("Export", CodeBlockTypeGroup.IMPLEMENTATION)
    COMPOUND = ("Compound", CodeBlockTypeGroup.IMPLEMENTATION)
    # Dependent clauses are clauses that are dependent on another compound statement and can't be shown on their own
    DEPENDENT_CLAUSE = ("DependentClause", CodeBlockTypeGroup.IMPLEMENTATION)
    ASSIGNMENT = ("Assignment", CodeBlockTypeGroup.IMPLEMENTATION)
    CALL = ("Call", CodeBlockTypeGroup.IMPLEMENTATION)
    STATEMENT = ("Statement", CodeBlockTypeGroup.IMPLEMENTATION)

    CODE = ("Code", CodeBlockTypeGroup.IMPLEMENTATION)

    # TODO: Incorporate in code block?
    BLOCK_DELIMITER = ("BlockDelimiter", CodeBlockTypeGroup.BLOCK_DELIMITER)

    # TODO: Remove as it's just to fill upp spaces at the end of the file?
    SPACE = ("Space", CodeBlockTypeGroup.SPACE)

    COMMENT = ("Comment", CodeBlockTypeGroup.COMMENT)
    COMMENTED_OUT_CODE = (
        "Placeholder",
        CodeBlockTypeGroup.COMMENT,
    )  # TODO: Replace to PlaceholderComment

    ERROR = ("Error", CodeBlockTypeGroup.ERROR)

    def __init__(self, value: str, group: CodeBlockTypeGroup):
        self._value_ = value
        self.group = group
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::3
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlockType(Enum):

    @classmethod
    def from_string(cls, tag: str) -> Optional["CodeBlockType"]:
        if not tag.startswith("definition"):
            return None

        tag_to_block_type = {
            "definition.assignment": cls.ASSIGNMENT,
            "definition.block_delimiter": cls.BLOCK_DELIMITER,
            "definition.call": cls.CALL,
            "definition.class": cls.CLASS,
            "definition.code": cls.CODE,
            "definition.comment": cls.COMMENT,
            "definition.compound": cls.COMPOUND,
            "definition.constructor": cls.CONSTRUCTOR,
            "definition.dependent_clause": cls.DEPENDENT_CLAUSE,
            "definition.error": cls.ERROR,
            "definition.export": cls.EXPORT,
            "definition.function": cls.FUNCTION,
            "definition.import": cls.IMPORT,
            "definition.module": cls.MODULE,
            "definition.statement": cls.STATEMENT,
            "definition.test_suite": cls.TEST_SUITE,
            "definition.test_case": cls.TEST_CASE,
        }
        return tag_to_block_type.get(tag)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::4
Filepath: moatless\codeblocks\codeblocks.py
Content:
NON_CODE_BLOCKS = [
    CodeBlockType.BLOCK_DELIMITER,
    CodeBlockType.COMMENT,
    CodeBlockType.COMMENTED_OUT_CODE,
    CodeBlockType.EXPORT,
    CodeBlockType.IMPORT,
    CodeBlockType.ERROR,
    CodeBlockType.SPACE,
]

INDEXED_BLOCKS = [
    CodeBlockType.FUNCTION,
    CodeBlockType.CLASS,
    CodeBlockType.TEST_SUITE,
    CodeBlockType.TEST_CASE,
]


@deprecated("Use BlockSpans to define code block visibility instead")
class PathTree(BaseModel):
    show: bool = Field(default=False, description="Show the block and all sub blocks.")
    tree: dict[str, "PathTree"] = Field(default_factory=dict)

    @staticmethod
    def from_block_paths(block_paths: list[BlockPath]) -> "PathTree":
        tree = PathTree()
        for block_path in block_paths:
            tree.add_to_tree(block_path)

        return tree

    def child_tree(self, key: str) -> Optional["PathTree"]:
        return self.tree.get(key, None)

    def merge(self, other: "PathTree"):
        if other.show:
            self.show = True

        for key, value in other.tree.items():
            if key not in self.tree:
                self.tree[key] = PathTree()
            self.tree[key].merge(value)

    def extend_tree(self, paths: list[list[str]]):
        for path in paths:
            self.add_to_tree(path)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::5
Filepath: moatless\codeblocks\codeblocks.py
Content:
@deprecated("Use BlockSpans to define code block visibility instead")
class PathTree(BaseModel):

    def add_to_tree(self, path: list[str]):
        if path is None:
            return

        if len(path) == 0:
            self.show = True
            return

        if len(path) == 1:
            if path[0] not in self.tree:
                self.tree[path[0]] = PathTree(show=True)
            else:
                self.tree[path[0]].show = True

            return

        if path[0] not in self.tree:
            self.tree[path[0]] = PathTree(show=False)

        self.tree[path[0]].add_to_tree(path[1:])
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::6
Filepath: moatless\codeblocks\codeblocks.py
Content:
class ReferenceScope(str, Enum):
    EXTERNAL = "external"
    DEPENDENCY = "dependency"  # External dependency
    FILE = "file"  # File in repository
    PROJECT = "project"
    CLASS = "class"
    LOCAL = "local"
    GLOBAL = "global"


class RelationshipType(str, Enum):
    UTILIZES = "utilizes"
    USES = "uses"
    DEFINED_BY = "defined_by"
    IS_A = "is_a"
    PROVIDES = "provides"
    IMPORTS = "imports"
    CALLS = "calls"
    DEPENDENCY = "dependency"
    TYPE = "type"
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::7
Filepath: moatless\codeblocks\codeblocks.py
Content:
class Relationship(BaseModel):
    scope: ReferenceScope = Field(description="The scope of the reference.")
    identifier: Optional[str] = Field(default=None, description="ID")
    type: RelationshipType = Field(
        default=RelationshipType.USES, description="The type of the reference."
    )
    external_path: list[str] = Field(
        default=[], description="The path to the referenced parent code block."
    )
    resolved_path: list[str] = Field(
        default=[], description="The path to the file with the referenced code block."
    )
    path: list[str] = Field(
        default=[], description="The path to the referenced code block."
    )

    @classmethod
    @model_validator(mode="before")
    def validate_path(cls, values):
        external_path = values.get("external_path")
        path = values.get("path")
        if not external_path and not path:
            raise ValueError("Cannot create Reference without external_path or path.")
        return values

    def __hash__(self):
        return hash((self.scope, tuple(self.path)))

    def __eq__(self, other):
        return (self.scope, self.path) == (other.scope, other.path)

    def full_path(self):
        return self.external_path + self.path

    def __str__(self):
        start_node = self.identifier if self.identifier else ""

        end_node = ""
        if self.external_path:
            end_node = "/".join(self.external_path)
        if self.path:
            if self.external_path:
                end_node += "/"
            end_node += ".".join(self.path)

        return f"({start_node})-[:{self.type.name} {{scope: {self.scope.value}}}]->({end_node})"
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::8
Filepath: moatless\codeblocks\codeblocks.py
Content:
class Parameter(BaseModel):
    identifier: str = Field(description="The identifier of the parameter.")
    type: Optional[str] = Field(description="The type of the parameter.")


class SpanType(str, Enum):
    INITATION = "init"
    DOCUMENTATION = "docs"
    IMPLEMENTATION = "impl"


class BlockSpan(BaseModel):
    span_id: str = Field()
    span_type: SpanType = Field(description="Type of span.")
    start_line: int = Field(description="Start line of the span.")
    end_line: int = Field(description="End line of the span.")

    initiating_block: "CodeBlock" = Field(
        default=None,
        description="The block that initiated the span.",
    )

    @property
    def block_type(self):
        return self.initiating_block.type

    # TODO: Remove
    visible: bool = Field(default=True, description="If the span should be visible.")

    index: int = 0

    parent_block_path: BlockPath = Field(
        default=None,
        description="Path to the parent block of the span.",
    )

    is_partial: bool = Field(
        default=False,
        description="If the span is covering a partial part of the parent block.",
    )

    block_paths: list[BlockPath] = Field(
        default=[],
        description="Block paths that should be shown when the span is shown.",
    )

    tokens: int = Field(default=0, description="Number of tokens in the span.")

    def __str__(self):
        return f"{self.span_id} ({self.span_type.value}, {self.tokens} tokens)"

    def get_first_child_block_path(self):
        for block_path in self.block_paths:
            if len(block_path) == len(self.parent_block_path):
                continue
            return block_path


class ValidationError(BaseModel):
    error: str
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::9
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):
    content: str
    type: CodeBlockType
    identifier: Optional[str] = None
    parameters: list[Parameter] = []  # TODO: Move to Function sub class
    relationships: list[Relationship] = []
    span_ids: set[str] = set()
    belongs_to_span: BlockSpan | None = None
    content_lines: list[str] = []
    start_line: int = 0
    end_line: int = 0
    properties: dict = {}
    pre_code: str = ""
    pre_lines: int = 0
    indentation: str = ""
    tokens: int = 0
    children: list["CodeBlock"] = []
    validation_errors: list[ValidationError] = []
    parent: Optional["CodeBlock"] = None
    previous: Optional["CodeBlock"] = None
    next: Optional["CodeBlock"] = None

    model_config = ConfigDict(arbitrary_types_allowed=True)

    @classmethod
    @field_validator("type", mode="before")
    def validate_type(cls, v):
        if v is None:
            raise ValueError("Cannot create CodeBlock without type.")
        return v

    def __init__(self, **data):
        super().__init__(**data)
        for child in self.children:
            child.parent = self

        if self.pre_code and not re.match(r"^[ \n\\]*$", self.pre_code):
            raise ValueError(
                f"Failed to parse code block with type {self.type} and content `{self.content}`. "
                f"Expected pre_code to only contain spaces and line breaks. Got `{self.pre_code}`"
            )

        if self.pre_code and not self.indentation and not self.pre_lines:
            pre_code_lines = self.pre_code.split("\n")
            self.pre_lines = len(pre_code_lines) - 1
            if self.pre_lines > 0:
                self.indentation = pre_code_lines[-1]
            else:
                self.indentation = self.pre_code

        self.content_lines = self.content.split("\n")
        # if self.indentation and self.pre_lines:
        #    self.content_lines[1:] = [line[len(self.indentation):] for line in self.content_lines[1:]]

    def last(self):
        if self.next:
            return self.next.last()
        return self

    def insert_child(self, index: int, child: "CodeBlock"):
        if index == 0 and self.children[0].pre_lines == 0:
            self.children[0].pre_lines = 1

        self.children.insert(index, child)
        child.parent = self

    def insert_children(self, index: int, children: list["CodeBlock"]):
        for child in children:
            self.insert_child(index, child)
            index += 1

    def append_child(self, child: "CodeBlock"):
        self.children.append(child)
        self.span_ids.update(child.span_ids)
        child.parent = self

    def append_children(self, children: list["CodeBlock"]):
        for child in children:
            self.append_child(child)

    def replace_children(
        self, start_index: int, end_index: int, children: list["CodeBlock"]
    ):
        self.children = (
            self.children[:start_index] + children + self.children[end_index:]
        )
        for child in children:
            child.parent = self

    def replace_child(self, index: int, child: "CodeBlock"):
        # TODO: Do a proper update of everything when replacing child blocks
        child.pre_code = self.children[index].pre_code
        child.pre_lines = self.children[index].pre_lines
        self.sync_indentation(self.children[index], child)

        self.children[index] = child
        child.parent = self

    def remove_child(self, index: int):
        del self.children[index]
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::10
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def sync_indentation(self, original_block: "CodeBlock", updated_block: "CodeBlock"):
        original_indentation_length = len(original_block.indentation) + len(
            self.indentation
        )
        updated_indentation_length = len(updated_block.indentation) + len(
            updated_block.parent.indentation
        )

        # To handle separate code blocks provdided out of context
        if (
            original_indentation_length == updated_indentation_length
            and len(updated_block.indentation) == 0
        ):
            updated_block.indentation = " " * original_indentation_length

        elif original_indentation_length > updated_indentation_length:
            additional_indentation = " " * (
                original_indentation_length - updated_indentation_length
            )
            updated_block.add_indentation(additional_indentation)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::11
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def replace_by_path(self, path: list[str], new_block: "CodeBlock"):
        if not path:
            return

        for i, child in enumerate(self.children):
            if child.identifier == path[0]:
                if len(path) == 1:
                    self.replace_child(i, new_block)
                    return
                else:
                    child.replace_by_path(path[1:], new_block)

    def __str__(self):
        return self.to_string()

    def to_string(self):
        return self._to_string()

    def sum_tokens(self):
        tokens = self.tokens
        tokens += sum([child.sum_tokens() for child in self.children])
        return tokens

    def get_all_child_blocks(self) -> list["CodeBlock"]:
        blocks = []
        for child in self.children:
            blocks.append(child)
            blocks.extend(child.get_all_child_blocks())
        return blocks

    def get_children(
        self, exclude_blocks: list[CodeBlockType] = None
    ) -> list["CodeBlock"]:
        if exclude_blocks is None:
            exclude_blocks = []
        return [child for child in self.children if child.type not in exclude_blocks]

    def show_related_spans(
        self,
        span_id: Optional[str] = None,  # TODO: Set max tokens to show
    ):
        related_spans = self.find_related_spans(span_id)
        for span in related_spans:
            span.visible = True

    def has_visible_children(self):
        for child in self.children:
            if child.is_visible:
                return True

            if child.has_visible_children():
                return True

        return False

    @property
    def is_visible(self):
        return self.belongs_to_span and self.belongs_to_span.visible
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::12
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def _to_string(self) -> str:
        contents = ""

        if self.pre_lines:
            contents += "\n" * (self.pre_lines - 1)
            for i, line in enumerate(self.content_lines):
                if i == 0 and line:
                    contents += "\n" + self.indentation + line
                elif line:
                    contents += "\n" + line
                else:
                    contents += "\n"
        else:
            contents += self.pre_code + self.content

        for _i, child in enumerate(self.children):
            contents += child._to_string()

        return contents
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::13
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def _build_path_tree(
        self, block_paths: list[str], include_references: bool = False
    ):
        path_tree = PathTree()

        for block_path in block_paths:
            if block_path:
                path = block_path.split(".")
                if include_references:
                    block = self.find_by_path(path)
                    if block:
                        if self.type == CodeBlockType.CLASS:
                            references = [
                                self._fix_reference_path(reference)
                                for reference in self.get_all_relationships(
                                    exclude_types=[
                                        CodeBlockType.FUNCTION,
                                        CodeBlockType.TEST_CASE,
                                    ]
                                )
                                if reference
                                and reference.scope != ReferenceScope.EXTERNAL
                            ]  # FIXME skip _fix_reference_path?
                        else:
                            references = [
                                self._fix_reference_path(reference)
                                for reference in self.get_all_relationships()
                                if reference
                                and reference.scope != ReferenceScope.EXTERNAL
                            ]  # FIXME skip _fix_reference_path?

                        for ref in references:
                            path_tree.add_to_tree(ref.path)

                path_tree.add_to_tree(path)
            elif block_path == "":
                path_tree.show = True

        return path_tree
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::14
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def to_tree(
        self,
        indent: int = 0,
        current_span: BlockSpan | None = None,
        highlight_spans: set[str] | None = None,
        only_identifiers: bool = False,
        show_full_path: bool = True,
        show_tokens: bool = False,
        show_spans: bool = False,
        debug: bool = False,
        exclude_not_highlighted: bool = False,
        include_line_numbers: bool = False,
        include_types: list[CodeBlockType] | None = None,
        include_parameters: bool = False,
        include_block_delimiters: bool = False,
        include_references: bool = False,
        include_merge_history: bool = False,
    ):
        if not include_merge_history and self.type == CodeBlockType.BLOCK_DELIMITER:
            return ""

        indent_str = " " * indent

        highlighted = False

        child_tree = ""
        for _i, child in enumerate(self.children):
            if child.belongs_to_span and (
                not current_span
                or current_span.span_id != child.belongs_to_span.span_id
            ):
                current_span = child.belongs_to_span

                highlighted = highlight_spans is None or (
                    current_span is not None and current_span.span_id in highlight_spans
                )

                if show_spans:
                    color = Colors.WHITE if highlighted else Colors.GRAY
                    child_tree += f"{indent_str} {indent} {color}Span: {current_span}{Colors.RESET}\n"

            if (
                exclude_not_highlighted
                and not highlighted
                and not child.has_any_span(highlight_spans)
            ):
                continue

            child_tree += child.to_tree(
                indent=indent + 1,
                current_span=current_span,
                highlight_spans=highlight_spans,
                exclude_not_highlighted=exclude_not_highlighted,
                only_identifiers=only_identifiers,
                show_full_path=show_full_path,
                show_tokens=show_tokens,
                debug=debug,
                show_spans=show_spans,
                include_line_numbers=include_line_numbers,
                include_types=include_types,
                include_parameters=include_parameters,
                include_block_delimiters=include_block_delimiters,
                include_references=include_references,
                include_merge_history=include_merge_history,
            )

        is_visible = not highlight_spans or self.belongs_to_any_span(highlight_spans)
        extra = ""
        if show_tokens:
            extra += f" ({self.tokens} tokens)"

        if include_references and self.relationships:
            extra += " references: " + ", ".join(
                [str(ref) for ref in self.relationships]
            )

        content = (
            Colors.YELLOW
            if is_visible
            else Colors.GRAY
            + (self.content.strip().replace("\n", "\\n") or "")
            + Colors.RESET
        )

        if self.identifier:
            if only_identifiers:
                content = ""
            content += Colors.GREEN if is_visible else Colors.GRAY
            if include_parameters and self.parameters:
                content += f"{self.identifier}({', '.join([param.identifier for param in self.parameters])})"
            elif show_full_path:
                content += f" ({self.path_string()})"
            else:
                content += f" ({self.identifier})"

            content += Colors.RESET

        if include_line_numbers:
            extra += f" {self.start_line}-{self.end_line}"

        if debug and self.properties:
            extra += f" properties: {self.properties}"

        if include_merge_history and self.merge_history:
            extra += " merge_history: " + ", ".join(
                [str(action) for action in self.merge_history]
            )

        type_color = Colors.BLUE if is_visible else Colors.GRAY
        return f"{indent_str} {indent} {type_color}{self.type.value}{Colors.RESET} `{content}`{extra}{Colors.RESET}\n{child_tree}"
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::15
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def _to_prompt_string(
        self,
        show_span_id: bool = False,
        span_marker: SpanMarker = SpanMarker.COMMENT,
        show_line_numbers: bool = False,
    ) -> str:
        contents = ""

        if show_span_id:
            contents += "\n\n"
            if span_marker == SpanMarker.COMMENT:
                span_comment = self.create_comment(
                    f"span_id: {self.belongs_to_span.span_id}"
                )
                contents += f"{self.indentation}{span_comment}"
            elif span_marker == SpanMarker.TAG:
                contents += f"\n<span id='{self.belongs_to_span.span_id}'>"

            if not self.pre_lines:
                contents += "\n"

        def print_line(line_number):
            if not show_line_numbers:
                return ""
            return str(line_number).ljust(6)

        # Just to write out the first line number when there are no pre_lines on first block
        if self.parent.type == CodeBlockType.MODULE and self.parent.children[0] == self:
            contents += print_line(self.start_line)

        if self.pre_lines:
            for i in range(self.pre_lines):
                contents += "\n"
                contents += print_line(self.start_line - self.pre_lines + i + 1)

        contents += self.indentation + self.content_lines[0]

        for i, line in enumerate(self.content_lines[1:]):
            contents += "\n"
            contents += print_line(self.start_line + i + 1)
            contents += line

        return contents
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::16
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def to_prompt(
        self,
        span_ids: set[str] | None = None,
        start_line: Optional[int] = None,
        end_line: Optional[int] = None,
        show_outcommented_code: bool = True,
        outcomment_code_comment: str = "...",
        show_span_id: bool = False,
        current_span_id: Optional[str] = None,
        show_line_numbers: bool = False,
        exclude_block_types: list[CodeBlockType] | None = None,
        include_block_types: list[CodeBlockType] | None = None,
    ):
        contents = ""

        has_outcommented_code = False
        for _i, child in enumerate(self.children):
            show_child = True

            if exclude_block_types and child.type in exclude_block_types:
                show_child = False

            if show_child and span_ids:
                show_child = child.has_any_span(span_ids)

            if show_child and include_block_types:
                show_child = child.has_blocks_with_types(include_block_types)

            if show_child and start_line and end_line:
                show_child = child.has_lines(
                    start_line, end_line
                ) or child.is_within_lines(start_line, end_line)

            if show_child:
                if has_outcommented_code:
                    contents += child.create_commented_out_block(
                        outcomment_code_comment
                    ).to_string()

                has_outcommented_code = False

                show_new_span_id = (
                    show_span_id
                    and child.belongs_to_span
                    and (
                        not current_span_id
                        or current_span_id != child.belongs_to_span.span_id
                    )
                )
                if child.belongs_to_span:
                    current_span_id = child.belongs_to_span.span_id

                contents += child._to_prompt_string(
                    show_span_id=show_new_span_id, show_line_numbers=show_line_numbers
                )
                contents += child.to_prompt(
                    span_ids=span_ids,
                    start_line=start_line,
                    end_line=end_line,
                    show_outcommented_code=show_outcommented_code,
                    outcomment_code_comment=outcomment_code_comment,
                    show_span_id=show_span_id,
                    current_span_id=current_span_id,
                    show_line_numbers=show_line_numbers,
                    exclude_block_types=exclude_block_types,
                    include_block_types=include_block_types,
                )
            elif show_outcommented_code and child.type not in [
                CodeBlockType.COMMENT,
                CodeBlockType.COMMENTED_OUT_CODE,
            ]:
                has_outcommented_code = True

        if (
            outcomment_code_comment
            and has_outcommented_code
            and child.type
            not in [
                CodeBlockType.COMMENT,
                CodeBlockType.COMMENTED_OUT_CODE,
                CodeBlockType.SPACE,
            ]
        ):
            contents += "\n.    " if show_line_numbers else "\n"
            contents += child.create_commented_out_block(
                outcomment_code_comment
            ).to_string()
            contents += "\n"

        return contents
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::17
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def __eq__(self, other):
        if not isinstance(other, CodeBlock):
            return False

        return self.full_path() == other.full_path()

    def find_block_by_type(self, block_type: CodeBlockType) -> Optional["CodeBlock"]:
        if self.type == block_type:
            return self

        for child in self.children:
            block = child.find_block_by_type(block_type)
            if block:
                return block

        return None

    def find_type_in_parents(self, block_type: CodeBlockType) -> Optional["CodeBlock"]:
        if not self.parent:
            return None

        if self.parent.type == block_type:
            return self.parent

        if self.parent:
            return self.parent.find_type_in_parents(block_type)

        return None

    def structure_block(self):
        if self.type.group == CodeBlockTypeGroup.STRUCTURE:
            return self

        if self.parent:
            return self.parent.structure_block()

        return None

    def find_type_group_in_parents(
        self, block_type_group: CodeBlockTypeGroup
    ) -> Optional["CodeBlock"]:
        if not self.parent:
            return None

        if self.parent.type.group == block_type_group:
            return self.parent

        if self.parent:
            return self.parent.find_type_group_in_parents(block_type_group)

        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::18
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_spans_by_line_numbers(
        self, start_line: int, end_line: int = None
    ) -> list[BlockSpan]:
        spans = []
        for child in self.children:
            if end_line is None:
                end_line = start_line

            if child.end_line < start_line:
                continue

            if child.start_line > end_line:
                return spans

            if (
                child.belongs_to_span
                and child.belongs_to_span.span_id not in spans
                and (
                    not child.children
                    or child.start_line >= start_line
                    and child.end_line <= end_line
                    or child.start_line == start_line
                    or child.end_line == end_line
                )
            ):
                spans.append(child.belongs_to_span)

            child_spans = child.find_spans_by_line_numbers(start_line, end_line)
            for span in child_spans:
                if span not in spans:
                    spans.append(span)

        return spans
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::19
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def dict(self, **kwargs):
        # TODO: Add **kwargs to dict call
        return super().dict(exclude={"parent", "merge_history"})

    def path_string(self):
        return ".".join(self.full_path())

    def full_path(self):
        path = []
        if self.parent:
            path.extend(self.parent.full_path())

        if self.identifier:
            path.append(self.identifier)

        return path

    @property
    def module(self) -> "Module":  # noqa: F821
        if self.parent:
            return self.parent.module
        return self

    @deprecated("Use codeblock.module")
    def root(self) -> "Module":  # noqa: F821
        return self.module

    def get_blocks(
        self, has_identifier: bool, include_types: list[CodeBlockType] | None = None
    ) -> list["CodeBlock"]:
        blocks = [self]

        for child in self.children:
            if has_identifier and not child.identifier:
                continue

            if include_types and child.type not in include_types:
                continue

            blocks.extend(child.get_indexable_blocks())
        return blocks
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::20
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_reference(self, ref_path: [str]) -> Relationship | None:
        for child in self.children:
            if child.type == CodeBlockType.IMPORT:
                for reference in child.relationships:
                    if (
                        reference.path[len(reference.path) - len(ref_path) :]
                        == ref_path
                    ):
                        return reference

            child_path = child.full_path()

            if child_path[len(child_path) - len(ref_path) :] == ref_path:
                if self.type == CodeBlockType.CLASS:
                    return Relationship(scope=ReferenceScope.CLASS, path=child_path)
                if self.type == CodeBlockType.MODULE:
                    return Relationship(scope=ReferenceScope.GLOBAL, path=child_path)

                return Relationship(scope=ReferenceScope.LOCAL, path=child_path)

        if self.parent:
            reference = self.parent.find_reference(ref_path)
            if reference:
                return reference

        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::21
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def get_all_relationships(
        self, exclude_types: list[CodeBlockType] = None
    ) -> list[Relationship]:
        if exclude_types is None:
            exclude_types = []
        references = []
        references.extend(self.relationships)
        for childblock in self.children:
            if not exclude_types or childblock.type not in exclude_types:
                references.extend(
                    childblock.get_all_relationships(exclude_types=exclude_types)
                )

        return references

    def is_complete(self):
        if self.type == CodeBlockType.COMMENTED_OUT_CODE:
            return False
        return all(child.is_complete() for child in self.children)

    def find_errors(self) -> list["CodeBlock"]:
        errors = []

        if self.children:
            for child in self.children:
                errors.extend(child.find_errors())

        if self.type == CodeBlockType.ERROR:
            errors.append(self)

        return errors

    def find_validation_errors(self) -> list[ValidationError]:
        errors = []
        errors.extend(self.validation_errors)

        for child in self.children:
            errors.extend(child.find_validation_errors())

        return errors

    def create_commented_out_block(self, comment_out_str: str = "..."):
        return CodeBlock(
            type=CodeBlockType.COMMENTED_OUT_CODE,
            indentation=self.indentation,
            parent=self,
            pre_lines=1,
            content=self.create_comment(comment_out_str),
        )

    def create_comment_block(self, comment: str = "...", pre_lines: int = 1):
        return CodeBlock(
            type=CodeBlockType.COMMENT,
            indentation=self.indentation,
            parent=self,
            pre_lines=pre_lines,
            content=self.create_comment(comment),
        )

    def create_comment(self, comment: str) -> str:
        symbol = get_comment_symbol("python")  # FIXME: Derive language from Module
        return f"{symbol} {comment}"

    def add_indentation(self, indentation: str):
        if self.pre_lines:
            self.indentation += indentation

        # TODO: Find a more graceful way to solve multi line blocks
        if "\n" in self.content:
            lines = self.content.split("\n")
            content = lines[0]
            for line in lines[1:]:
                if line.startswith(" "):
                    content += "\n" + indentation + line
            self.content = content

        for child in self.children:
            child.add_indentation(indentation)

    def find_by_path(self, path: list[str]) -> Optional["CodeBlock"]:
        if path is None:
            return None

        if not path:
            return self

        for child in self.children:
            if child.identifier == path[0]:
                if len(path) == 1:
                    return child
                else:
                    return child.find_by_path(path[1:])

        return None

    def find_blocks_by_span_id(self, span_id: str) -> list["CodeBlock"]:
        blocks = []
        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:
            blocks.append(self)

        for child in self.children:
            # TODO: Optimize to just check relevant children (by mapping spans?
            blocks.extend(child.find_blocks_by_span_id(span_id))

        return blocks
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::22
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_last_before_span(
        self, span_id: str, last_before_span: Optional["CodeBlock"] = None
    ) -> Optional["CodeBlock"]:
        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:
            return last_before_span

        for child in self.children:
            if child.belongs_to_span and child.belongs_to_span.span_id == span_id:
                return last_before_span

            if child.belongs_to_span and child.belongs_to_span.span_id != span_id:
                last_before_span = child

            result = child.find_last_before_span(span_id, last_before_span)
            if result:
                return result

        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::23
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_first_by_span_id(self, span_id: str) -> Optional["CodeBlock"]:
        if self.belongs_to_span and self.belongs_to_span.span_id == span_id:
            return self

        for child in self.children:
            found = child.find_first_by_span_id(span_id)
            if found:
                return found

        return None

    def find_last_by_span_id(self, span_id: str) -> Optional["CodeBlock"]:
        for child in reversed(self.children):
            if child.belongs_to_span and child.belongs_to_span.span_id == span_id:
                return child

            found = child.find_last_by_span_id(span_id)
            if found:
                return found

        return None

    def has_any_block(self, blocks: list["CodeBlock"]) -> bool:
        for block in blocks:
            if block.full_path()[: len(self.full_path())] == self.full_path():
                return True
        return False

    def find_by_identifier(
        self,
        identifier: str,
        type: CodeBlockType | None = None,
        recursive: bool = False,
    ):
        for child in self.children:
            if child.identifier == identifier and (not type or child.type == type):
                return child

            if recursive:
                found = child.find_by_identifier(identifier, type, recursive)
                if found:
                    return found
        return None

    def find_blocks_with_identifier(self, identifier: str) -> list["CodeBlock"]:
        blocks = []
        for child_block in self.children:
            if child_block.identifier == identifier:
                blocks.append(child_block)
            blocks.extend(child_block.find_blocks_with_identifier(identifier))
        return blocks

    def find_incomplete_blocks_with_type(self, block_type: CodeBlockType):
        return self.find_incomplete_blocks_with_types([block_type])

    def find_incomplete_blocks_with_types(self, block_types: [CodeBlockType]):
        matching_blocks = []
        for child_block in self.children:
            if child_block.type in block_types and not child_block.is_complete():
                matching_blocks.append(child_block)

            if child_block.children:
                matching_blocks.extend(
                    child_block.find_incomplete_blocks_with_types(block_types)
                )

        return matching_blocks

    def find_blocks_with_types(
        self, block_types: list[CodeBlockType]
    ) -> list["CodeBlock"]:
        matching_blocks = []
        if self.type in block_types:
            matching_blocks.append(self)
        for child_block in self.children:
            matching_blocks.extend(
                child_block.find_blocks_with_types(block_types=block_types)
            )
        return matching_blocks

    def has_blocks_with_types(self, block_types: list[CodeBlockType]) -> bool:
        if self.type in block_types:
            return True
        for child_block in self.children:
            if child_block.has_blocks_with_types(block_types):
                return True
        return False

    def find_blocks_with_type(self, block_type: CodeBlockType) -> list["CodeBlock"]:
        return self.find_blocks_with_types([block_type])

    def find_first_by_start_line(self, start_line: int) -> Optional["CodeBlock"]:
        for child in self.children:
            if child.start_line >= start_line:
                return child

            if child.end_line >= start_line:
                if not child.children:
                    return child

                found = child.find_first_by_start_line(start_line)
                if found:
                    return found

        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::24
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_last_by_end_line(
        self, end_line: int, tokens: Optional[int] = None
    ) -> Optional["CodeBlock"]:
        last_child = None
        for child in self.children:
            if child.start_line > end_line or (tokens and child.tokens > tokens):
                return last_child

            if tokens:
                tokens -= child.tokens

            last_child = child

            if child.end_line > end_line:
                found = child.find_last_by_end_line(end_line, tokens=tokens)
                if found:
                    return found

        return None
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::25
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def find_closest_indexed_parent(self) -> Optional["CodeBlock"]:
        if self.is_indexed:
            return self

        if self.parent:
            return self.parent.find_closest_indexed_parent()

        return None

    def find_indexed_blocks(self):
        indexed_blocks = []
        for child in self.children:
            if child.is_indexed:
                indexed_blocks.append(child)
            indexed_blocks.extend(child.find_indexed_blocks())
        return indexed_blocks

    def get_indexed_blocks(self) -> list["CodeBlock"]:
        blocks = []
        for child in self.children:
            if child.is_indexed:
                blocks.append(child)

            blocks.extend(child.get_indexed_blocks())

        return blocks
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::26
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def line_witin_token_context(self, line_number: int, tokens: int) -> bool:
        if tokens <= 0:
            return False

        if self.end_line < line_number:
            if not self.next:
                return False
            if self.next.start_line > line_number:
                return True
            else:
                return self.next.line_witin_token_context(
                    line_number, tokens - self.tokens
                )
        else:
            if not self.previous:
                return False
            elif self.previous.end_line < line_number:
                return True
            else:
                return self.previous.line_witin_token_context(
                    line_number, tokens - self.tokens
                )

    def tokens_from_line(self, line_number: int) -> Optional[int]:
        if not self.previous or self.previous.end_line < line_number:
            return self.tokens

        return self.tokens + self.previous.tokens_from_line(line_number)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::27
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def last_block_until_line(self, line_number: int, tokens: int) -> "CodeBlock":
        if self.end_line < line_number:
            if (
                not self.next
                or self.next.start_line > line_number
                or self.next.tokens > tokens
            ):
                return self
            else:
                return self.next.last_block_until_line(
                    line_number, tokens - self.tokens
                )
        else:
            if (
                not self.previous
                or self.previous.end_line < line_number
                or self.next.tokens > tokens
            ):
                return self
            else:
                return self.previous.last_block_until_line(
                    line_number, tokens - self.tokens
                )
--------------------------------------------------------------------------------
Chunk ID: codeblocks/codeblocks.py::28
Filepath: moatless\codeblocks\codeblocks.py
Content:
class CodeBlock(BaseModel):

    def get_all_span_ids(self, include_self: bool = True) -> set[str]:
        span_ids = set()

        if include_self and self.belongs_to_span:
            span_ids.add(self.belongs_to_span.span_id)

        for child in self.children:
            span_ids.update(child.get_all_span_ids())

        return span_ids

    def has_span(self, span_id: str):
        return self.has_any_span({span_id})

    def has_any_span(self, span_ids: set[str]):
        all_span_ids = self.get_all_span_ids(include_self=False)
        return any([span_id in all_span_ids for span_id in span_ids])

    def belongs_to_any_span(self, span_ids: set[str]):
        return self.belongs_to_span and self.belongs_to_span.span_id in span_ids

    def has_lines(self, start_line: int, end_line: int):
        # Returns True if any part of the block is within the provided line range
        return not (self.end_line < start_line or self.start_line > end_line)

    def is_within_lines(self, start_line: int, end_line: int):
        return self.start_line >= start_line and self.end_line <= end_line

    def has_content(self, query: str, span_id: Optional[str] = None):
        if (
            self.content
            and query in self.content
            and (
                not span_id
                or (self.belongs_to_span and self.belongs_to_span.span_id == span_id)
            )
        ):
            return True

        if span_id and not self.has_span(span_id):
            return False

        return any(child.has_content(query, span_id) for child in self.children)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/module.py::1
Filepath: moatless\codeblocks\module.py
Content:
import logging
from typing import Optional

from networkx import DiGraph
from pydantic import (
    ConfigDict,
)

from moatless.codeblocks import CodeBlock, CodeBlockType
from moatless.codeblocks.codeblocks import BlockSpan, SpanType

logger = logging.getLogger(__name__)


class Module(CodeBlock):
    model_config = ConfigDict(arbitrary_types_allowed=True)

    file_path: Optional[str] = None
    content: str = None
    spans_by_id: dict[str, BlockSpan] = {}
    language: Optional[str] = None
    parent: CodeBlock | None = None

    _graph: DiGraph = None  # TODO: Move to central CodeGraph

    def __init__(self, **data):
        data.setdefault("type", CodeBlockType.MODULE)
        super().__init__(**data)

    def find_span_by_id(self, span_id: str) -> BlockSpan | None:
        return self.spans_by_id.get(span_id)

    def sum_tokens(self, span_ids: set[str] | None = None):
        tokens = self.tokens
        if span_ids:
            for span_id in span_ids:
                span = self.spans_by_id.get(span_id)
                if span:
                    tokens += span.tokens
            return tokens

        tokens += sum([child.sum_tokens() for child in self.children])
        return tokens
--------------------------------------------------------------------------------
Chunk ID: codeblocks/module.py::2
Filepath: moatless\codeblocks\module.py
Content:
class Module(CodeBlock):

    def show_spans(
        self,
        span_ids: list[str] | None = None,
        show_related: bool = False,
        max_tokens: int = 2000,
    ) -> bool:
        for span in self.spans_by_id.values():
            span.visible = False

        checked_span_ids = set()
        span_ids_to_check = []

        tokens = 0
        for span_id in span_ids:
            span = self.spans_by_id.get(span_id)
            if not span:
                return False

            tokens += span.tokens
            checked_span_ids.add(span_id)
            span_ids_to_check.append(span_id)
            span.visible = True

        if not show_related:
            return True

        # Add imports from module
        for span in self.spans.values():
            if (
                span.span_type == SpanType.INITATION
                and span.span_id not in checked_span_ids
            ):
                span_ids_to_check.append(span.span_id)

        while span_ids_to_check:
            span_id = span_ids_to_check.pop(0)
            related_spans = self.find_related_spans(span_id)

            logger.info(f"Related spans: {len(related_spans)} for {span_id}")

            # TODO: Go through priotiized related spans to make sure that the most relevant are added first
            # TODO: Verify span token size
            for span in related_spans:
                if span.tokens + tokens > max_tokens:
                    logger.info(
                        f"Max tokens reached: {span.tokens} + {tokens} > {max_tokens}"
                    )
                    return True

                span.visible = True
                tokens += span.tokens

                if span.span_id not in checked_span_ids:
                    checked_span_ids.add(span.span_id)
                    span_ids_to_check.append(span.span_id)

        logger.info(f"Max tokens reached {tokens} < {max_tokens}")

        return True
--------------------------------------------------------------------------------
Chunk ID: codeblocks/module.py::3
Filepath: moatless\codeblocks\module.py
Content:
class Module(CodeBlock):

    def find_related_span_ids(self, span_id: Optional[str] = None) -> set[str]:
        related_span_ids = set()

        blocks = self.find_blocks_by_span_id(span_id)
        for block in blocks:
            # Find successors (outgoing relationships)
            successors = list(self._graph.successors(block.path_string()))
            for succ in successors:
                node_data = self._graph.nodes[succ]
                if "block" in node_data:
                    span = node_data["block"].belongs_to_span
                    related_span_ids.add(span.span_id)

            # Find predecessors (incoming relationships)
            predecessors = list(self._graph.predecessors(block.path_string()))
            for pred in predecessors:
                node_data = self._graph.nodes[pred]
                if "block" in node_data:
                    span = node_data["block"].belongs_to_span
                    related_span_ids.add(span.span_id)

            # Always add parent class initation span
            if block.parent and block.parent.type == CodeBlockType.CLASS:
                related_span_ids.add(block.belongs_to_span.span_id)
                for class_child in block.parent.children:
                    if class_child.belongs_to_span.span_type == SpanType.INITATION:
                        related_span_ids.add(class_child.belongs_to_span.span_id)

        # Always add module initation span
        for span in self.spans_by_id.values():
            if (
                span.block_type == CodeBlockType.MODULE
                and span.span_type == SpanType.INITATION
            ):
                related_span_ids.add(span.span_id)

        return related_span_ids
--------------------------------------------------------------------------------
Chunk ID: parser/comment.py::1
Filepath: moatless\codeblocks\parser\comment.py
Content:
comment_symbols = {
    "ada": "--",
    "agda": "--",
    "apex": "//",
    "bash": "#",
    "beancount": ";",
    "capn proto": "#",
    "c": "//",
    "c++": "//",
    "c#": "//",
    "clojure": ";",
    "cmake": "#",
    "common lisp": ";",
    "css": "/* ",  # TDOO ... */
    "cuda": "//",
    "dart": "//",
    "d": "//",
    "dockerfile": "#",
    "dot": "//",
    "elixir": "#",
    "elm": "--",
    "emacs lisp": ";",
    "erb / ejs": "<%# ... %>",
    "erlang": "%",
    "fish": "#",
    "fortran": "!",
    "gitattributes": "#",
    "gitignore": "#",
    "gleam": "//",
    "go": "//",
    "graphql": "#",
    "haskell": "--",
    "html": "<!--",  # TODO:  ... -->
    "java": "//",
    "javascript": "//",
    "json5": "//",
    "julia": "#",
    "kotlin": "//",
    "latex": "%",
    "lua": "--",
    "make": "#",
    "motorola 68000 assembly": ";",
    "nix": "#",
    "objective-c": "//",
    "ocaml": "(*",  # TODO ... *)
    "pascal": "{",  # TODO ... }
    "perl": "#",
    "php": "//",
    "powershell": "#",
    "protocol buffers": "//",
    "python": "#",
    "racket": ";",
    "rego": "#",
    "restructuredtext": "..",
    "r": "#",
    "ruby": "#",
    "rust": "//",
    "scala": "//",
    "scheme": ";",
    "scss": "//",
    "s-expressions": ";",
    "sql": "--",
    "swift": "//",
    "toml": "#",
    "typescript": "//",
    "tsx": "//",
    "verilog": "//",
    "vhdl": "--",
    "vue": "<!-- ",  # TODO ... -->
    "yaml": "#",
    "zig": "//",
}


def get_comment_symbol(language):
    if language:
        return comment_symbols.get(language.lower(), None)
    return "#"
--------------------------------------------------------------------------------
Chunk ID: parser/create.py::1
Filepath: moatless\codeblocks\parser\create.py
Content:
from moatless.codeblocks.parser.parser import CodeParser
from moatless.codeblocks.parser.python import PythonParser
from moatless.codeblocks.parser.java import JavaParser


def is_supported(language: str) -> bool:
    return language and language in ["python", "java"]


def create_parser_by_ext(ext: str, **kwargs) -> CodeParser | None:
    if ext == ".py":
        return PythonParser(**kwargs)
    elif ext == ".java":
        return JavaParser(**kwargs)

    raise NotImplementedError(f"Extension {ext} is not supported.")


def create_parser(language: str, **kwargs) -> CodeParser | None:
    if language == "python":
        return PythonParser(**kwargs)
    elif language == "java":
        return JavaParser(**kwargs)

    raise NotImplementedError(f"Language {language} is not supported.")
--------------------------------------------------------------------------------
Chunk ID: parser/java.py::1
Filepath: moatless\codeblocks\parser\java.py
Content:
import tree_sitter_java as java
from tree_sitter import Language

from moatless.codeblocks.parser.parser import CodeParser


class JavaParser(CodeParser):
    def __init__(self, **kwargs):
        super().__init__(Language(java.language()), **kwargs)
        self.queries = []
        self.queries.extend(self._build_queries("java.scm"))
        self.gpt_queries = []
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::1
Filepath: moatless\codeblocks\parser\parser.py
Content:
import logging
import re
from collections.abc import Callable
from dataclasses import dataclass, field
from importlib import resources
from typing import Optional

import networkx as nx
from llama_index.core import get_tokenizer
from tree_sitter import Language, Node, Parser

from moatless.codeblocks.codeblocks import (
    BlockSpan,
    CodeBlock,
    CodeBlockType,
    CodeBlockTypeGroup,
    Parameter,
    ReferenceScope,
    Relationship,
    RelationshipType,
    SpanType,
)
from moatless.codeblocks.module import Module
from moatless.codeblocks.parser.comment import get_comment_symbol

commented_out_keywords = ["rest of the code", "existing code", "other code"]
child_block_types = ["ERROR", "block"]
module_types = ["program", "module"]

logger = logging.getLogger(__name__)


@dataclass
class NodeMatch:
    block_type: CodeBlockType = None
    identifier_node: Node = None
    first_child: Node = None
    last_child: Node = None
    check_child: Node = None
    parameters: list[tuple[Node, Node | None]] = field(default_factory=list)
    relationships: list[tuple[Node, str]] = field(default_factory=list)
    query: str = None


def _find_type(node: Node, type: str):
    for i, child in enumerate(node.children):
        if child.type == type:
            return i, child
    return None, None


def find_type(node: Node, types: list[str]):
    for child in node.children:
        if child.type in types:
            return child
    return None


def find_nested_type(node: Node, type: str, levels: int = -1):
    if levels == 0:
        return None
    if node.type == type:
        return node
    for child in node.children:
        found_node = find_nested_type(child, type, levels - 1)
        if found_node:
            return found_node
    return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::2
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:
    def __init__(
        self,
        language: Language,
        encoding: str = "utf8",
        max_tokens_in_span: int = 500,
        min_tokens_for_docs_span: int = 100,
        index_callback: Callable[[CodeBlock], None] | None = None,
        tokenizer: Callable[[str], list] | None = None,
        apply_gpt_tweaks: bool = False,
        debug: bool = False,
    ):
        try:
            self.tree_parser = Parser()
            self.tree_parser.language = language
            self.tree_language = language
        except Exception as e:
            logger.warning(f"Could not get parser for language {language}.")
            raise e
        self.apply_gpt_tweaks = apply_gpt_tweaks
        self.index_callback = index_callback
        self.debug = debug
        self.encoding = encoding
        self.gpt_queries = []
        self.queries = []

        # TODO: How to handle these in a thread safe way?
        self.spans_by_id = {}
        self.comments_with_no_span = []
        self._span_counter = {}
        self._previous_block = None

        # TODO: Move this to CodeGraph
        self._graph = None

        self.tokenizer = tokenizer or get_tokenizer()
        self._max_tokens_in_span = max_tokens_in_span
        self._min_tokens_for_docs_span = min_tokens_for_docs_span

    @property
    def language(self):
        pass

    def _extract_node_type(self, query: str):
        pattern = r"\(\s*(\w+)"
        match = re.search(pattern, query)
        if match:
            return match.group(1)
        else:
            return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::3
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def _build_queries(self, query_file: str):
        with (
            resources.files("moatless.codeblocks.parser.queries")
            .joinpath(query_file)
            .open() as file
        ):
            query_list = file.read().strip().split("\n\n")
            parsed_queries = []
            for i, query in enumerate(query_list):
                try:
                    node_type = self._extract_node_type(query)
                    parsed_queries.append(
                        (
                            f"{query_file}:{i+1}",
                            node_type,
                            self.tree_language.query(query),
                        )
                    )
                except Exception as e:
                    logging.error(f"Could not parse query {query}:{i+1}")
                    raise e
            return parsed_queries
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::4
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def parse_code(
        self,
        content_bytes: bytes,
        node: Node,
        start_byte: int = 0,
        level: int = 0,
        file_path: Optional[str] = None,
        parent_block: CodeBlock | None = None,
        current_span: BlockSpan | None = None,
    ) -> tuple[CodeBlock, Node, BlockSpan]:
        if node.type == "ERROR" or any(
            child.type == "ERROR" for child in node.children
        ):
            node_match = NodeMatch(block_type=CodeBlockType.ERROR)
            self.debug_log(f"Found error node {node.type}")
        else:
            node_match = self.find_in_tree(node)

        pre_code = content_bytes[start_byte : node.start_byte].decode(self.encoding)
        end_line = node.end_point[0]

        if node_match.first_child:
            end_byte = self.get_previous(node_match.first_child, node)
        else:
            end_byte = node.end_byte

        code = content_bytes[node.start_byte : end_byte].decode(self.encoding)

        if node_match.identifier_node:
            identifier = content_bytes[
                node_match.identifier_node.start_byte : node_match.identifier_node.end_byte
            ].decode(self.encoding)
        else:
            identifier = None

        relationships = self.create_references(
            code, content_bytes, identifier, node_match
        )
        parameters = self.create_parameters(content_bytes, node_match, relationships)
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::5
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def parse_code(
        self,
        content_bytes: bytes,
        node: Node,
        start_byte: int = 0,
        level: int = 0,
        file_path: Optional[str] = None,
        parent_block: CodeBlock | None = None,
        current_span: BlockSpan | None = None,
    ) -> tuple[CodeBlock, Node, BlockSpan]:
        # ... other code

        if parent_block:
            code_block = CodeBlock(
                type=node_match.block_type,
                identifier=identifier,
                parent=parent_block,
                previous=self._previous_block,
                parameters=parameters,
                relationships=relationships,
                span_ids=set(),
                start_line=node.start_point[0] + 1,
                end_line=end_line + 1,
                pre_code=pre_code,
                content=code,
                language=self.language,
                tokens=self._count_tokens(code),
                children=[],
                properties={
                    "query": node_match.query,
                    "tree_sitter_type": node.type,
                },
            )

            self._previous_block.next = code_block
            self._previous_block = code_block

            self.pre_process(code_block, node_match)

            if code_block.identifier:
                identifier = code_block.identifier
            else:
                if code_block.content:
                    identifier = code_block.content.split("\n")[0].strip()[0:25]
                    identifier = re.sub(r"\W+", "_", identifier)
                else:
                    identifier = code_block.type.value.lower()

            # Set a unique identifier on each code block
            # TODO: Just count occurrences of the identifier
            existing_identifiers = [
                b.identifier for b in parent_block.children if b.type == code_block.type
            ]
            if identifier in existing_identifiers:
                code_block.identifier = (
                    f"{code_block.identifier}_{len(existing_identifiers)}"
                )
            else:
                code_block.identifier = identifier

            if (
                code_block.type == CodeBlockType.COMMENT
                and current_span
                and current_span.span_type != SpanType.DOCUMENTATION
                and len(current_span.block_paths) > 1
            ):
                # TODO: Find a more robust way to connect comments to the right span
                self.comments_with_no_span.append(code_block)
            else:
                new_span = self._create_new_span(
                    current_span=current_span, block=code_block
                )
                if new_span:
                    current_span = new_span
                    self.spans_by_id[current_span.span_id] = current_span
                    code_block.span_ids.add(current_span.span_id)
                else:
                    current_span.end_line = code_block.end_line

                for comment_block in self.comments_with_no_span:
                    comment_block.belongs_to_span = current_span
                    current_span.block_paths.append(comment_block.full_path())
                    current_span.tokens += comment_block.tokens

                current_span.block_paths.append(code_block.full_path())
                current_span.tokens += code_block.tokens

                code_block.belongs_to_span = current_span
                code_block.span_ids.add(current_span.span_id)

                self.comments_with_no_span = []

            self._graph.add_node(code_block.path_string(), block=code_block)

            for relationship in relationships:
                self._graph.add_edge(
                    code_block.path_string(), ".".join(relationship.path)
                )

        else:
            current_span = None
            code_block = Module(
                type=CodeBlockType.MODULE,
                identifier=None,
                file_path=file_path,
                content="",
                spans_by_id={},
                start_line=node.start_point[0] + 1,
                end_line=end_line + 1,
                language=self.language,
                children=[],
                properties={
                    "query": node_match.query,
                    "tree_sitter_type": node.type,
                },
            )
            self._previous_block = code_block

        next_node = node_match.first_child
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::6
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def parse_code(
        self,
        content_bytes: bytes,
        node: Node,
        start_byte: int = 0,
        level: int = 0,
        file_path: Optional[str] = None,
        parent_block: CodeBlock | None = None,
        current_span: BlockSpan | None = None,
    ) -> tuple[CodeBlock, Node, BlockSpan]:
        # ... other code

        self.debug_log(
            f"""Created code block
    content: {code_block.content[:50]} 
    block_type: {code_block.type} 
    node_type: {node.type}
    next_node: {next_node.type if next_node else "none"}
    first_child: {node_match.first_child}
    last_child: {node_match.last_child}
    start_byte: {start_byte}
    node.start_byte: {node.start_byte}
    node.end_byte: {node.end_byte}"""
        )

        index = 0

        while next_node:
            if (
                next_node.children and next_node.type == "block"
            ):  # TODO: This should be handled in get_block_definition
                next_node = next_node.children[0]

            self.debug_log(
                f"next  [{level}]: -> {next_node.type} - {next_node.start_byte}"
            )

            child_block, child_last_node, child_span = self.parse_code(
                content_bytes,
                next_node,
                start_byte=end_byte,
                level=level + 1,
                parent_block=code_block,
                current_span=current_span,
            )

            if not current_span or child_span.span_id != current_span.span_id:
                current_span = child_span

            code_block.append_child(child_block)

            index += 1

            if child_last_node:
                self.debug_log(f"next  [{level}]: child_last_node -> {child_last_node}")
                next_node = child_last_node

            end_byte = next_node.end_byte

            self.debug_log(
                f"""next  [{level}]
    last_child -> {node_match.last_child}
    next_node -> {next_node}
    next_node.next_sibling -> {next_node.next_sibling}
    end_byte -> {end_byte}
"""
            )
            if next_node == node_match.last_child:
                break
            elif next_node.next_sibling:
                next_node = next_node.next_sibling
            else:
                next_parent_node = self.get_parent_next(
                    next_node, node_match.check_child or node
                )
                next_node = None if next_parent_node == next_node else next_parent_node

        self.debug_log(f"end   [{level}]: {code_block.content}")

        for comment_block in self.comments_with_no_span:
            comment_block.belongs_to_span = current_span
            comment_block.span_ids.add(current_span.span_id)
            current_span.block_paths.append(comment_block.full_path())
            current_span.tokens += comment_block.tokens

        self.comments_with_no_span = []

        self.post_process(code_block)

        self.add_to_index(code_block)

        # TODO: Find a way to remove the Space end block
        if level == 0 and not node.parent and node.end_byte > end_byte:
            space_block = CodeBlock(
                type=CodeBlockType.SPACE,
                identifier=None,
                pre_code=content_bytes[end_byte : node.end_byte].decode(self.encoding),
                parent=code_block,
                start_line=end_line + 1,
                end_line=node.end_point[0] + 1,
                content="",
            )
            code_block.append_child(space_block)

        return code_block, next_node, current_span
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::7
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def is_commented_out_code(self, node: Node):
        comment = node.text.decode("utf8").strip()
        return comment.startswith(f"{get_comment_symbol(self.language)} ...") or any(
            keyword in comment.lower() for keyword in commented_out_keywords
        )

    def find_in_tree(self, node: Node) -> NodeMatch | None:
        if self.apply_gpt_tweaks:
            match = self.find_match_with_gpt_tweaks(node)
            if match:
                self.debug_log(
                    f"find_in_tree() GPT match: {match.block_type} on {node}"
                )
                return match

        match = self.find_match(node)
        if match:
            self.debug_log(
                f"find_in_tree() Found match on node type {node.type} with block type {match.block_type}"
            )
            return match
        else:
            self.debug_log(
                f"find_in_tree() Found no match on node type {node.type} set block type {CodeBlockType.CODE}"
            )
            return NodeMatch(block_type=CodeBlockType.CODE)
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::8
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def find_match_with_gpt_tweaks(self, node: Node) -> NodeMatch | None:
        for label, node_type, query in self.gpt_queries:
            if node_type and node.type != node_type and node_type != "_":
                continue
            match = self._find_match(node, query, label, capture_from_parent=True)
            if match:
                self.debug_log(
                    f"find_match_with_gpt_tweaks() Found match on node {node.type} with query {label}"
                )
                if not match.query:
                    match.query = label
                return match

        return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::9
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def find_match(self, node: Node) -> NodeMatch | None:
        self.debug_log(f"find_match() node type {node.type}")
        for label, node_type, query in self.queries:
            if node_type and node.type != node_type and node_type != "_":
                continue
            match = self._find_match(node, query, label)
            if match:
                self.debug_log(
                    f"find_match() Found match on node {node.type} with query {label}"
                )
                if not match.query:
                    match.query = label
                return match

        return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::10
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def _find_match(
        self, node: Node, query, label: str, capture_from_parent: bool = False
    ) -> NodeMatch | None:
        if capture_from_parent:
            captures = query.captures(node.parent)
        else:
            captures = query.captures(node)

        node_match = NodeMatch()

        if not captures:
            return None

        root_node = None

        for found_node, tag in captures:
            self.debug_log(f"[{label}] Found tag {tag} on node {found_node}")

            if tag == "root" and not root_node and node == found_node:
                self.debug_log(f"[{label}] Root node {found_node}")
                root_node = found_node

            if not root_node:
                continue

            if tag == "no_children" and found_node.children:
                return None

            if tag == "check_child":
                self.debug_log(f"[{label}] Check child {found_node}")
                node_match = self.find_match(found_node)
                if node_match:
                    node_match.check_child = found_node
                return node_match

            if tag == "parse_child":
                self.debug_log(f"[{label}] Parse child {found_node}")

                child_match = self.find_match(found_node)
                if child_match:
                    if child_match.relationships:
                        self.debug_log(
                            f"[{label}] Found {len(child_match.relationships)} references on child {found_node}"
                        )
                        node_match.relationships = child_match.relationships
                    if child_match.parameters:
                        self.debug_log(
                            f"[{label}] Found {len(child_match.parameters)} parameters on child {found_node}"
                        )
                        node_match.parameters.extend(child_match.parameters)
                    if child_match.first_child:
                        node_match.first_child = child_match.first_child

            if tag == "identifier" and not node_match.identifier_node:
                node_match.identifier_node = found_node

            if tag == "child.first" and not node_match.first_child:
                node_match.first_child = found_node

            if tag == "child.last" and not node_match.last_child:
                node_match.last_child = found_node

            if tag == "parameter.identifier":
                node_match.parameters.append((found_node, None))

            if tag == "parameter.type" and node_match.parameters:
                node_match.parameters[-1] = (node_match.parameters[-1][0], found_node)

            if root_node and tag.startswith("reference"):
                node_match.relationships.append((found_node, tag))

            if not node_match.block_type:
                node_match.block_type = CodeBlockType.from_string(tag)

        if node_match.block_type:
            self.debug_log(
                f"[{label}] Return match with type {node_match.block_type} for node {node}"
            )
            return node_match

        return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::11
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def create_references(self, code, content_bytes, identifier, node_match):
        references = []
        if node_match.block_type == CodeBlockType.IMPORT and node_match.relationships:
            module_nodes = [
                ref for ref in node_match.relationships if ref[1] == "reference.module"
            ]
            if module_nodes:
                module_reference_id = self.get_content(
                    module_nodes[0][0], content_bytes
                )
                if len(node_match.relationships) > 1:
                    for ref_node in node_match.relationships:
                        if ref_node == module_nodes[0]:
                            continue
                        elif ref_node[1] == "reference.alias":
                            reference_id = self.get_content(ref_node[0], content_bytes)
                            references.append(
                                Relationship(
                                    scope=ReferenceScope.EXTERNAL,
                                    type=RelationshipType.IMPORTS,
                                    identifier=reference_id,
                                    path=[],
                                    external_path=[module_reference_id],
                                )
                            )
                        else:
                            reference_id = self.get_content(ref_node[0], content_bytes)
                            references.append(
                                Relationship(
                                    scope=ReferenceScope.EXTERNAL,
                                    type=RelationshipType.IMPORTS,
                                    identifier=reference_id,
                                    path=[reference_id],
                                    external_path=[module_reference_id],
                                )
                            )
                else:
                    references.append(
                        Relationship(
                            scope=ReferenceScope.EXTERNAL,
                            type=RelationshipType.IMPORTS,
                            identifier=module_reference_id,
                            external_path=[module_reference_id],
                        )
                    )
        else:
            for reference in node_match.relationships:
                reference_id = self.get_content(reference[0], content_bytes)

                reference_id_path = reference_id.split(".")

                if not reference_id_path:
                    logger.warning(
                        f"Empty reference_id_path ({reference_id_path}) for code `{code}` in reference node {reference} with value {reference_id}"
                    )
                    continue

                if reference[1] == "reference.utilizes":
                    if node_match.block_type in [
                        CodeBlockType.FUNCTION,
                        CodeBlockType.CLASS,
                    ]:
                        relationship_type = RelationshipType.DEFINED_BY
                    else:
                        relationship_type = RelationshipType.UTILIZES
                elif reference[1] == "reference.provides":
                    relationship_type = RelationshipType.PROVIDES
                elif reference[1] == "reference.calls":
                    relationship_type = RelationshipType.CALLS
                elif reference[1] == "reference.type":
                    relationship_type = RelationshipType.IS_A
                elif reference[1] == "reference.imports":
                    relationship_type = RelationshipType.IMPORTS
                else:
                    relationship_type = RelationshipType.USES

                references.append(
                    Relationship(
                        scope=ReferenceScope.LOCAL,
                        type=relationship_type,
                        identifier=identifier,
                        path=reference_id_path,
                    )
                )
        return references
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::12
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def create_parameters(self, content_bytes, node_match, references):
        parameters = []
        for parameter in node_match.parameters:
            parameter_type = (
                self.get_content(parameter[1], content_bytes) if parameter[1] else None
            )
            parameter_id = self.get_content(parameter[0], content_bytes)

            parameters.append(Parameter(identifier=parameter_id, type=parameter_type))

            if parameter_type:
                parameter_type = parameter_type.replace('"', "")

                type_split = parameter_type.split(".")

                reference = Relationship(
                    scope=ReferenceScope.LOCAL, identifier=parameter_id, path=type_split
                )
                references.append(reference)
        return parameters
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::13
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def add_to_index(self, codeblock: CodeBlock):
        if self.index_callback:
            self.index_callback(codeblock)

    def pre_process(self, codeblock: CodeBlock, node_match: NodeMatch):
        pass

    def post_process(self, codeblock: CodeBlock):
        pass

    def get_previous(self, node: Node, origin_node: Node):
        if node == origin_node:
            return node.start_byte
        if node.prev_sibling:
            return node.prev_sibling.end_byte
        elif node.parent:
            return self.get_previous(node.parent, origin_node)
        else:
            return node.start_byte

    def get_parent_next(self, node: Node, orig_node: Node):
        self.debug_log(f"get_parent_next: {node.type} - {orig_node.type}")
        if node != orig_node:
            if node.next_sibling:
                self.debug_log(
                    f"get_parent_next: node.next_sibling -> {node.next_sibling}"
                )
                return node.next_sibling
            else:
                return self.get_parent_next(node.parent, orig_node)
        return None

    def has_error(self, node: Node):
        if node.type == "ERROR":
            return True
        if node.children:
            return any(self.has_error(child) for child in node.children)
        return False
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::14
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def parse(self, content, file_path: Optional[str] = None) -> Module:
        if isinstance(content, str):
            content_in_bytes = bytes(content, self.encoding)
        elif isinstance(content, bytes):
            content_in_bytes = content
        else:
            raise ValueError("Content must be either a string or bytes")

        # TODO: make thread safe?
        self.spans_by_id = {}
        self._span_counter = {}

        # TODO: Should me moved to a central CodeGraph
        self._graph = nx.DiGraph()

        tree = self.tree_parser.parse(content_in_bytes)
        module, _, _ = self.parse_code(
            content_in_bytes, tree.walk().node, file_path=file_path
        )
        module.spans_by_id = self.spans_by_id
        module.file_path = file_path
        module.language = self.language
        module._graph = self._graph
        return module

    def get_content(self, node: Node, content_bytes: bytes) -> str:
        return content_bytes[node.start_byte : node.end_byte].decode(self.encoding)
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::15
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def _create_new_span(
        self, current_span: BlockSpan | None, block: CodeBlock
    ) -> BlockSpan | None:
        # Set documentation phase on comments in the start of structure blocks if more than min_tokens_for_docs_span
        # TODO: This is isn't valid in other languages, try to set block type to docstring?
        block_types_with_document_span = [
            CodeBlockType.MODULE
        ]  # TODO: Make this configurable
        if block.type == CodeBlockType.COMMENT and (
            not current_span
            or current_span.block_type in block_types_with_document_span
            and (
                current_span.span_type != SpanType.IMPLEMENTATION
                or current_span.index == 0
            )
        ):
            span_type = SpanType.DOCUMENTATION
            span_id = self._create_span_id(block, label="docstring")

        # Set initation phase when block is a class or constructor, and until first function:
        elif block.type in [CodeBlockType.CLASS, CodeBlockType.CONSTRUCTOR] or (
            current_span
            and current_span.block_type
            in [CodeBlockType.CLASS, CodeBlockType.CONSTRUCTOR]
            and current_span.initiating_block.parent != block.parent
            and current_span.span_type != SpanType.IMPLEMENTATION
            and block.type not in [CodeBlockType.FUNCTION]
        ):
            span_type = SpanType.INITATION
            span_id = self._create_span_id(block)

        # Set initation phase on imports in module blocks
        elif block.type == CodeBlockType.IMPORT and (
            not current_span or current_span.block_type == CodeBlockType.MODULE
        ):
            span_type = SpanType.INITATION
            span_id = self._create_span_id(block, label="imports")

        else:
            span_type = SpanType.IMPLEMENTATION
            span_id = self._create_span_id(block)

        # if no curent_span exists, expected to be on Module level
        if not current_span:
            if block.type.group == CodeBlockTypeGroup.STRUCTURE:
                return BlockSpan(
                    span_id=span_id,
                    span_type=span_type,
                    start_line=block.start_line,
                    end_line=block.start_line,
                    initiating_block=block,
                    parent_block_path=block.full_path(),
                )
            else:
                return BlockSpan(
                    span_id=span_id,
                    span_type=span_type,
                    start_line=block.start_line,
                    end_line=block.start_line,
                    initiating_block=block.parent,
                    parent_block_path=block.parent.full_path(),
                )

        # create a new span on new structures in classes or modules but not functions
        # * if the parent block doesn't have a span
        if (
            block.type.group in [CodeBlockTypeGroup.STRUCTURE]
            and block.parent.type in [CodeBlockType.MODULE, CodeBlockType.CLASS]
            and current_span.parent_block_path == block.parent.full_path()
        ):
            if len(current_span.parent_block_path) < len(block.full_path()):
                # If there is a current span from the parent block it should be set to is_partial
                current_span.is_partial = True

            return BlockSpan(
                span_id=span_id,
                span_type=span_type,
                start_line=block.start_line,
                end_line=block.start_line,
                initiating_block=block,
                parent_block_path=block.full_path(),
            )

        # if current span is from a child block
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::16
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def _create_new_span(
        self, current_span: BlockSpan | None, block: CodeBlock
    ) -> BlockSpan | None:
        # ... other code
        if len(current_span.parent_block_path) > len(block.parent.full_path()):
            if block.type.group == CodeBlockTypeGroup.STRUCTURE:
                parent_block_path = block.full_path()
            else:
                parent_block_path = block.parent.full_path()

            return BlockSpan(
                span_id=span_id,
                span_type=span_type,
                start_line=block.start_line,
                end_line=block.start_line,
                initiating_block=block,
                parent_block_path=parent_block_path,
            )

        # Create new span if span type has changed
        # if span_type != current_span.span_type:
        #    return BlockSpan(
        #        span_id=span_id,
        #        span_type=span_type,
        #        start_line=block.start_line,
        #        end_line=block.start_line,
        #        initiating_block=current_span.initiating_block,
        #        parent_block_path=current_span.parent_block_path,
        #    )

        # Create new span if the current is too large and the parent block is a structure block
        split_on_block_type = [CodeBlockType.MODULE]  # Only split on Module level
        if (
            current_span.tokens + block.sum_tokens() > self._max_tokens_in_span
            and block.parent.type in split_on_block_type
        ):
            current_span.is_partial = True

            return BlockSpan(
                span_id=span_id,
                span_type=span_type,
                start_line=block.start_line,
                end_line=block.start_line,
                initiating_block=current_span.initiating_block,
                parent_block_path=current_span.parent_block_path,
                is_partial=True,
                index=current_span.index + 1,
            )

        return None
--------------------------------------------------------------------------------
Chunk ID: parser/parser.py::17
Filepath: moatless\codeblocks\parser\parser.py
Content:
class CodeParser:

    def _create_span_id(self, block: CodeBlock, label: Optional[str] = None):
        if block.type.group == CodeBlockTypeGroup.STRUCTURE:
            structure_block = block
        else:
            structure_block = block.find_type_group_in_parents(
                CodeBlockTypeGroup.STRUCTURE
            )

        span_id = structure_block.path_string()
        if label and span_id:
            span_id += f":{label}"
        elif label and not span_id:
            span_id = label
        elif not span_id:
            span_id = "impl"

        if span_id in self._span_counter:
            self._span_counter[span_id] += 1
            span_id += f":{self._span_counter[span_id]}"
        else:
            self._span_counter[span_id] = 1

        return span_id

    def _count_tokens(self, content: str):
        if not self.tokenizer:
            return 0
        return len(self.tokenizer(content))

    def debug_log(self, message: str):
        if self.debug:
            logger.debug(message)
--------------------------------------------------------------------------------
Chunk ID: parser/python.py::1
Filepath: moatless\codeblocks\parser\python.py
Content:
import logging

import tree_sitter_python as tspython
from tree_sitter import Language

from moatless.codeblocks.codeblocks import (
    CodeBlock,
    CodeBlockType,
    ReferenceScope,
    RelationshipType,
    ValidationError,
)
from moatless.codeblocks.parser.parser import (
    CodeParser,
    NodeMatch,
    commented_out_keywords,
)

child_block_types = ["ERROR", "block"]

block_delimiters = [":"]

logger = logging.getLogger(__name__)


class PythonParser(CodeParser):
    def __init__(self, **kwargs):
        language = Language(tspython.language())

        super().__init__(language, **kwargs)

        self.queries = []
        self.queries.extend(self._build_queries("python.scm"))

        if self.apply_gpt_tweaks:
            self.gpt_queries.extend(self._build_queries("python_gpt.scm"))

    @property
    def language(self):
        return "python"

    def pre_process(self, codeblock: CodeBlock, node_match: NodeMatch):
        if (
            codeblock.type == CodeBlockType.FUNCTION
            and codeblock.identifier == "__init__"
        ):
            codeblock.type = CodeBlockType.CONSTRUCTOR

        # Handle line breaks after assignment without \
        if (
            codeblock.type == CodeBlockType.ASSIGNMENT
            and codeblock.content_lines[0].strip().endswith("=")
            and node_match.check_child
            and node_match.first_child
            and node_match.check_child.start_point[0]
            < node_match.first_child.start_point[0]
        ):
            logger.warning(
                f"Parsed block with type ASSIGNMENT with line break but no ending \\: {codeblock.content_lines[0]}"
            )
            codeblock.content_lines[0] = codeblock.content_lines[0] + " \\"
--------------------------------------------------------------------------------
Chunk ID: parser/python.py::2
Filepath: moatless\codeblocks\parser\python.py
Content:
class PythonParser(CodeParser):

    def post_process(self, codeblock: CodeBlock):
        if codeblock.type == CodeBlockType.COMMENT and self.is_outcommented_code(
            codeblock.content
        ):
            codeblock.type = CodeBlockType.COMMENTED_OUT_CODE

        if codeblock.type == CodeBlockType.ASSIGNMENT:
            for reference in codeblock.relationships:
                reference.type = RelationshipType.TYPE

        new_references = []
        for reference in codeblock.relationships:
            # Set parent class path as reference path on self
            if reference.path and reference.path[0] == "self":
                class_block = codeblock.find_type_in_parents(CodeBlockType.CLASS)
                if class_block:
                    reference.scope = ReferenceScope.CLASS
                    if len(reference.path) > 1:
                        reference.path = class_block.full_path() + reference.path[1:2]
                        reference.identifier = codeblock.identifier

            # Set parent classes super class path as reference path on super()
            # TODO: make a solution where this can be derived even further (by checking import)
            if reference.path and reference.path[0] == "super()":
                class_block = codeblock.find_type_in_parents(CodeBlockType.CLASS)
                if class_block:
                    is_a_rel = [
                        rel
                        for rel in class_block.relationships
                        if rel.type == RelationshipType.IS_A
                    ]
                    if is_a_rel:
                        super_class = codeblock.module.find_by_path(is_a_rel[0].path)

                        if super_class:
                            reference.path = (
                                super_class.full_path() + reference.path[1:2]
                            )
                            reference.identifier = super_class.identifier

        codeblock.relationships.extend(new_references)

        if (
            codeblock.type in [CodeBlockType.CLASS, CodeBlockType.FUNCTION]
            and len(codeblock.children) == 1
            and codeblock.children[0].type == CodeBlockType.COMMENTED_OUT_CODE
        ):
            codeblock.type = CodeBlockType.COMMENTED_OUT_CODE

        function_names = set()
        class_names = set()
        for child in codeblock.children:
            if child.type == CodeBlockType.FUNCTION:
                if child.identifier in function_names:
                    child.validation_errors.append(
                        ValidationError(
                            error=f"Duplicate function name: {child.identifier}"
                        )
                    )
                function_names.add(child.identifier)
            if child.type == CodeBlockType.CLASS:
                if child.identifier in class_names:
                    child.validation_errors.append(
                        ValidationError(
                            error=f"Duplicate class name: {child.identifier}"
                        )
                    )
                class_names.add(child.identifier)

    def is_outcommented_code(self, comment):
        return comment.startswith("# ...") or any(
            keyword in comment.lower() for keyword in commented_out_keywords
        )
--------------------------------------------------------------------------------
Chunk ID: edit/__init__.py::1
Filepath: moatless\edit\__init__.py
Content:
from moatless.edit.clarify import ClarifyCodeChange
from moatless.edit.edit import EditCode
from moatless.edit.plan import PlanToCode
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::1
Filepath: moatless\edit\clarify.py
Content:
import logging
from typing import Optional

from pydantic import BaseModel, Field, PrivateAttr

from moatless.codeblocks import CodeBlockType
from moatless.codeblocks.codeblocks import BlockSpan, CodeBlockTypeGroup
from moatless.edit.prompt import CLARIFY_CHANGE_SYSTEM_PROMPT
from moatless.repository import CodeFile
from moatless.state import ActionResponse, AgenticState
from moatless.types import (
    ActionRequest,
    FileWithSpans,
    Message,
)
from moatless.utils.tokenizer import count_tokens

logger = logging.getLogger("ClarifyCodeChange")


class LineNumberClarification(ActionRequest):
    scratch_pad: str = Field(..., description="Thoughts on which lines to select")
    start_line: int = Field(
        ..., description="The start line of the code to be updated."
    )

    end_line: int = Field(..., description="The end line of the code to be updated.")
    reject: Optional[bool] = Field(
        None, description="Whether the request should be rejected."
    )
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::2
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):
    instructions: str = Field(..., description="The instructions for the code change.")
    file_path: str = Field(..., description="The path to the file to be updated.")
    span_id: str = Field(..., description="The ID of the span to be updated.")

    start_line: Optional[int] = Field(None, description="The start line of the code to be updated.")
    end_line: Optional[int] = Field(None, description="The end line of the code to be updated.")

    max_tokens_in_edit_prompt: int = Field(
        500,
        description="The maximum number of tokens in a span to show the edit prompt.",
    )

    _file: CodeFile | None = PrivateAttr(None)
    _span: BlockSpan | None = PrivateAttr(None)
    _file_context_str: Optional[str] = PrivateAttr(None)
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::3
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):

    def init(self):
        self._file = self.file_repo.get_file(self.file_path)
        self._span = self._file.module.find_span_by_id(self.span_id)

        file_context = self.create_file_context(
            [FileWithSpans(file_path=self.file_path, span_ids=[self.span.span_id])]
        )

        # Include all function/class signatures if the block is a class
        if self.span.initiating_block.type == CodeBlockType.CLASS:
            for child in self.span.initiating_block.children:
                if (
                    child.type.group == CodeBlockTypeGroup.STRUCTURE
                    and child.belongs_to_span
                    and child.belongs_to_span.span_id != self._span.span_id
                ):
                    file_context.add_span_to_context(
                        file_path=self.file_path,
                        span_id=child.belongs_to_span.span_id,
                        tokens=1,
                    )  # TODO: Change so 0 can be set and mean "only signature"

        self._file_context_str = file_context.create_prompt(
            show_line_numbers=True,
            show_span_ids=False,
            exclude_comments=False,
            show_outcommented_code=True,
            outcomment_code_comment="... other code",
        )
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::4
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):

    def _execute_action(self, request: LineNumberClarification) -> ActionResponse:
        logger.info(
            f"{self}: Got line number clarification: {request.start_line} - {request.end_line}"
        )

        if request.reject:
            return ActionResponse.transition(
                trigger="reject", output={"message": request.scratch_pad}
            )

        retry_message = self._verify_line_numbers(request)
        if retry_message:
            return ActionResponse.retry(retry_message)

        if request.end_line - request.start_line < 4:
            start_line, end_line = self.get_line_span(
                request.start_line, request.end_line, self.max_tokens_in_edit_prompt
            )
        else:
            start_line, end_line = request.start_line, request.end_line

        if request.scratch_pad:
            self.instructions += "\n\n" + request.scratch_pad

        return ActionResponse.transition(
            trigger="edit_code",
            output={
                "instructions": self.instructions,
                "file_path": self.file_path,
                "span_id": self.span_id,
                "start_line": start_line,
                "end_line": end_line,
            },
        )
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::5
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):

    @classmethod
    def required_fields(cls) -> set[str]:
        return {"instructions", "file_path", "span_id"}

    def action_type(self) -> type[BaseModel] | None:
        return LineNumberClarification

    @property
    def file(self) -> CodeFile:
        assert self._file is not None, "File has not been set"
        return self._file

    @property
    def span(self) -> BlockSpan:
        assert self._span is not None, "Span has not been set"
        return self._span
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::6
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):

    def _verify_line_numbers(
        self, line_numbers: LineNumberClarification
    ) -> Optional[str]:
        logger.info(
            f"{self}: Verifying line numbers: {line_numbers.start_line} - {line_numbers.end_line}. "
            f"To span with line numbers: {self.span.start_line} - {self.span.end_line}"
        )

        if (
            line_numbers.start_line <= self.span.start_line
            and line_numbers.end_line >= self.span.end_line
        ):
            return f"The provided line numbers {line_numbers.start_line} - {line_numbers.end_line} covers the whole code span. You must specify line numbers of only lines you want to change."

        span_block = self.span.initiating_block

        # The LLM sometimes refer to only the lines of the class/function signature when it's intention is to edit lines
        if span_block.type.group == CodeBlockTypeGroup.STRUCTURE:
            last_block_content_line = span_block.children[0].start_line - 1

            logger.info(
                f"{self}: Checking if the line numbers only covers a class/function signature to "
                f"{self.span.initiating_block.path_string()} ({span_block.start_line} - {last_block_content_line})"
            )
            if (
                line_numbers.start_line == span_block.start_line
                and last_block_content_line >= line_numbers.end_line
                and self.span.initiating_block.sum_tokens()
                > self.max_tokens_in_edit_prompt
            ):
                clarify_msg = f"The line numbers {line_numbers.start_line} - {line_numbers.end_line} only covers to the signature of the {self.span.initiating_block.type.value}."
                logger.info(f"{self}: {clarify_msg}. Ask for clarification.")
                # TODO: Ask if this was intentional instead instructing the LLM
                return f"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change."

        code_lines = self.file.content.split("\n")
        lines_to_replace = code_lines[
            line_numbers.start_line - 1 : line_numbers.end_line
        ]

        edit_block_code = "\n".join(lines_to_replace)

        tokens = count_tokens(edit_block_code)
        if tokens > self.max_tokens_in_edit_prompt:
            clarify_msg = f"Lines {line_numbers.start_line} - {line_numbers.end_line} has {tokens} tokens, which is higher than the maximum allowed {self.max_tokens_in_edit_prompt} tokens in completion"
            logger.info(f"{self} {clarify_msg}. Ask for clarification.")
            return f"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change. If this is not possible you should reject the request."

        return None

    def system_prompt(self) -> str:
        return CLARIFY_CHANGE_SYSTEM_PROMPT

    def messages(self) -> list[Message]:
        if not self._file_context_str:
            self.init()

        messages = [
            Message(
                role="user",
                content=f"<instructions>\n{self.instructions}\n</instructions>\n<code>\n{self._file_context_str}\n</code>",
            )
        ]

        messages.extend(self.retry_messages())

        return messages
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::7
Filepath: moatless\edit\clarify.py
Content:
class ClarifyCodeChange(AgenticState):

    def get_line_span(
        self,
        start_line: int,
        end_line: int,
        max_tokens: int,
    ) -> tuple[Optional[int], Optional[int]]:
        """
        Find the span that covers the lines from start_line to end_line
        """

        logger.info(
            f"Get span to change in {self.file_path} from {start_line} to {end_line}"
        )

        start_block = self.file.module.find_first_by_start_line(start_line)
        assert (
            start_block is not None
        ), f"No block found in {self.file_path} that starts at line {start_line}"

        if start_block.type.group == CodeBlockTypeGroup.STRUCTURE and (
            not end_line or start_block.end_line > end_line
        ):
            struture_block = start_block
        else:
            struture_block = start_block.find_type_group_in_parents(
                CodeBlockTypeGroup.STRUCTURE
            )

        assert (
            struture_block is not None
        ), f"No structure bock found for {start_block.path_string()}"

        if struture_block.sum_tokens() < max_tokens:
            logger.info(
                f"Return block [{struture_block.path_string()}] ({struture_block.start_line} - {struture_block.end_line}) with {struture_block.sum_tokens()} tokens that covers the provided line span ({start_line} - {end_line})"
            )
            return struture_block.start_line, struture_block.end_line

        if not end_line:
            end_line = start_line

        original_lines = self.file.content.split("\n")
        if struture_block.end_line - end_line < 5:
            logger.info(
                f"Set parent block [{struture_block.path_string()}] end line {struture_block.end_line} as it's {struture_block.end_line - end_line} lines from the end of the file"
            )
            end_line = struture_block.end_line
        else:
            end_line = _get_post_end_line_index(
                end_line, struture_block.end_line, original_lines
            )
            logger.info(f"Set end line to {end_line} from the end of the parent block")

        if start_line - struture_block.start_line < 5:
            logger.info(
                f"Set parent block [{struture_block.path_string()}] start line {struture_block.start_line} as it's {start_line - struture_block.start_line} lines from the start of the file"
            )
            start_line = struture_block.start_line
        else:
            start_line = _get_pre_start_line(
                start_line, struture_block.start_line, original_lines
            )
            logger.info(
                f"Set start line to {start_line} from the start of the parent block"
            )

        return start_line, end_line
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::8
Filepath: moatless\edit\clarify.py
Content:
def _get_pre_start_line(
    start_line: int, min_start_line: int, content_lines: list[str], max_lines: int = 4
) -> int:
    if start_line > len(content_lines):
        raise ValueError(
            f"start_line {start_line} is out of range ({len(content_lines)})."
        )

    if start_line - min_start_line < max_lines:
        return min_start_line

    start_line_index = start_line - 1
    start_search_index = max(0, start_line_index - 1)
    end_search_index = max(min_start_line, start_line_index - max_lines)

    non_empty_indices = []

    for idx in range(start_search_index, end_search_index - 1, -1):
        if content_lines[idx].strip() != "":
            non_empty_indices.append(idx)

    # Check if any non-empty line was found within the search range
    if non_empty_indices:
        return non_empty_indices[-1] + 1

    # If no non-empty lines were found, check the start_line itself
    if content_lines[start_line_index].strip() != "":
        return start_line_index + 1

    # If the start_line is also empty, raise an exception
    raise ValueError("No non-empty line found within 3 lines above the start_line.")
--------------------------------------------------------------------------------
Chunk ID: edit/clarify.py::9
Filepath: moatless\edit\clarify.py
Content:
def _get_post_end_line_index(
    end_line: int, max_end_line: int, content_lines: list[str], max_lines: int = 4
) -> int:
    if end_line < 1 or end_line > len(content_lines):
        raise IndexError("end_line is out of range.")

    if max_end_line - end_line < max_lines:
        return max_end_line

    end_line_index = end_line - 1
    start_search_index = min(len(content_lines) - 1, end_line_index + 1)
    end_search_index = min(max_end_line - 1, end_line_index + max_lines)

    non_empty_indices = []

    for idx in range(start_search_index, end_search_index + 1):
        if content_lines[idx].strip() != "":
            non_empty_indices.append(idx)

    # Check if any non-empty line was found within the search range
    if non_empty_indices:
        return non_empty_indices[-1] + 1

    # If no non-empty lines were found, check the end_line itself
    if content_lines[end_line_index].strip() != "":
        return end_line_index + 1

    # If the end_line is also empty, raise an exception
    raise ValueError("No non-empty line found within 3 lines after the end_line.")
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::1
Filepath: moatless\edit\edit.py
Content:
import logging
from typing import Optional

from pydantic import BaseModel, Field, PrivateAttr

from moatless.state import AgenticState, Finished
from moatless.types import (
    ActionRequest,
    ActionResponse,
    AssistantMessage,
    Content,
    Message,
    UserMessage,
    VerificationError,
)

logger = logging.getLogger(__name__)

ROLE_PROMPT = "You are autonomous AI assisistant with superior programming skills."

MAIN_OBJECTIVE_PROMPT = "The main objective is to solve a bigger task specified by the user, this is wrapped in a <main_objective> tag."

SEARCH_REPLACE_PROMPT = """Your task is to solve a smaller task within the main objective. This task is wrapped in a <task> tag.

The surrounding code context is wrapped in a <file_context> tag.

The code to that should be modified is wrapped in a <search> tag, like this:
<search>
{{CODE}}
</search>

Your task is to update the code inside the <search> tags based on the current task.

When updating the code, please adhere to the following important rules:
- Fully implement the requested change, but do not make any other changes that were not directly asked for
- Do not add any comments describing your changes 
- Indentation and formatting should be the same in the replace code as in the search code
- Ensure the modified code is complete - do not leave any TODOs, placeholder, or missing pieces
- Keep any existing placeholder comments in the <search> block (e.g. # ... other code) - do not remove or implement them

After updating the code, please format your response like this:

<replace>
put the updated code here
</replace>

ONLY return the code that was inside the original <search> tags, but with the requested modifications made. 
Do not include any of the surrounding code.

If all code in the search tag should be removed you can return an empty <replace> tag like this:
<replace>
</replace>

If you can't do any changes and want to reject the instructions return the rejection reason wrapped in a <reject> tag, like this:
<reject>
{{REASON}}
</reject>

Here is an example of what the user's request might look like:

<search>
from flask import Flask 
</search>

And here is how you should format your response:

<replace>
import math
from flask import Flask
</replace>

Remember, only put the updated version of the code from inside the <search> tags in your response, wrapped in <replace>
tags. DO NOT include any other surrounding code than the code in the <search> tag! DO NOT leave out any code that was inside the <search> tag!
"""


CHAIN_OF_THOUGHT_PROMPT = "Please provide your thoughts on the code change, if any, in the tag <scratch_pad>, and then the code change itself."


class CodeChange(ActionRequest):
    scratch_pad: Optional[str] = Field(
        default=None, description="The thoughts on the code change."
    )
    replace: str = Field(..., description="The code to replace the existing code with.")
    rejected: bool = Field(..., description="Whether the code change was rejected.")
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::2
Filepath: moatless\edit\edit.py
Content:
class EditCode(AgenticState):
    instructions: str = Field(..., description="The instructions for the code change.")
    file_path: str = Field(..., description="The path to the file to be updated.")
    span_id: Optional[str] = Field(None, description="The ID of the span to be updated.")
    start_line: int = Field(..., description="The start line of the code to be updated.")
    end_line: int = Field(..., description="The end line of the code to be updated.")

    show_initial_message: bool = Field(True, description="Whether to show the initial message.")
    show_file_context: bool = Field(True, description="Whether to show the file context.")
    verify: bool = Field(True, description="Whether to verify the code change.")
    chain_of_thought: bool = Field(False, description="Whether to use chain of thought reasoning.")

    max_prompt_file_tokens: int = Field(
        4000,
        description="The maximum number of tokens in the file context to show in the prompt.",
    )

    _code_to_replace: Optional[str] = PrivateAttr(default=None)
    _retry: int = PrivateAttr(default=0)
    _messages: list[Message] = PrivateAttr(default_factory=list)

    def init(self):
        file = self.file_context.get_file(self.file_path)
        if not file:
            raise ValueError(f"File not found: {self.file_path}")

        code_lines = file.file.content.split("\n")
        lines_to_replace = code_lines[self.start_line - 1 : self.end_line]
        self._code_to_replace = "\n".join(lines_to_replace)
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::3
Filepath: moatless\edit\edit.py
Content:
class EditCode(AgenticState):

    def _execute_action(self, content: Content) -> ActionResponse:
        self._messages.append(AssistantMessage(content=content.content))

        scratch_pad = None

        if "<scratch_pad>" in content.content:
            scratch_pad = content.content.split("<scratch_pad>")[1].split(
                "</scratch_pad>"
            )[0]

        if "<reject>" in content.content:
            rejection_message = content.content.split("<reject>")[1].split("</reject>")[
                0
            ]
            return ActionResponse.transition(
                "reject",
                output={"message": rejection_message},
            )

        msg_split = content.content.split("<replace>")
        if len(msg_split) == 1:
            if not self._add_prepared_response:
                logger.warning(
                    f"No <replace> tag found in response without prepped tag: {msg_split[0]}"
                )
                return ActionResponse.retry(
                    "You did not provide any code in the replace tag. If you want to reject the instructions, use the reject function."
                )

            replacement_code = msg_split[0]
        else:
            if msg_split[0] and not scratch_pad:
                scratch_pad = msg_split[0]

            if "</replace>" in msg_split[1]:
                replacement_code = msg_split[1].split("</replace>")[0]
            else:
                replacement_code = msg_split[1]

        file = self.file_context.get_file(self.file_path)

        update_result = file.update_content_by_line_numbers(
            self.start_line - 1, self.end_line, replacement_code
        )
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::4
Filepath: moatless\edit\edit.py
Content:
class EditCode(AgenticState):

    def _execute_action(self, content: Content) -> ActionResponse:
        # ... other code

        if update_result.diff and update_result.updated:
            logger.info(
                f"Updated file {self.file_path} with diff:\n{update_result.diff}"
            )

            message = f"Applied the change to {self.file_path}."

            if scratch_pad:
                message += f"\n\n<scratch_pad>\n{scratch_pad}</scratch_pad>"

            original_verification_errors = []
            if self.verify:
                logger.info(f"Verifying original code in {self.file_path}.")
                original_verification_errors = self.workspace.verify(file.file)

            self.file_repo.save_file(file_path=file.file_path)

            verification_errors = []
            if self.verify:
                logger.info(f"Verifying updated code in {self.file_path}.")
                verification_errors_in_update = self.workspace.verify(file.file)

                if len(verification_errors_in_update) > len(
                    original_verification_errors
                ):
                    logger.info(
                        f"Found {len(verification_errors_in_update)} verification errors in updated code. Which differs from the original {len(original_verification_errors)}."
                    )

                    for error in verification_errors_in_update:
                        logger.info(
                            f"Verification error: {error.code}, {error.message}"
                        )
                else:
                    logger.info(
                        f"Found {len(verification_errors_in_update)} verification errors in updated code."
                    )

                original_error_set = set(
                    (msg.code, msg.message) for msg in original_verification_errors
                )

                updated_error_set = set(
                    (msg.code, msg.message) for msg in verification_errors_in_update
                )
                added_messages_set = updated_error_set - original_error_set

                verification_errors = [
                    VerificationError(
                        code=msg.code,
                        file_path=file.file_path,
                        message=msg.message,
                        line=msg.line,
                    )
                    for msg in verification_errors_in_update
                    if (msg.code, msg.message) in added_messages_set
                ]

                for error in verification_errors:
                    logger.info(
                        f"New verification error: {error.code}, {error.message}"
                    )

            return ActionResponse.transition(
                "finish",
                output={
                    "message": message,
                    "diff": update_result.diff,
                    "verification_errors": verification_errors,
                },
            )

        if self._retry > 2:
            logger.warning(f"Failed after {self._retry} retries. Will reject change.")
            message = ""
            if scratch_pad:
                message += f"<scratch_pad>\n{scratch_pad}</scratch_pad>\n\n"
            message = "Failed to apply changes. Please try again."
            return ActionResponse.transition("reject", output={"message": message})

        if update_result.diff:
            logger.warning(f"Diff was not applied:\n{update_result.diff}")
            response_message = (
                f"The following diff was not applied:\n {update_result.diff}. \n"
                f"Errors:\n{update_result.error}\n"
                f"Make sure that you return the unchanged code in the replace tag exactly as it is. "
                f"If you want to reject the instructions, use the reject function."
            )

            self._retry += 1

        else:
            logger.info(f"No changes found in {self.file_path}.")
            response_message = (
                "The code in the replace tag is the same as in the search. Use the reject function if you "
                "can't do any changes and want to reject the instructions."
            )

            self._retry += 1

        return ActionResponse.retry(response_message)
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::5
Filepath: moatless\edit\edit.py
Content:
class EditCode(AgenticState):

    @classmethod
    def required_fields(cls) -> set[str]:
        return {"instructions", "file_path", "span_id", "start_line", "end_line"}

    def finish(self, message: str):
        self.transition_to(Finished(message=message))

    def system_prompt(self) -> str:
        system_prompt = ROLE_PROMPT

        if self.show_initial_message:
            system_prompt += "\n\n"
            system_prompt += MAIN_OBJECTIVE_PROMPT

        system_prompt += "\n\n"
        system_prompt += SEARCH_REPLACE_PROMPT

        if self.chain_of_thought:
            system_prompt += "\n\n"
            system_prompt += CHAIN_OF_THOUGHT_PROMPT

        return system_prompt
--------------------------------------------------------------------------------
Chunk ID: edit/edit.py::6
Filepath: moatless\edit\edit.py
Content:
class EditCode(AgenticState):

    def messages(self) -> list[Message]:
        if not self._code_to_replace:
            self.init()

        content = ""
        if self.show_initial_message:
            content = f"<main_objective>\n{self.initial_message}\n</main_objective>\n\n"

        content += f"<instructions>\n{self.instructions}\n</instructions>\n"

        if self.show_file_context:
            file_context_str = self.file_context.create_prompt(
                show_line_numbers=False,
                show_span_ids=False,
                exclude_comments=False,
                show_outcommented_code=True,
                outcomment_code_comment="... other code",
            )
        else:
            file_context = self.create_file_context()
            file_context.add_span_to_context(self.file_path, self.span_id)
            file_context.expand_context_with_init_spans()
            file_context.expand_context_with_related_spans(self.max_prompt_file_tokens)
            file_context_str = file_context.create_prompt(
                show_line_numbers=False,
                show_span_ids=False,
                exclude_comments=False,
                show_outcommented_code=True,
                outcomment_code_comment="... other code",
            )
        content += f"<file_context>\n{file_context_str}\n</file_context>\n"

        content += f"<search>\n{self._code_to_replace}\n</search>"

        messages = [UserMessage(content=content)]

        messages.extend(self.retry_messages())

        if self._add_prepared_response:
            messages.append(AssistantMessage(content="<replace>"))

        return messages

    @property
    def _add_prepared_response(self):
        return "claude" in self.model and not self.chain_of_thought

    def action_type(self) -> type[BaseModel] | None:
        return None

    def stop_words(self):
        return ["</replace>"]
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::1
Filepath: moatless\edit\plan.py
Content:
import logging
from typing import Optional

from pydantic import ConfigDict, Field, PrivateAttr

from moatless.codeblocks import CodeBlockType
from moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line
from moatless.edit.prompt import (
    CODER_FINAL_SYSTEM_PROMPT,
    CODER_SYSTEM_PROMPT,
    SELECT_SPAN_SYSTEM_PROMPT,
)
from moatless.state import AgenticState
from moatless.types import (
    ActionRequest,
    ActionResponse,
    AssistantMessage,
    Message,
    UserMessage,
)
from moatless.verify.lint import VerificationError

logger = logging.getLogger("PlanToCode")
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::2
Filepath: moatless\edit\plan.py
Content:
class ApplyChange(ActionRequest):
    """
    Request to apply a change to the code.
    """

    scratch_pad: str = Field(..., description="Your thoughts on the code change.")

    action: str = Field(
        ...,
        description="The action to take, possible values are 'modify', 'review', 'finish', 'reject'",
    )

    instructions: Optional[str] = Field(
        None, description="Instructions to do the code change."
    )
    file_path: Optional[str] = Field(
        None, description="The file path of the code to be updated."
    )
    span_id: Optional[str] = Field(
        None, description="The span id of the code to be updated."
    )

    reject: Optional[str] = Field(
        None, description="Reject the request and explain why."
    )
    finish: Optional[str] = Field(
        None, description="Finish the request and explain why"
    )

    model_config = ConfigDict(
        extra="allow",
    )
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::3
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):
    message: Optional[str] = Field(
        None,
        description="Message to the coder",
    )

    # TODO: Move to a new state handling changes
    diff: Optional[str] = Field(
        None,
        description="The diff of a previous code change.",
    )

    # TODO: Move to a new state handling lint problems
    verification_errors: list[VerificationError] | None = Field(
        None,
        description="The lint errors of the previous code change.",
    )

    max_prompt_file_tokens: int = Field(
        4000,
        description="The maximum number of tokens in the file context to show in the prompt.",
    )

    max_tokens_in_edit_prompt: int = Field(
        500,
        description="The maximum number of tokens in a span to show the edit prompt.",
    )

    expand_context_with_related_spans: bool = Field(
        True,
        description="Whether to expand the context with related spans.",
    )

    allow_hallucinated_spans: bool = Field(
        False,
        description="Whether to allow spans that exists but aren't found in the file context.",
    )

    finish_on_review: bool = Field(
        False, description="Whether to finish the task if a review is requested."
    )

    include_message_history: bool = Field(
        True,
        description="Whether to include the message history in the prompt.",
    )

    _expanded_context: bool = PrivateAttr(False)

    def init(self):
        if not self._expanded_context:
            self.file_context.expand_context_with_init_spans()

            if (
                self.expand_context_with_related_spans
                and len(self.get_previous_states(self)) == 0
            ):
                self.file_context.expand_context_with_related_spans(
                    max_tokens=self.max_prompt_file_tokens
                )
                self.file_context.expand_small_classes(max_tokens=1000)
            self._expanded_context = True
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::4
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):

    def _execute_action(self, action: ApplyChange) -> ActionResponse:
        if action.action == "review":
            if self.diff and self.finish_on_review:
                logger.info("Review suggested after diff, will finish")
                return ActionResponse.transition(
                    trigger="finish", output={"message": "Finish on suggested review."}
                )
            else:
                return ActionResponse.retry(
                    "Review isn't possible. If the change is done you can finish or reject the task."
                )

        if action.action == "finish":
            return ActionResponse.transition(
                trigger="finish", output={"message": action.finish}
            )
        elif action.reject:
            return ActionResponse.transition(
                trigger="reject", output={"message": action.reject}
            )

        elif action.file_path and action.span_id:
            return self._request_for_change(action)

        return ActionResponse.retry(
            "You must either provide an apply_change action or finish."
        )

    def action_type(self) -> type[ApplyChange]:
        return ApplyChange
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::5
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):

    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:
        logger.info(
            f"request_for_change(file_path={rfc.file_path}, span_id={rfc.span_id})"
        )

        if not rfc.instructions:
            return ActionResponse.retry(
                f"Please provide instructions for the code change."
            )

        context_file = self.file_context.get_file(rfc.file_path)
        if not context_file:
            logger.warning(
                f"request_for_change: File {rfc.file_path} is not found in the file context."
            )

            files_str = ""
            for file in self.file_context.files:
                files_str += f" * {file.file_path}\n"

            return ActionResponse.retry(
                f"File {rfc.file_path} is not found in the file context. "
                f"You can only request changes to files that are in file context:\n{files_str}"
            )

        block_span = context_file.get_block_span(rfc.span_id)
        if not block_span and context_file.file.supports_codeblocks:
            spans = self.file_context.get_spans(rfc.file_path)
            span_ids = [span.span_id for span in spans]

            span_not_in_context = context_file.file.module.find_span_by_id(rfc.span_id)
            if span_not_in_context and self.allow_hallucinated_spans:
                logger.info(
                    f"{self}: Span {rfc.span_id} is not found in the context. Will add it."
                )
                block_span = span_not_in_context
                self.file_context.add_span_to_context(
                    file_path=rfc.file_path, span_id=block_span.span_id
                )

            # Check if the LLM is referring to a parent span shown in the prompt
            if (
                span_not_in_context
                and span_not_in_context.initiating_block.has_any_span(set(span_ids))
            ):
                logger.info(
                    f"{self}: Use span {rfc.span_id} as it's a parent span of a span in the context."
                )
                block_span = span_not_in_context

            if not block_span:
                span_str = ", ".join(span_ids)
                logger.warning(
                    f"{self}: Span not found: {rfc.span_id}. Available spans: {span_str}"
                )
                return ActionResponse.retry(
                    f"Span not found: {rfc.span_id}. Available spans: {span_str}"
                )

        # If span is for a class block, consider the whole class
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::6
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):

    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:
        # ... other code
        if block_span:
            start_line = block_span.start_line
            if block_span.initiating_block.type == CodeBlockType.CLASS:
                tokens = block_span.initiating_block.sum_tokens()
                end_line = block_span.initiating_block.end_line
                logger.info(
                    f"{self}: Span {rfc.span_id} is a class block. Consider the whole class ({block_span.initiating_block.start_line} - {end_line}) with {tokens} tokens."
                )
            else:
                tokens = block_span.tokens
                end_line = block_span.end_line

        else:
            span = context_file.get_span(rfc.span_id)
            if not span:
                spans = self.file_context.get_spans(rfc.file_path)
                span_ids = [span.span_id for span in spans]
                span_str = ", ".join(span_ids)
                return ActionResponse.retry(
                    f"Span not found: {rfc.span_id}. Available spans: {span_str}"
                )

            content_lines = context_file.file.content.split("\n")
            start_line = _get_pre_start_line(span.start_line, 1, content_lines)
            end_line = _get_post_end_line_index(
                span.end_line, len(content_lines), content_lines
            )

            # TODO: Support token count in files without codeblock support
            tokens = 0

        if tokens > self.max_tokens_in_edit_prompt:
            logger.info(
                f"{self}: Span has {tokens} tokens, which is higher than the maximum allowed "
                f"{self.max_tokens_in_edit_prompt} tokens. Ask for clarification."
            )
            return ActionResponse.transition(
                trigger="edit_code",
                output={
                    "instructions": rfc.instructions,
                    "file_path": rfc.file_path,
                    "span_id": rfc.span_id,
                },
            )

        return ActionResponse.transition(
            trigger="edit_code",
            output={
                "instructions": rfc.instructions,
                "file_path": rfc.file_path,
                "span_id": rfc.span_id,
                "start_line": start_line,
                "end_line": end_line,
            },
        )
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::7
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):

    def system_prompt(self) -> str:
        return (
            CODER_SYSTEM_PROMPT + SELECT_SPAN_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT
        )

    def to_message(self) -> str:
        response_msg = ""

        if self.message:
            response_msg += self.message

        if self.diff:
            response_msg += f"\n\n<diff>\n{self.diff}\n</diff>"

        if self.verification_errors:
            lint_str = ""
            for lint_message in self.verification_errors:
                lint_str += f" * {lint_message.code}: {lint_message.message} (line {lint_message.line})\n"

            if lint_str:
                response_msg += f"\n\nThe following lint errors was introduced after this change:\n<lint_errors>\n{lint_str}\n</lint_errors>"

        return response_msg
--------------------------------------------------------------------------------
Chunk ID: edit/plan.py::8
Filepath: moatless\edit\plan.py
Content:
class PlanToCode(AgenticState):

    def messages(self) -> list[Message]:
        self.init()

        messages: list[Message] = []

        if self.initial_message:
            content = f"<issue>\n{self.initial_message}\n</issue>\n"
        else:
            content = ""

        previous_states = self.get_previous_states(self)

        for previous_state in previous_states:
            new_message = previous_state.to_message()
            if new_message and not content:
                content = new_message
            elif new_message:
                content += f"\n\n{new_message}"

            messages.append(UserMessage(content=content))
            messages.append(
                AssistantMessage(
                    action=previous_state.last_action.request,
                )
            )
            content = ""

        content += self.to_message()
        file_context_str = self.file_context.create_prompt(
            show_span_ids=True,
            exclude_comments=True,
            show_outcommented_code=True,
            outcomment_code_comment="... rest of the code",
        )

        content += f"\n\n<file_context>\n{file_context_str}\n</file_context>"

        messages.append(UserMessage(content=content))
        messages.extend(self.retry_messages())

        return messages
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::1
Filepath: moatless\edit\plan_lines.py
Content:
import logging
from typing import Optional

from pydantic import ConfigDict, Field

from moatless.codeblocks.codeblocks import CodeBlockTypeGroup
from moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line
from moatless.edit.prompt import (
    CODER_FINAL_SYSTEM_PROMPT,
    CODER_SYSTEM_PROMPT,
    SELECT_LINES_SYSTEM_PROMPT,
)
from moatless.state import AgenticState
from moatless.types import (
    ActionRequest,
    ActionResponse,
    AssistantMessage,
    Message,
    UserMessage,
)
from moatless.utils.tokenizer import count_tokens
from moatless.verify.lint import VerificationError

logger = logging.getLogger("PlanToCode")
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::2
Filepath: moatless\edit\plan_lines.py
Content:
class ApplyChange(ActionRequest):
    """
    Request to apply a change to the code.
    """

    thoughts: str = Field(..., description="Your thoughts on the code change.")

    instructions: Optional[str] = Field(
        None, description="Instructions to do the code change."
    )
    file_path: Optional[str] = Field(
        None, description="The file path of the code to be updated."
    )
    start_line: Optional[int] = Field(
        None, description="The start line of the code to be updated."
    )
    end_line: Optional[int] = Field(
        None, description="The end line of the code to be updated."
    )

    reject: Optional[str] = Field(
        ..., description="Reject the request and explain why."
    )
    finish: Optional[str] = Field(
        None, description="Finish the request and explain why"
    )

    model_config = ConfigDict(
        extra="allow",
    )
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::3
Filepath: moatless\edit\plan_lines.py
Content:
class PlanToCodeWithLines(AgenticState):
    message: Optional[str] = Field(
        None,
        description="Message to the coder",
    )

    # TODO: Move to a new state handling changes
    diff: Optional[str] = Field(
        None,
        description="The diff of a previous code change.",
    )

    # TODO: Move to a new state handling lint problems
    verification_errors: list[VerificationError] | None = Field(
        None,
        description="The verification errors from the previous code change.",
    )

    max_tokens_in_edit_prompt: int = Field(
        500,
        description="The maximum number of tokens in a span to show the edit prompt.",
    )

    expand_context_with_related_spans: bool = Field(
        True,
        description="Whether to expand the context with related spans.",
    )

    include_message_history: bool = Field(
        True,
        description="Whether to include the message history in the prompt.",
    )

    def init(self):
        # TODO: Make addition to context customizable??

        for error in self.verification_errors:
            self.file_context.add_file(
                file_path=error.file_path
            )  # TODO: BY line number!

        self.file_context.expand_context_with_init_spans()

        if (
            self.expand_context_with_related_spans
            and len(self.get_previous_states(self)) == 0
        ):
            self.file_context.expand_context_with_related_spans(max_tokens=4000)

    def _execute_action(self, action: ApplyChange) -> ActionResponse:
        if action.finish:
            self.file_context.save()

            return ActionResponse.transition(
                trigger="finish", output={"message": action.finish}
            )
        elif action.reject:
            return ActionResponse.transition(
                trigger="reject", output={"message": action.reject}
            )

        elif action.file_path:
            return self._request_for_change(action)

        return ActionResponse.retry(
            "You must either provide an apply_change action or finish."
        )

    def action_type(self) -> type[ApplyChange]:
        return ApplyChange
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::4
Filepath: moatless\edit\plan_lines.py
Content:
class PlanToCodeWithLines(AgenticState):

    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:
        logger.info(f"request_for_change(file_path={rfc.file_path}")

        context_file = self.file_context.get_file(rfc.file_path)
        if not context_file:
            logger.warning(
                f"request_for_change: File {rfc.file_path} is not found in the file context."
            )

            files_str = ""
            for file in self.file_context.files:
                files_str += f" * {file.file_path}\n"

            return ActionResponse.retry(
                f"File {rfc.file_path} is not found in the file context. "
                f"You can only request changes to files that are in file context:\n{files_str}"
            )

        if (
            not rfc.start_line
            and context_file.module.sum_tokens() > self.max_tokens_in_edit_prompt
        ):
            return ActionResponse.retry(
                f"The file {rfc.file_path} is to big to edit in one go, please provide start and end line numbers to specify the part of the code that needs to be updated."
            )

        block = context_file.module.find_first_by_start_line(rfc.start_line)

        if block.type.group == CodeBlockTypeGroup.STRUCTURE:
            structure_block = block
        else:
            structure_block = block.find_type_group_in_parents(
                CodeBlockTypeGroup.STRUCTURE
            )

        if structure_block.sum_tokens() < self.max_tokens_in_edit_prompt:
            return ActionResponse.transition(
                trigger="edit_code",
                output={
                    "instructions": rfc.instructions,
                    "file_path": rfc.file_path,
                    "start_line": structure_block.start_line,
                    "end_line": structure_block.end_line,
                },
            )

        last_structure_block_signature_line = structure_block.children[0].start_line - 1
        logger.info(
            f"{self}: Checking if the line numbers only covers a class/function signature to "
            f"{structure_block.path_string()} ({structure_block.start_line} - {last_structure_block_signature_line})"
        )
        if (
            rfc.start_line == block.start_line
            and last_structure_block_signature_line >= rfc.end_line
        ):
            clarify_msg = f"The line numbers {rfc.start_line} - {rfc.end_line} only covers to the signature of the {block.type.value}."
            logger.info(f"{self}: {clarify_msg}. Ask for clarification.")
            # TODO: Ask if this was intentional instead instructing the LLM
            return ActionResponse.retry(
                f"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change."
            )

        code_lines = context_file.file.content.split("\n")
        lines_to_replace = code_lines[rfc.start_line - 1 : rfc.end_line]

        edit_block_code = "\n".join(lines_to_replace)

        tokens = count_tokens(edit_block_code)
        if tokens > self.max_tokens_in_edit_prompt:
            clarify_msg = f"Lines {rfc.start_line} - {rfc.end_line} has {tokens} tokens, which is higher than the maximum allowed {self.max_tokens_in_edit_prompt} tokens in completion"
            logger.info(f"{self} {clarify_msg}. Ask for clarification.")
            return ActionResponse.retry(
                f"{clarify_msg}. You need to specify the exact part of the code that needs to be updated to fulfill the change. If this is not possible you should reject the request."
            )

        start_line = _get_pre_start_line(
            rfc.start_line, structure_block.start_line, code_lines
        )
        end_line = _get_post_end_line_index(
            rfc.end_line, structure_block.end_line, code_lines
        )

        return ActionResponse.transition(
            trigger="edit_code",
            output={
                "instructions": rfc.instructions,
                "file_path": rfc.file_path,
                "start_line": start_line,
                "end_line": end_line,
            },
        )
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::5
Filepath: moatless\edit\plan_lines.py
Content:
class PlanToCodeWithLines(AgenticState):

    def system_prompt(self) -> str:
        return (
            CODER_SYSTEM_PROMPT + SELECT_LINES_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT
        )

    def to_message(self) -> str:
        response_msg = ""

        if self.message:
            response_msg += self.message

        if self.diff:
            response_msg += f"\n\n<diff>\n{self.diff}\n</diff>"

        if self.verification_errors:
            lint_str = ""
            for lint_message in self.verification_errors:
                if lint_message.code[0] in ["E", "F"]:
                    lint_str += f" * {lint_message.code}: {lint_message.message} (line {lint_message.line})\n"

            if lint_str:
                response_msg += f"\n\nThe following lint errors was introduced after this change:\n<lint_errors>\n{lint_str}\n</lint_errors>"

        return response_msg
--------------------------------------------------------------------------------
Chunk ID: edit/plan_lines.py::6
Filepath: moatless\edit\plan_lines.py
Content:
class PlanToCodeWithLines(AgenticState):

    def messages(self) -> list[Message]:
        messages: list[Message] = []

        content = self.initial_message or ""

        previous_states = self.get_previous_states(self)

        for previous_state in previous_states:
            new_message = previous_state.to_message()
            if new_message and not content:
                content = new_message
            elif new_message:
                content += f"\n\n{new_message}"

            messages.append(UserMessage(content=content))
            messages.append(
                AssistantMessage(
                    action=previous_state.last_action.request,
                )
            )
            content = ""

        content += self.to_message()
        file_context_str = self.file_context.create_prompt(
            show_span_ids=False,
            show_line_numbers=True,
            exclude_comments=True,
            show_outcommented_code=True,
            outcomment_code_comment="... rest of the code",
        )

        content += f"\n\n<file_context>\n{file_context_str}\n</file_context>"

        messages.append(UserMessage(content=content))
        messages.extend(self.retry_messages())

        return messages
--------------------------------------------------------------------------------
Chunk ID: edit/prompt.py::1
Filepath: moatless\edit\prompt.py
Content:
CODER_SYSTEM_PROMPT = """You are an autonomous AI assistant with superior programming skills.

Your task is to update the code based on a reported issue wraped in the tag <issue>. 
The files relevant to the issue is provided in the tag <file_context>.

To get started, carefully review the issue and the file context to understand the changes that need to be made.
"""

CODER_FINAL_SYSTEM_PROMPT = """
After receiving the git diff with the updated code, confirm the changes and proceed to the next instruction if applicable.

Use the finish action when the fix of the issue have been properly implemented.

IMPORTANT:
 * Stick to implementing the requirements exactly as specified, without additional changes or suggestions. 
 * Limit code changes to only the specific files included in the current context. Don't modify other files or create new ones.
 * DO NOT suggest changes in surrounding code not DIRECTLY connected to the task. When you solved the issue in the code you're finsihed!
 * DO NOT suggest changes in code that are not in <file_context>.
 * DO NOT suggest code reviews! 
 * Tests are not in scope. Do not search for tests or suggest writing tests.
 * When you are confident that all changes are correct, you can finish the task without further verification.
"""

SELECT_SPAN_SYSTEM_PROMPT = """
The code is separated into code spans; you can update one span at a time.
Before each code change, you first need to request permission to make the change.
You do this by using the `ApplyChange` function, which will verify the change and if approved it will do the change and return a git diff and the updated file context.

When requesting permission for a change, include the following details:

 * The instructions of the specific change you intend to make.
 * The code span you intend to update.
"""

SELECT_LINES_SYSTEM_PROMPT = """You can update one section of the code at a time.

Before each code change, you first need to request permission to make the change.
You do this by using the `ApplyChange` function, which will verify the change and if approved it will do the change and return a git diff and the updated file context.

When requesting permission for a change, include the following details:

 * The instructions of the specific change you intend to make.
 * The start and end line numbers of the code you intend to update.
"""

CLARIFY_CHANGE_SYSTEM_PROMPT = """You are autonomous AI assisistant with superior programming skills.

Please read the instruction and code carefully. Identify the specific lines in the code that need to be modified to fulfill the instruction.

You should specify the start and end line numbers using this function `specify_lines`.  You can only specify one contiguous range of lines.
"""
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::1
Filepath: moatless\edit\review.py
Content:
import logging
from typing import Type, Optional, List

from pydantic import Field, ConfigDict, PrivateAttr

from moatless.codeblocks import CodeBlockType
from moatless.edit.clarify import _get_post_end_line_index, _get_pre_start_line
from moatless.edit.prompt import (
    CODER_SYSTEM_PROMPT,
    SELECT_SPAN_SYSTEM_PROMPT,
    CODER_FINAL_SYSTEM_PROMPT,
)
from moatless.state import AgenticState
from moatless.types import (
    ActionRequest,
    ActionResponse,
    Message,
    UserMessage,
    AssistantMessage,
    CodeChange,
)
from moatless.verify.lint import VerificationError

logger = logging.getLogger("PlanToCode")


class IncludeSpan(ActionRequest):
    file_path: Optional[str] = Field(None, description="Find by file path.")
    class_name: Optional[str] = Field(None, description="Find by class name.")
    function_name: Optional[str] = Field(None, description="Find by function name.")
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::2
Filepath: moatless\edit\review.py
Content:
class ApplyChange(ActionRequest):
    """
    Request to apply a change to the code.
    """

    scratch_pad: str = Field(..., description="Your thoughts on the code change.")

    action: str = Field(
        ...,
        description="The action to take, possible values are 'modify', 'review', 'include', 'finish', 'reject'",
    )

    instructions: Optional[str] = Field(
        None, description="Instructions to do the code change."
    )
    file_path: Optional[str] = Field(
        None, description="The file path of the code to be updated."
    )
    span_id: Optional[str] = Field(
        None, description="The span id of the code to be updated."
    )

    include_spans: Optional[List[IncludeSpan]] = Field(
        None, description="Find spans to include."
    )

    reject: Optional[str] = Field(
        None, description="Reject the request and explain why."
    )
    finish: Optional[str] = Field(
        None, description="Finish the request and explain why"
    )

    model_config = ConfigDict(
        extra="allow",
    )
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::3
Filepath: moatless\edit\review.py
Content:
class ApplyChanges(ActionRequest):
    """
    Request to apply a change to the code.
    """

    scratch_pad: str = Field(..., description="Your thoughts on the code change.")

    action: str = Field(
        ...,
        description="The action to take, possible values are 'modify', 'review', 'include', 'finish', 'reject'",
    )

    changes: Optional[List[CodeChange]] = Field(
        None, description="The changes to apply."
    )

    reject: Optional[str] = Field(
        None, description="Reject the request and explain why."
    )
    finish: Optional[str] = Field(
        None, description="Finish the request and explain why"
    )

    model_config = ConfigDict(
        extra="allow",
    )
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::4
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):
    message: Optional[str] = Field(
        None,
        description="Message to the coder",
    )

    # TODO: Move to a new state handling changes
    diff: Optional[str] = Field(
        None,
        description="The diff of a previous code change.",
    )

    max_prompt_file_tokens: int = Field(
        4000,
        description="The maximum number of tokens in the file context to show in the prompt.",
    )

    max_tokens_in_edit_prompt: int = Field(
        500,
        description="The maximum number of tokens in a span to show the edit prompt.",
    )

    allow_hallucinated_spans: bool = Field(
        False,
        description="Allow hallucinated spans to be used in the edit prompt.",
    )

    finish_on_review: bool = Field(
        False, description="Whether to finish the task if a review is requested."
    )

    finish_on_no_errors: bool = Field(
        False,
        description="Whether to finish the task if no verification errors are found.",
    )

    include_message_history: bool = Field(
        True,
        description="Whether to include the message history in the prompt.",
    )

    _verification_errors: List[VerificationError] = PrivateAttr(default_factory=list)

    def init(self) -> Optional[ActionResponse]:
        self._verification_errors = self.workspace.verify()

        self.file_context.reset_verification_errors()

        for verification_error in self._verification_errors:
            logger.info(f"Verification error: {verification_error}")
            self.file_context.add_verification_error(verification_error)

        if self.finish_on_no_errors and not self._verification_errors:
            return ActionResponse.transition(
                trigger="finish", output={"message": "No errors to review."}
            )

        return None
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::5
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):

    def _execute_action(self, action: ApplyChange) -> ActionResponse:
        if action.action == "review":
            if self.diff and self.finish_on_review:
                logger.info(f"Review suggested after diff, will finish")
                return ActionResponse.transition(
                    trigger="finish", output={"message": "Finish on suggested review."}
                )
            else:
                return ActionResponse.retry(
                    "Review isn't possible. If the change is done you can finish or reject the task."
                )

        if action.include_spans:
            found_response = ""
            not_found_response = ""
            for include_span in action.include_spans:
                logger.info(
                    f"include_span(file_path={include_span.file_path}, class_name={include_span.class_name}, function_name={include_span.function_name})"
                )

                if not include_span.class_name and not include_span.function_name:
                    return ActionResponse.retry(
                        "You must provide either a class name or a function name or both."
                    )

                search_response = self.workspace.code_index.find_by_name(
                    class_names=[include_span.class_name],
                    function_names=[include_span.function_name],
                )
                if len(search_response.hits) == 1:
                    found_response += f" * {search_response.hits[0].file_path}\n"
                    for span in search_response.hits[0].spans:
                        self.file_context.add_span_to_context(
                            file_path=search_response.hits[0].file_path,
                            span_id=span.span_id,
                        )
                        found_response += f"   - {span}\n"
                elif len(search_response.hits) > 1 and include_span.file_path:
                    file_name = include_span.file_path.split("/")[-1]
                    for hit in search_response.hits:
                        if file_name in hit.file_path:
                            found_response += f" * {hit.file_path}\n"
                            for span in hit.spans:
                                self.file_context.add_span_to_context(
                                    file_path=hit.file_path,
                                    span_id=span.span_id,
                                )
                                found_response += f"   - {span}\n"
                else:
                    if include_span.file_path:
                        not_found_response += f"{include_span.file_path}"

                    if include_span.class_name:
                        not_found_response += f" class: {include_span.class_name}"

                    if include_span.function_name:
                        not_found_response += f" function: {include_span.function_name}"

            response = ""
            if found_response:
                response += f"Found the following spans:\n{found_response}"

            if not_found_response:
                response += (
                    f"\nCouldn't find the following spans:\n{not_found_response}"
                )

            return ActionResponse.retry(response)

        if action.finish:
            self.file_context.save()

            return ActionResponse.transition(
                trigger="finish", output={"message": action.finish}
            )
        elif action.reject:
            return ActionResponse.transition(
                trigger="reject", output={"message": action.reject}
            )

        elif action.file_path and action.span_id:
            return self._request_for_change(action)

        return ActionResponse.retry(
            "You must either provide an apply_change action or finish."
        )

    def action_type(self) -> Type[ApplyChange]:
        return ApplyChange
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::6
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):

    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:
        logger.info(
            f"request_for_change(file_path={rfc.file_path}, span_id={rfc.span_id})"
        )

        context_file = self.file_context.get_file(rfc.file_path)
        if not context_file:
            logger.warning(
                f"request_for_change: File {rfc.file_path} is not found in the file context."
            )

            files_str = ""
            for file in self.file_context.files:
                files_str += f" * {file.file_path}\n"

            return ActionResponse.retry(
                f"File {rfc.file_path} is not found in the file context. "
                f"You can only request changes to files that are in file context:\n{files_str}. You can try to add them by using the include_span action."
            )

        block_span = context_file.get_block_span(rfc.span_id)
        if not block_span and context_file.file.supports_codeblocks:
            spans = self.file_context.get_spans(rfc.file_path)
            span_ids = [span.span_id for span in spans]

            span_not_in_context = context_file.file.module.find_span_by_id(rfc.span_id)
            if span_not_in_context and self.allow_hallucinated_spans:
                logger.info(
                    f"{self}: Span {rfc.span_id} is not found in the context. Will add it."
                )
                block_span = span_not_in_context
                self.file_context.add_span_to_context(
                    file_path=rfc.file_path, span_id=block_span.span_id
                )

            # Check if the LLM is referring to a parent span shown in the prompt
            if (
                span_not_in_context
                and span_not_in_context.initiating_block.has_any_span(set(span_ids))
            ):
                logger.info(
                    f"{self}: Use span {rfc.span_id} as it's a parent span of a span in the context."
                )
                block_span = span_not_in_context

            if not block_span:
                span_str = ", ".join(span_ids)
                logger.warning(
                    f"{self}: Span not found: {rfc.span_id}. Available spans: {span_str}"
                )
                return ActionResponse.retry(
                    f"Span not found: {rfc.span_id}. Available spans: {span_str}"
                )

        # If span is for a class block, consider the whole class
        if block_span:
            start_line = block_span.start_line
            if block_span.initiating_block.type == CodeBlockType.CLASS:
                tokens = block_span.initiating_block.sum_tokens()
                end_line = block_span.initiating_block.end_line
                logger.info(
                    f"{self}: Span {rfc.span_id} is a class block. Consider the whole class ({block_span.initiating_block.start_line} - {end_line}) with {tokens} tokens."
                )
            else:
                tokens = block_span.tokens
                end_line = block_span.end_line

        else:
            span = context_file.get_span(rfc.span_id)
            if not span:
                spans = self.file_context.get_spans(rfc.file_path)
                span_ids = [span.span_id for span in spans]
                span_str = ", ".join(span_ids)
                return ActionResponse.retry(
                    f"Span not found: {rfc.span_id}. Available spans: {span_str}"
                )

            content_lines = context_file.file.content.split("\n")
            start_line = _get_pre_start_line(span.start_line, 1, content_lines)
            end_line = _get_post_end_line_index(
                span.end_line, len(content_lines), content_lines
            )

            # TODO: Support token count in files without codeblock support
            tokens = 0
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::7
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):

    def _request_for_change(self, rfc: ApplyChange) -> ActionResponse:
        # ... other code

        if tokens > self.max_tokens_in_edit_prompt:
            logger.info(
                f"{self}: Span has {tokens} tokens, which is higher than the maximum allowed "
                f"{self.max_tokens_in_edit_prompt} tokens. Ask for clarification."
            )
            return ActionResponse.transition(
                trigger="edit_code",
                output={
                    "instructions": rfc.instructions,
                    "file_path": rfc.file_path,
                    "span_id": rfc.span_id,
                },
            )

        return ActionResponse.transition(
            trigger="edit_code",
            output={
                "instructions": rfc.instructions,
                "file_path": rfc.file_path,
                "span_id": rfc.span_id,
                "start_line": start_line,
                "end_line": end_line,
            },
        )
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::8
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):

    def system_prompt(self) -> str:
        return (
            CODER_SYSTEM_PROMPT + SELECT_SPAN_SYSTEM_PROMPT + CODER_FINAL_SYSTEM_PROMPT
        )

    def to_message(self) -> str:
        response_msg = ""

        if self.message:
            response_msg += self.message

        if self.diff:
            response_msg += f"\n\n<diff>\n{self.diff}\n</diff>"

        error_str = ""
        for verification_error in self._verification_errors:
            error_str += f" * {verification_error.code}: {verification_error.message} (file: {verification_error.file_path}, line {verification_error.line})\n"

        if error_str:
            response_msg += (
                f"\n\nThe following verification errors was found:\n\n{error_str}\n"
            )

        return response_msg
--------------------------------------------------------------------------------
Chunk ID: edit/review.py::9
Filepath: moatless\edit\review.py
Content:
class ReviewCode(AgenticState):

    def messages(self) -> list[Message]:
        messages: list[Message] = []

        if self.initial_message:
            content = f"<main_objective>\n{self.initial_message}\n</main_objective>"
        else:
            content = ""

        previous_states = self.get_previous_states(self)

        for previous_state in previous_states:
            new_message = previous_state.to_message()
            if new_message and not content:
                content = new_message
            elif new_message:
                content += f"\n\n{new_message}"

            messages.append(UserMessage(content=content))
            messages.append(
                AssistantMessage(
                    action=previous_state.last_action.request,
                )
            )
            content = ""

        content += self.to_message()
        file_context_str = self.file_context.create_prompt(
            show_span_ids=True,
            show_line_numbers=True,
            exclude_comments=False,
            show_outcommented_code=True,
            outcomment_code_comment="... rest of the code",
        )

        content += f"\n\n<file_context>\n{file_context_str}\n</file_context>"

        messages.append(UserMessage(content=content))
        messages.extend(self.retry_messages())

        return messages
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::1
Filepath: moatless\file_context.py
Content:
import json
import logging
from dataclasses import dataclass
from typing import Optional, List, Dict, Set

from pydantic import BaseModel, ConfigDict
from pydantic.v1 import PrivateAttr

from moatless.codeblocks import CodeBlockType
from moatless.codeblocks.codeblocks import (
    BlockSpan,
    CodeBlock,
    CodeBlockTypeGroup,
    SpanMarker,
    SpanType,
)
from moatless.repository import CodeFile, FileRepository, UpdateResult
from moatless.types import FileWithSpans

logger = logging.getLogger(__name__)


class RankedFileSpan(BaseModel):
    file_path: str
    span_id: str
    rank: int = 0
    tokens: int = 0


class ContextSpan(BaseModel):
    span_id: str
    start_line: Optional[int] = None
    end_line: Optional[int] = None
    tokens: Optional[int] = None


@dataclass
class CurrentPromptSpan:
    span_id: Optional[str] = None
    tokens: int = 0
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::2
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):
    file: CodeFile
    spans: List[ContextSpan] = []
    show_all_spans: bool = False

    def __init__(self, **data):
        super().__init__(**data)

    def model_dump(self, **kwargs):
        data = super().model_dump(**kwargs, exclude={"file"})
        data["file_path"] = self.file.file_path
        return data

    @property
    def file_path(self):
        return self.file.file_path

    @property
    def module(self):
        return self.file.module

    @property
    def content(self):
        return self.file.content

    @property
    def span_ids(self):
        return {span.span_id for span in self.spans}
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::3
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def to_prompt(
        self,
        show_span_ids=False,
        show_line_numbers=False,
        exclude_comments=False,
        show_outcommented_code=False,
        outcomment_code_comment: str = "...",
    ):
        if self.file.supports_codeblocks:
            if (
                not self.show_all_spans
                and self.span_ids is not None
                and len(self.span_ids) == 0
            ):
                logger.warning(
                    f"No span ids provided for {self.file_path}, return empty"
                )
                return ""

            code = self._to_prompt(
                code_block=self.module,
                show_span_id=show_span_ids,
                show_line_numbers=show_line_numbers,
                outcomment_code_comment=outcomment_code_comment,
                show_outcommented_code=show_outcommented_code,
                exclude_comments=exclude_comments,
            )
        else:
            code = self._to_prompt_with_line_spans(show_span_id=show_span_ids)

        return f"{self.file_path}\n```\n{code}\n```\n"
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::4
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def _find_span(self, codeblock: CodeBlock) -> Optional[ContextSpan]:
        if not codeblock.belongs_to_span:
            return None

        for span in self.spans:
            if codeblock.belongs_to_span.span_id == span.span_id:
                return span

        return None

    def _within_span(self, line_no: int) -> Optional[ContextSpan]:
        for span in self.spans:
            if (
                span.start_line
                and span.end_line
                and span.start_line <= line_no <= span.end_line
            ):
                return span
        return None
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::5
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def _to_prompt_with_line_spans(self, show_span_id: bool = False) -> str:
        content_lines = self.content.split("\n")

        if not self.span_ids:
            return self.content

        prompt_content = ""
        outcommented = True
        for i, line in enumerate(content_lines):
            line_no = i + 1

            span = self._within_span(line_no)
            if span:
                if outcommented and show_span_id:
                    prompt_content += f"<span id={span.span_id}>\n"

                prompt_content += line + "\n"
                outcommented = False
            elif not outcommented:
                prompt_content += "... other code\n"
                outcommented = True

        return prompt_content
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::6
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def _to_prompt(
        self,
        code_block: CodeBlock,
        current_span: Optional[CurrentPromptSpan] = None,
        show_outcommented_code: bool = True,
        outcomment_code_comment: str = "...",
        show_span_id: bool = False,
        show_line_numbers: bool = False,
        exclude_comments: bool = False,
    ):
        if current_span is None:
            current_span = CurrentPromptSpan()
        contents = ""

        outcommented_block = None
        for _i, child in enumerate(code_block.children):
            if exclude_comments and child.type.group == CodeBlockTypeGroup.COMMENT:
                continue

            show_new_span_id = False
            show_child = False
            child_span = self._find_span(child)

            if child_span:
                if child_span.span_id != current_span.span_id:
                    show_child = True
                    show_new_span_id = show_span_id
                    current_span = CurrentPromptSpan(child_span.span_id)
                elif not child_span.tokens:
                    show_child = True
                else:
                    # Count all tokens in child block if it's not a structure (function or class) or a 'compound' (like an 'if' or 'for' clause)
                    if (
                        child.type.group == CodeBlockTypeGroup.IMPLEMENTATION
                        and child.type
                        not in [CodeBlockType.COMPOUND, CodeBlockType.DEPENDENT_CLAUSE]
                    ):
                        child_tokens = child.sum_tokens()
                    else:
                        child_tokens = child.tokens

                    if current_span.tokens + child_tokens <= child_span.tokens:
                        show_child = True

                    current_span.tokens += child_tokens

            elif (
                not child.belongs_to_span or child.belongs_to_any_span not in self.spans
            ) and child.has_any_span(self.span_ids):
                show_child = True

                if (
                    child.belongs_to_span
                    and current_span.span_id != child.belongs_to_span.span_id
                ):
                    show_new_span_id = show_span_id
                    current_span = CurrentPromptSpan(child.belongs_to_span.span_id)

            if self.show_all_spans:
                show_child = True

            if show_child:
                if outcommented_block:
                    contents += outcommented_block._to_prompt_string(
                        show_line_numbers=show_line_numbers
                    )

                outcommented_block = None

                contents += child._to_prompt_string(
                    show_span_id=show_new_span_id,
                    show_line_numbers=show_line_numbers,
                    span_marker=SpanMarker.TAG,
                )
                contents += self._to_prompt(
                    code_block=child,
                    exclude_comments=exclude_comments,
                    show_outcommented_code=show_outcommented_code,
                    outcomment_code_comment=outcomment_code_comment,
                    show_span_id=show_span_id,
                    current_span=current_span,
                    show_line_numbers=show_line_numbers,
                )
            elif show_outcommented_code and not outcommented_block:
                outcommented_block = child.create_commented_out_block(
                    outcomment_code_comment
                )
                outcommented_block.start_line = child.start_line

        if (
            outcomment_code_comment
            and outcommented_block
            and child.type
            not in [
                CodeBlockType.COMMENT,
                CodeBlockType.COMMENTED_OUT_CODE,
                CodeBlockType.SPACE,
            ]
        ):
            contents += outcommented_block._to_prompt_string(
                show_line_numbers=show_line_numbers
            )

        return contents
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::7
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def context_size(self):
        if self.file.supports_codeblocks:
            if self.span_ids is None:
                return self.module.sum_tokens()
            else:
                tokens = 0
                for span_id in self.span_ids:
                    span = self.module.find_span_by_id(span_id)
                    if span:
                        tokens += span.tokens
                return tokens
        else:
            return 0  # TODO: Support context size...

    def add_spans(
        self,
        span_ids: Set[str],
        tokens: Optional[int] = None,
    ):
        for span_id in span_ids:
            self.add_span(span_id, tokens)
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::8
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def add_span(
        self,
        span_id: str,
        tokens: Optional[int] = None,
    ):
        existing_span = next(
            (span for span in self.spans if span.span_id == span_id), None
        )

        if existing_span:
            existing_span.tokens = tokens
        else:
            span = self.module.find_span_by_id(span_id)
            if span:
                self.spans.append(ContextSpan(span_id=span_id, tokens=tokens))
            else:
                logger.info(
                    f"Could not find span with id {span_id} in file {self.file_path}"
                )
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::9
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def add_line_span(self, start_line: int, end_line: int):
        module = self.file.module

        logger.info(f"Adding line span {start_line} - {end_line} to {self.file_path}")
        if module:
            block = module.find_first_by_start_line(start_line)
            structure_block = block.structure_block()
            self.spans.append(
                ContextSpan(span_id=structure_block.belongs_to_span.span_id)
            )
        else:
            logger.warning(f"Could not find module for file {self.file_path}")
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::10
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def remove_span(self, span_id: str):
        self.spans = [span for span in self.spans if span.span_id != span_id]

    def get_spans(self) -> List[BlockSpan]:
        block_spans = []
        for span in self.spans:
            if not self.file.supports_codeblocks:
                continue

            block_span = self.module.find_span_by_id(span.span_id)
            if block_span:
                block_spans.append(block_span)
        return block_spans

    def get_block_span(self, span_id: str) -> Optional[BlockSpan]:
        if not self.file.supports_codeblocks:
            return None
        for span in self.spans:
            if span.span_id == span_id:
                block_span = self.module.find_span_by_id(span_id)
                if block_span:
                    return block_span
                else:
                    logger.warning(
                        f"Could not find span with id {span_id} in file {self.file_path}"
                    )
        return None

    def get_span(self, span_id: str) -> Optional[ContextSpan]:
        for span in self.spans:
            if span.span_id == span_id:
                return span
        return None
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::11
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def update_content_by_line_numbers(
        self, start_line_index: int, end_line_index: int, replacement_content: str
    ) -> UpdateResult:
        update_result = self.file.update_content_by_line_numbers(
            start_line_index, end_line_index, replacement_content
        )

        if update_result.new_span_ids:
            logger.info(
                f"Adding new spans: {update_result.new_span_ids} to {self.file_path}"
            )
            self.add_spans(update_result.new_span_ids)

        return update_result
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::12
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def expand_context_with_init_spans(self):
        init_spans = set()
        if not self.file.supports_codeblocks:
            return

        for child in self.module.children:
            if (
                child.type == CodeBlockType.IMPORT
                and child.belongs_to_span.span_type == SpanType.INITATION
                and child.belongs_to_span.span_id not in init_spans
            ):
                self.add_span(child.belongs_to_span.span_id)

        for span_id in self.span_ids:
            span = self.module.find_span_by_id(span_id)
            if span and span.initiating_block.type == CodeBlockType.CLASS:
                for child in span.initiating_block.children:
                    if (
                        child.belongs_to_span.span_type == SpanType.INITATION
                        and child.belongs_to_span.span_id not in init_spans
                    ):
                        self.add_span(child.belongs_to_span.span_id)
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::13
Filepath: moatless\file_context.py
Content:
class ContextFile(BaseModel):

    def expand_small_classes(self, max_tokens: int):
        """
        Expand small classes with no other spans selected if the context allows it.

        TODO: This a temporary solution, should be handled by asking the LLM to specify spans in the Identify step.
        """
        if not self.file.supports_codeblocks:
            return

        if len(self.spans) == 1:
            span = self.module.find_span_by_id(self.spans[0].span_id)
            if (
                span
                and span.initiating_block.type == CodeBlockType.CLASS
                and span.initiating_block.sum_tokens() < max_tokens
            ):
                for span_id in span.initiating_block.get_all_span_ids():
                    self.add_span(span_id)
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::14
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):
    _repo: FileRepository = PrivateAttr()
    _file_context: Dict[str, ContextFile] = PrivateAttr(default_factory=dict)
    _max_tokens: int = PrivateAttr(default=4000)

    model_config = ConfigDict(arbitrary_types_allowed=True)

    def __init__(self, repo: FileRepository, **data):
        super().__init__(**data)
        self._repo = repo
        if "_file_context" not in self.__dict__:
            self.__dict__["_file_context"] = {}
        if "_max_tokens" not in self.__dict__:
            self.__dict__["_max_tokens"] = data.get("max_tokens", 4000)

    @classmethod
    def from_dir(cls, repo_dir: str, max_tokens: int = 4000):
        repo = FileRepository(repo_dir)
        instance = cls(max_tokens=max_tokens, repo=repo)
        return instance

    @classmethod
    def from_json(cls, repo_dir: str, json_data: str):
        """
        Create a FileContext instance from JSON data.

        :param repo_dir: The repository directory path.
        :param json_data: A JSON string representing the FileContext data.
        :return: A new FileContext instance.
        """
        data = json.loads(json_data)
        return cls.from_dict(repo_dir, data)

    @classmethod
    def from_dict(cls, repo_dir: str, data: Dict):
        repo = FileRepository(repo_dir)
        instance = cls(max_tokens=data.get("max_tokens", 4000), repo=repo)
        instance.load_files_from_dict(data.get("files", []))
        return instance
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::15
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def load_files_from_dict(self, files: list[dict]):
        for file_data in files:
            file_path = file_data["file_path"]
            show_all_spans = file_data.get("show_all_spans", False)
            spans = [ContextSpan(**span) for span in file_data.get("spans", [])]
            self._file_context[file_path] = ContextFile(
                file=self._repo.get_file(file_path),
                spans=spans,
                show_all_spans=show_all_spans,
            )
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::16
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def model_dump(self, **kwargs):
        if "exclude_none" not in kwargs:
            kwargs["exclude_none"] = True

        files = [
            file.model_dump(**kwargs)
            for file in self.__dict__["_file_context"].values()
        ]
        return {"max_tokens": self.__dict__["_max_tokens"], "files": files}

    def snapshot(self):
        dict = self.model_dump()
        del dict["max_tokens"]
        return dict

    def restore_from_snapshot(self, snapshot: dict):
        self._file_context = {}
        self.load_files_from_dict(snapshot.get("files", []))

    def to_files_with_spans(self) -> List[FileWithSpans]:
        return [
            FileWithSpans(file_path=file_path, span_ids=list(file.span_ids))
            for file_path, file in self._file_context.items()
        ]

    def add_files_with_spans(self, files_with_spans: List[FileWithSpans]):
        for file_with_spans in files_with_spans:
            self.add_spans_to_context(
                file_with_spans.file_path, set(file_with_spans.span_ids)
            )

    def add_file(self, file_path: str, show_all_spans: bool = False):
        if file_path not in self._file_context:
            self._file_context[file_path] = ContextFile(
                file=self._repo.get_file(file_path),
                spans=[],
                show_all_spans=show_all_spans,
            )

    def add_file_with_lines(
        self, file_path: str, start_line: int, end_line: Optional[int] = None
    ):
        end_line = end_line or start_line
        if file_path not in self._file_context:
            self._file_context[file_path] = ContextFile(
                file=self._repo.get_file(file_path), spans=[]
            )

        self._file_context[file_path].add_line_span(start_line, end_line)

    def remove_file(self, file_path: str):
        if file_path in self._file_context:
            del self._file_context[file_path]

    def exists(self, file_path: str):
        return file_path in self._file_context

    @property
    def files(self):
        return list(self._file_context.values())

    def get_file(
        self, file_path: str, add_if_not_found: bool = False
    ) -> Optional[ContextFile]:
        context_file = self._file_context.get(file_path)
        if not context_file and add_if_not_found:
            file = self._repo.get_file(file_path)
            if file:
                context_file = ContextFile(file=file, spans=[])
                self._file_context[file_path] = context_file

        return context_file

    def add_spans_to_context(
        self,
        file_path: str,
        span_ids: Set[str],
        tokens: Optional[int] = None,
    ):
        context_file = self.get_context_file(file_path)
        if context_file:
            context_file.add_spans(span_ids, tokens)
        else:
            logger.warning(f"Could not find file {file_path} in the repository")

    def add_span_to_context(
        self, file_path: str, span_id: str, tokens: Optional[int] = None
    ):
        context_file = self.get_context_file(file_path)
        if context_file:
            context_file.add_span(span_id, tokens)

    def add_line_span_to_context(self, file_path: str, start_line: int, end_line: int):
        context_file = self.get_context_file(file_path)
        if context_file:
            context_file.add_line_span(start_line, end_line)
        else:
            logger.warning(f"Could not find file {file_path} in the repository")
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::17
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def remove_span_from_context(
        self, file_path: str, span_id: str, remove_file: bool = False
    ):
        context_file = self.get_context_file(file_path)
        if context_file:
            context_file.remove_span(span_id)

            if not context_file.spans and remove_file:
                self.remove_file(file_path)

    def remove_spans_from_context(
        self, file_path: str, span_ids: List[str], remove_file: bool = False
    ):
        for span_id in span_ids:
            self.remove_span_from_context(file_path, span_id, remove_file)

    def get_spans(self, file_path: str) -> List[BlockSpan]:
        context_file = self.get_context_file(file_path)
        if context_file:
            return context_file.get_spans()
        return []

    def get_span(self, file_path: str, span_id: str) -> Optional[BlockSpan]:
        context_file = self.get_context_file(file_path)
        if context_file:
            return context_file.get_block_span(span_id)
        return None

    def has_span(self, file_path: str, span_id: str):
        context_file = self.get_context_file(file_path)
        if context_file:
            return span_id in context_file.span_ids
        return False
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::18
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def add_ranked_spans(
        self,
        ranked_spans: List[RankedFileSpan],
        decay_rate: float = 1.05,
        min_tokens: int = 50,
    ):
        if not ranked_spans:
            logger.info("No ranked spans provided")
            return

        sum_tokens = sum(span.tokens for span in ranked_spans)
        if sum_tokens < self._max_tokens:
            logger.info(
                f"Adding all {len(ranked_spans)} spans with {sum_tokens} tokens"
            )
            for span in ranked_spans:
                self.add_span_to_context(span.file_path, span.span_id)
            return

        ranked_spans.sort(key=lambda x: x.rank)

        base_tokens_needed = sum(min(span.tokens, min_tokens) for span in ranked_spans)

        # Filter out the lowest ranking spans if necessary
        while base_tokens_needed > self._max_tokens and ranked_spans:
            removed_span = ranked_spans.pop()
            base_tokens_needed -= min(removed_span.tokens, min_tokens)

        if not ranked_spans:
            raise ValueError(
                "Not enough tokens to meet the minimum token requirement for any span"
            )

        remaining_tokens = self._max_tokens - base_tokens_needed

        # Calculate total weights using exponential decay
        total_weight = sum([decay_rate ** (-span.rank) for span in ranked_spans])

        # Assign tokens based on the weight and the span's token count
        tokens_distribution = []
        for span in ranked_spans:
            weight = decay_rate ** (-span.rank)
            allocated_tokens = min(
                span.tokens,
                min_tokens + int(remaining_tokens * (weight / total_weight)),
            )
            tokens_distribution.append((span, allocated_tokens))

        # Adjust tokens for spans with the same rank
        rank_groups = {}
        for span, tokens in tokens_distribution:
            if span.rank not in rank_groups:
                rank_groups[span.rank] = []
            rank_groups[span.rank].append((span, tokens))

        final_tokens_distribution = []
        for _rank, group in rank_groups.items():
            for span, tokens in group:
                adjusted_tokens = min(span.tokens, tokens)
                final_tokens_distribution.append((span, adjusted_tokens))

        # Distribute tokens and add spans to the context
        sum_tokens = 0
        for span, tokens in final_tokens_distribution:
            self.add_span_to_context(span.file_path, span.span_id, tokens)
            sum_tokens += tokens

        logger.info(
            f"Added {len(final_tokens_distribution)} spans with {sum_tokens} tokens"
        )
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::19
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def expand_context_with_init_spans(self):
        for file in self._file_context.values():
            file.expand_context_with_init_spans()

    def expand_small_classes(self, max_tokens: int):
        for file in self._file_context.values():
            file.expand_small_classes(max_tokens)

    def expand_context_with_related_spans(
        self, max_tokens: int, set_tokens: bool = False
    ):
        # Add related spans if context allows it
        if self.context_size() > max_tokens:
            return

        spans = []
        for file in self._file_context.values():
            if not file.file.supports_codeblocks:
                continue
            if not file.span_ids:
                continue

            for span in file.spans:
                spans.append((file, span))

        spans.sort(key=lambda x: x[1].tokens or 0, reverse=True)

        for file, span in spans:
            span_id = span.span_id
            related_span_ids = file.module.find_related_span_ids(span_id)

            for related_span_id in related_span_ids:
                if related_span_id in file.span_ids:
                    continue

                related_span = file.module.find_span_by_id(related_span_id)

                tokens = max(related_span.tokens, span.tokens or 0)
                if tokens + self.context_size() > max_tokens:
                    return spans

                if set_tokens:
                    file.add_span(related_span_id, tokens=tokens)
                else:
                    file.add_span(related_span_id)

        return spans
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::20
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def get_context_file(self, file_path: str) -> Optional[ContextFile]:
        if file_path not in self._file_context:
            file = self._repo.get_file(file_path)
            if not file:
                return None
            self._file_context[file_path] = ContextFile(
                file=self._repo.get_file(file_path), spans=[]
            )

        return self._file_context[file_path]

    def context_size(self):
        return sum(file.context_size() for file in self._file_context.values())

    def save_file(self, file_path: str, updated_content: Optional[str] = None):
        self._repo.save_file(file_path, updated_content)

    def save(self):
        self._repo.save()

    def reset(self):
        self._file_context = {}

    def strip_line_breaks_only(self, text):
        return text.lstrip("\n\r").rstrip("\n\r")
--------------------------------------------------------------------------------
Chunk ID: moatless/file_context.py::21
Filepath: moatless\file_context.py
Content:
class FileContext(BaseModel):

    def create_prompt(
        self,
        show_span_ids=False,
        show_line_numbers=False,
        exclude_comments=False,
        show_outcommented_code=False,
        outcomment_code_comment: str = "...",
    ):
        file_context_content = ""
        for file in self._file_context.values():
            content = file.to_prompt(
                show_span_ids,
                show_line_numbers,
                exclude_comments,
                show_outcommented_code,
                outcomment_code_comment,
            )
            file_context_content += "\n\n" + content
        return self.strip_line_breaks_only(file_context_content)
--------------------------------------------------------------------------------
Chunk ID: find/__init__.py::1
Filepath: moatless\find\__init__.py
Content:
from moatless.find.search import SearchCode
from moatless.find.identify import IdentifyCode
from moatless.find.decide import DecideRelevance
--------------------------------------------------------------------------------
Chunk ID: find/decide.py::1
Filepath: moatless\find\decide.py
Content:
import logging
from typing import Optional

from pydantic import BaseModel, Field

from moatless.find import SearchCode
from moatless.state import AgenticState
from moatless.types import (
    ActionRequest,
    ActionResponse,
    Message,
    UserMessage,
)

logger = logging.getLogger(__name__)


MAYBE_FINISH_SYSTEM_PROMPT = """You will be provided a reported issue and the file context containing existing code from the project's git repository. 
Your task is to make a decision if the code related to a reported issue is provided in the file context. 

# Input Structure:

* <issue>: Contains the reported issue.
* <file_context>: The file context.

Instructions:

 * Analyze the Issue:
   * Review the reported issue to understand what functionality or bug fix is being requested.

 * Analyze File Context:
  * Examine the provided file context to identify if the relevant code for the reported issue is present.
  * If the issue suggests that code should be implemented and doesn't yet exist in the code, consider the task completed if relevant code is found that would be modified to implement the new functionality.
  * If relevant code in the file context points to other parts of the codebase not included, note these references.

 * Make a Decision:
  * Decide if the relevant code is found in the file context.
  * If you believe all existing relevant code is identified, mark the task as complete.
  * If the specific method or code required to fix the issue is not present, still mark the task as complete as long as the relevant class or area for modification is identified.
  * If you believe more relevant code can be identified, mark the task as not complete and provide your suggestions on how to find the relevant code.

Important:
 * You CANNOT change the codebase. DO NOT modify or suggest changes to any code.
 * Your task is ONLY to determine if the file context is complete. Do not go beyond this scope.
"""
--------------------------------------------------------------------------------
Chunk ID: find/decide.py::2
Filepath: moatless\find\decide.py
Content:
class Decision(ActionRequest):
    """Provide your decision if all relevant file context is provided."""

    scratch_pad: str = Field(
        description="Your thoughts on if the spans where relevant or not and if you found all relevant spans and can finish.."
    )

    relevant: bool = Field(
        default=False,
        description="Set to true if the relevant code have been identified.",
    )

    complete: bool = Field(
        default=False,
        description="Set to true if all the relevant code have been identified.",
    )

    search_suggestions: Optional[str] = Field(
        None,
        description="Suggestions on how to find the relevant code not found in the file context.",
    )
--------------------------------------------------------------------------------
Chunk ID: find/decide.py::3
Filepath: moatless\find\decide.py
Content:
class DecideRelevance(AgenticState):
    expand_context: bool = Field(
        False,
        description="If true, the file context will be expanded with additional context.",
    )
    finish_after_relevant_count: int = Field(
        2,
        description="Finish the task after this many relevant decisions have been made but not complete.",
    )
    max_prompt_file_tokens: int = Field(
        4000,
        description="The maximum number of tokens to include in the file context prompt.",
    )

    def _execute_action(self, action: Decision) -> ActionResponse:
        if action.complete and action.relevant:
            return ActionResponse.transition("finish")

        if (
            action.relevant
            and self._relevant_count() >= self.finish_after_relevant_count
        ):
            return ActionResponse.transition("finish")

        return ActionResponse.transition(
            "search",
            output={"message": action.search_suggestions},
        )

    def _relevant_count(self) -> int:
        """
        Count the number of times a decision was made that the file context was relevant.
        """
        relevant_count = 0
        previous_states = self.get_previous_states(self)
        for previous_state in previous_states:
            if (
                previous_state.last_action
                and previous_state.last_action.request.relevant
            ):
                relevant_count += 1
        return relevant_count

    def action_type(self) -> type[BaseModel] | None:
        return Decision

    def system_prompt(self) -> str:
        return MAYBE_FINISH_SYSTEM_PROMPT

    def _last_scratch_pad(self):
        previous_states = self.get_previous_states()
        if previous_states and previous_states[-1].last_action:
            last_action = previous_states[-1].last_action
            return last_action.request.scratch_pad
        else:
            return None
--------------------------------------------------------------------------------
Chunk ID: find/decide.py::4
Filepath: moatless\find\decide.py
Content:
class DecideRelevance(AgenticState):

    def messages(self) -> list[Message]:
        messages: list[Message] = []

        if self.expand_context:
            self.file_context.expand_context_with_init_spans()
            self.file_context.expand_context_with_related_spans(
                max_tokens=self.max_prompt_file_tokens
            )
            self.file_context.expand_small_classes(
                max_tokens=self.max_prompt_file_tokens
            )

        file_context_str = self.file_context.create_prompt(
            show_span_ids=False,
            show_line_numbers=False,
            exclude_comments=True,
            show_outcommented_code=True,
            outcomment_code_comment="... rest of the code",
        )

        content = f"""<issue>
{self.initial_message}
</issue>
"""

        scratch_pad = self._last_scratch_pad()
        if scratch_pad:
            content += f"""<scratch_pad>
{scratch_pad}
</scratch_pad>"""

        content += f"""
<file_context>
{file_context_str}
</file_context>
"""

        messages.append(UserMessage(content=content))
        return messages
--------------------------------------------------------------------------------
Chunk ID: find/find_code_snippet.py::1
Filepath: moatless\find\find_code_snippet.py
Content:
import logging
import os

logger = logging.getLogger(__name__)

ignored_dirs = ["target", "node_modules", ".git", ".idea"]


def find_code_snippet_in_files(repo_dir: str, code_snippet: str):
    occurrences = []

    for root, _dirs, files in os.walk(repo_dir):
        for file in files:
            if any(dir in root for dir in ignored_dirs):
                continue

            file_path = os.path.join(root, file)
            if not file_path.endswith(".java"):
                continue
            try:
                with open(file_path, encoding="utf-8") as f:
                    for line_number, line in enumerate(f, start=1):
                        if code_snippet.lower() in line.lower():
                            relative_path = os.path.relpath(file_path, repo_dir)
                            occurrences.append(
                                (
                                    relative_path,
                                    line_number,
                                    line.strip(),
                                )
                            )
            except Exception as e:
                if "invalid" not in str(e):
                    logger.error(f"Could not read file {file_path}: {e}")

    return occurrences
--------------------------------------------------------------------------------
Chunk ID: find/identify.py::1
Filepath: moatless\find\identify.py
Content:
import fnmatch
import logging
from typing import Optional

from pydantic import BaseModel, Field

from moatless.file_context import RankedFileSpan
from moatless.state import AgenticState
from moatless.types import (
    ActionRequest,
    ActionResponse,
    FileWithSpans,
    Message,
    UserMessage,
)

logger = logging.getLogger(__name__)


IDENTIFY_SYSTEM_PROMPT = """You are an autonomous AI assistant tasked with finding relevant code in an existing 
codebase based on a reported issue. Your task is to identify the relevant code spans in the provided search 
results and decide whether the search task is complete.

# Input Structure:

* <issue>: Contains the reported issue.
* <file_context>: Contains the context of already identified files and code spans.
* <search_results>: Contains the new search results with code divided into "code spans".

# Your Task:

1. Analyze User Instructions:
Carefully read the reported issue within the <issue> tag.

2. Review Current Context:
Examine the current file context provided in the <file_context> tag to understand already identified relevant files.

3. Process New Search Results:
3.1. Thoroughly analyze each code span in the <search_results> tag.
3.2. Match the code spans with the key elements, functions, variables, or patterns identified in the reported issue.
3.3. Evaluate the relevance of each code span based on how well it aligns with the reported issue and current file context.
3.4. If the issue suggests new functions or classes, identify the existing code that might be relevant to be able to implement the new functionality.
3.5. Review entire sections of code, not just isolated spans, to ensure you have a complete understanding before making a decision. It's crucial to see all code in a section to accurately determine relevance and completeness.
3.6. Verify if there are references to other parts of the codebase that might be relevant but not found in the search results. 
3.7. Identify and extract relevant code spans based on the reported issue. 

4. Respond Using the Function:
Use the Identify function to provide your response.

Think step by step and write out your thoughts in the scratch_pad field.
"""


class Identify(ActionRequest):
    """Identify if the provided search result is relevant to the reported issue."""

    scratch_pad: str = Field(
        description="Your thoughts on how to identify the relevant code and why."
    )

    identified_spans: Optional[list[FileWithSpans]] = Field(
        default=None,
        description="Files and code spans in the search results identified as relevant to the reported issue.",
    )
--------------------------------------------------------------------------------
Chunk ID: find/identify.py::2
Filepath: moatless\find\identify.py
Content:
class IdentifyCode(AgenticState):
    ranked_spans: Optional[list[RankedFileSpan]] = Field(
        default=None, description="Ranked file spans from the search results."
    )

    expand_context: bool = Field(
        default=False,
        description="Whether to expand the search result with relevant code spans.",
    )

    max_prompt_file_tokens: int = Field(
        default=4000,
        description="The maximum number of tokens to include in the prompt.",
    )

    def model_dump(self, **kwargs):
        return super().model_dump(**kwargs)
--------------------------------------------------------------------------------
Chunk ID: find/identify.py::3
Filepath: moatless\find\identify.py
Content:
class IdentifyCode(AgenticState):

    def _execute_action(self, action: Identify) -> ActionResponse:
        if action.identified_spans:
            self.file_context.add_files_with_spans(action.identified_spans)

            span_count = sum([len(file.span_ids) for file in action.identified_spans])
            logger.info(
                f"Identified {span_count} spans in {len(action.identified_spans)} files. Current file context size is {self.file_context.context_size()} tokens."
            )

            return ActionResponse.transition("finish")
        else:
            logger.info("No spans identified.")

        message = f"The search returned {len(self.ranked_spans)} results. But unfortunately, I didn't find any of the search results relevant to the query."

        message += "\n\n"
        message += action.scratch_pad

        return ActionResponse.transition(
            "search",
            output={"message": message},
        )

    def action_type(self) -> type[BaseModel] | None:
        return Identify

    def system_prompt(self) -> str:
        return IDENTIFY_SYSTEM_PROMPT
--------------------------------------------------------------------------------
Chunk ID: find/identify.py::4
Filepath: moatless\find\identify.py
Content:
class IdentifyCode(AgenticState):

    def messages(self) -> list[Message]:
        messages: list[Message] = []

        file_context = self.create_file_context(max_tokens=self.max_prompt_file_tokens)
        file_context.add_ranked_spans(self.ranked_spans)

        if file_context.files:
            file_context.expand_context_with_init_spans()

            if self.expand_context:
                file_context.expand_context_with_related_spans(
                    max_tokens=self.max_prompt_file_tokens, set_tokens=True
                )
                file_context.expand_small_classes(
                    max_tokens=self.max_prompt_file_tokens
                )

            search_result_str = file_context.create_prompt(
                show_span_ids=True,
                show_line_numbers=False,
                exclude_comments=True,
                show_outcommented_code=True,
                outcomment_code_comment="... rest of the code",
            )
        else:
            search_result_str = "No new search results found."

        if self.file_context.files:
            file_context_str = self.file_context.create_prompt(
                show_span_ids=True,
                show_line_numbers=False,
                exclude_comments=True,
                show_outcommented_code=True,
                outcomment_code_comment="... rest of the code",
            )
        else:
            file_context_str = "No relevant code identified yet."

        content = f"""<issue>
{self.initial_message}
</issue>

<file_context>
{file_context_str}
</file_context>

<search_results>
{search_result_str}
</search_results>
"""

        messages.append(UserMessage(content=content))
        return messages


def is_test_pattern(file_pattern: str):
    test_patterns = ["test_*.py", "/tests/"]
    for pattern in test_patterns:
        if pattern in file_pattern:
            return True

    if file_pattern.startswith("test"):
        return True

    test_patterns = ["test_*.py"]

    return any(fnmatch.filter([file_pattern], pattern) for pattern in test_patterns)
--------------------------------------------------------------------------------
Chunk ID: find/search.py::1
Filepath: moatless\find\search.py
Content:
import fnmatch
import logging
from typing import Optional

import instructor
from pydantic import BaseModel, Field, model_validator, ValidationError

from moatless.file_context import RankedFileSpan
from moatless.index.types import SearchCodeHit
from moatless.state import ActionResponse, AgenticState
from moatless.types import (
    ActionRequest,
    AssistantMessage,
    Message,
    UserMessage,
)
from moatless.utils.llm_utils import instructor_mode_by_model

logger = logging.getLogger(__name__)


SEARCH_SYSTEM_PROMPT = """You are an autonomous AI assistant.
Your task is to locate the code relevant to an issue.

# Instructions:

1. Understand The Issue:
Read the <issue> tag to understand the issue.

2. Review Current File Context:
Examine the <file_context> tag to see which files and code spans have already been identified.
If you believe that all relevant files have been identified, you can finish the search by setting complete to true.

3. Consider the Necessary Search Parameters:
Determine if specific file types, directories, function or class names or code patterns are mentioned in the issue.
If you can you should always try to specify the search parameters as accurately as possible.
You can do more than one search request at the same time so you can try different search parameters to cover all possible relevant code.

4. Ensure At Least One Search Parameter:
Make sure that at least one of query, code_snippet, class_name, or function_name is provided.

5. Formulate the Search function:
Set at least one of the search paramaters `query`, `code_snippet`, `class_name` or `function_name`.



"""


SEARCH_FUNCTIONS_FEW_SHOT_OPENAI_FUNC = """
6. Execute the Search function:
Use the Search function with the search parameters and your thoughts on how to approach this task.

Think step by step and write out your thoughts in the thoughts field.

Examples:

User:
The file uploader intermittently fails with "TypeError: cannot unpack non-iterable NoneType object". This issue appears sporadically during high load conditions..

AI Assistant:
functions.Search({
    query: "File upload process to fix intermittent 'TypeError: cannot unpack non-iterable NoneType object'",
    file_pattern: "**/uploader/**/*.py"
)

User:
There's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.

AI Assistant:
functions.Search({
    class_names: ["PaymentProcessor"]
)

User:
The generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.

AI Assistant:
functions.Search({
    function_names: ["generate_report"],
    file_pattern: "**/reports/**/*.py"
)

User:
The extract_data function in HTMLParser throws an "AttributeError: 'NoneType' object has no attribute 'find'" error when parsing certain HTML pages.

AI Assistant:
functions.Search({
    class_names: ["HTMLParser"],
    function_names: ["extract_data"]
)

User:
The database connection setup is missing SSL configuration, causing insecure connections.

Here's the stack trace of the error:

File "/opt/app/db_config/database.py", line 45, in setup_connection
    engine = create_engine(DATABASE_URL)
File "/opt/app/db_config/database.py", line 50, in <module>
    connection = setup_connection()

AI Assistant:
functions.Search({
    code_snippet: "engine = create_engine(DATABASE_URL)",
    file_pattern: "db_config/database.py"
)
"""
--------------------------------------------------------------------------------
Chunk ID: find/search.py::2
Filepath: moatless\find\search.py
Content:
SEARCH_FUNCTIONS_FEW_SHOT = """6. Execute the Search function:
Use the Search function with the search parameters and your thoughts on how to approach this task.

Think step by step and write out your thoughts in the scratch_pad field.

Examples:

User:
The file uploader intermittently fails with "TypeError: cannot unpack non-iterable NoneType object". This issue appears sporadically during high load conditions..

Search parameters:
    query: "File upload process to fix intermittent 'TypeError: cannot unpack non-iterable NoneType object'",
    file_pattern: "**/uploader/**/*.py"


User:
There's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.

Search parameters:
    class_names: ["PaymentProcessor"]


User:
The generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.

Search parameters:
    function_names: ["generate_report"]
    file_pattern: "**/reports/**/*.py"


User:
The extract_data function in HTMLParser throws an "AttributeError: 'NoneType' object has no attribute 'find'" error when parsing certain HTML pages.

Search parameters:
    class_names: ["HTMLParser"]
    function_names: ["extract_data"]


User:
The database connection setup is missing SSL configuration, causing insecure connections.

Here's the stack trace of the error:

File "/opt/app/db_config/database.py", line 45, in setup_connection
    engine = create_engine(DATABASE_URL)
File "/opt/app/db_config/database.py", line 50, in <module>
    connection = setup_connection()

Search parameters:
    code_snippet: "engine = create_engine(DATABASE_URL)",
    file_pattern: "db_config/database.py"

"""
--------------------------------------------------------------------------------
Chunk ID: find/search.py::3
Filepath: moatless\find\search.py
Content:
SEARCH_JSON_FEW_SHOT = """6. Execute the Search:
Execute the search by providing the search parameters and your thoughts on how to approach this task in a JSON object. 

Think step by step and write out your thoughts in the scratch_pad field.

Examples:

User:
The file uploader intermittently fails with "TypeError: cannot unpack non-iterable NoneType object". This issue appears sporadically during high load conditions..

Assistant:
{
 "scratch_pad": "The error indicates that a variable expected to be iterable is None, which might be happening due to race conditions or missing checks under high load. Investigate the file upload logic to ensure all necessary checks are in place and improve concurrency handling.",
 "file_pattern": "**/uploader/**/*.py",
 "query": "TypeError: cannot unpack non-iterable NoneType object"
}

User:
There's a bug in the PaymentProcessor class where transactions sometimes fail to log correctly, resulting in missing transaction records.

Assistant:
{
  "scratch_pad": "Missing transaction logs can cause significant issues in tracking payments. The problem may be related to how the logging mechanism handles transaction states or errors. Investigate the PaymentProcessor class, focusing on the transaction logging part.",
  "class_name": "PaymentProcessor",
  "query": "transactions fail to log correctly"
}

User:
The generate_report function sometimes produces incomplete reports under certain conditions. This function is part of the reporting module. Locate the generate_report function in the reports directory to debug and fix the issue.

Assistant:
{
  "scratch_pad": "Incomplete reports suggest that the function might be encountering edge cases or unhandled exceptions that disrupt the report generation. Reviewing the function's logic and error handling in the reporting module is necessary.",
  "function_name": "generate_report",
  "file_pattern": "**/reports/**/*.py",
}

User:
The extract_data function in HTMLParser throws an "AttributeError: 'NoneType' object has no attribute 'find'" error when parsing certain HTML pages.

Assistant:
{
  "scratch_pad": "The error occurs when 'find' is called on a NoneType object, suggesting that the HTML structure might not match expected patterns. ",
  "class_name": "HTMLParser",
  "function_name": "extract_data",
}


User:
The database connection setup is missing SSL configuration, causing insecure connections.

Here's the stack trace of the error:

File "/opt/app/db_config/database.py", line 45, in setup_connection
    engine = create_engine(DATABASE_URL)
File "/opt/app/db_config/database.py", line 50, in <module>
    connection = setup_connection()

Assistant:
{
  "scratch_pad": "The missing SSL configuration poses a security risk by allowing unencrypted connections. Find the code snippet `engine = create_engine(DATABASE_URL)` provided in the issue.",
  "code_snippet": "engine = create_engine(DATABASE_URL)",
}
"""

IGNORE_TEST_PROMPT = (
    "Test files are not in the search scope. Ignore requests to search for tests. "
)
--------------------------------------------------------------------------------
Chunk ID: find/search.py::4
Filepath: moatless\find\search.py
Content:
class SearchRequest(BaseModel):
    file_pattern: Optional[str] = Field(
        default=None,
        description="A glob pattern to filter search results to specific file types or directories. ",
    )

    query: Optional[str] = Field(
        default=None,
        description="A semantic similarity search query. Use natural language to describe what you are looking for.",
    )

    code_snippet: Optional[str] = Field(
        default=None,
        description="Specific code snippet to that should be exactly matched.",
    )

    class_names: list[str] = Field(
        default=[], description="Specific class names to include in the search."
    )

    function_names: list[str] = Field(
        default=[], description="Specific function names to include in the search."
    )

    def has_search_attributes(self):
        return any(
            [
                self.query,
                self.code_snippet,
                self.class_names,
                self.function_names,
            ]
        )

    @model_validator(mode='after')
    def validate_search_requests(self):
        if not self.has_search_attributes:
            raise ValueError("A search request must have at least one attribute set.")
        return self
--------------------------------------------------------------------------------
Chunk ID: find/search.py::5
Filepath: moatless\find\search.py
Content:
class Search(ActionRequest):
    """Take action to search for code, identify found and finish up."""

    scratch_pad: str = Field(
        description="Scratch pad for the search. Use this to write down your thoughts on how to approach the search."
    )

    search_requests: list[SearchRequest] = Field(
        default=[],
        description="List of search requests.",
    )

    complete: Optional[bool] = Field(
        default=False, description="Set to true when the search is complete."
    )

    @model_validator(mode='after')
    def validate_search_requests(self):
        if not self.complete:
            if not self.search_requests:
                raise ValueError("At least one search request must exist.")
        return self
--------------------------------------------------------------------------------
Chunk ID: find/search.py::6
Filepath: moatless\find\search.py
Content:
class SearchCode(AgenticState):
    message: Optional[str] = Field(
        None,
        description="Message to the search",
    )

    max_search_results: int = Field(
        25,
        description="The maximum number of search results.",
    )

    max_retries_with_any_file_context: int = Field(
        3,
        description="The maximum number of retries when there are identified files in file context.",
    )

    include_message_history: bool = Field(
        True,
        description="Include message history from previous iterations",
    )

    provide_initial_context: bool = True
    initial_context_tokens: int = 4000
    initial_search_results: int = 50
    initial_context_spans_per_file: int = 5

    support_test_files: bool = False
--------------------------------------------------------------------------------
Chunk ID: find/search.py::7
Filepath: moatless\find\search.py
Content:
class SearchCode(AgenticState):

    def _execute_action(self, action: Search) -> ActionResponse:
        if action.complete:
            return ActionResponse.transition(
                "finish",
                output={
                    "message": action.scratch_pad,
                },
            )

        if isinstance(action, Search):
            for request in action.search_requests:
                if (
                    not self.support_test_files
                    and request.file_pattern
                    and is_test_pattern(request.file_pattern)
                ):
                    return self._retry("It's not possible to search for test files.")

        message = ""
        search_result: list[SearchCodeHit] = []
        for search_request in action.search_requests:
            search_response = self.workspace.code_index.search(
                file_pattern=search_request.file_pattern,
                query=search_request.query,
                code_snippet=search_request.code_snippet,
                class_names=search_request.class_names,
                function_names=search_request.function_names,
                max_results=int(self.max_search_results / len(action.search_requests)),
            )
            search_result.extend(search_response.hits)
            message += "\n" + search_response.message

        logger.info(f"Found {len(search_result)} hits.")

        ranked_spans = []
        for hit in search_result:
            for span in hit.spans:
                ranked_spans.append(
                    RankedFileSpan(
                        file_path=hit.file_path,
                        span_id=span.span_id,
                        rank=span.rank,
                        tokens=span.tokens,
                    )
                )

        if len(ranked_spans) == 0:
            logger.info("No search results found. Will retry.")
            message = "\n\nUnfortunately, I didn't find any relevant results."
            return self._retry(message)

        return ActionResponse.transition(
            trigger="did_search",
            output={"ranked_spans": ranked_spans},
        )
--------------------------------------------------------------------------------
Chunk ID: find/search.py::8
Filepath: moatless\find\search.py
Content:
class SearchCode(AgenticState):

    def _retry(self, message: str) -> ActionResponse:
        if (
            self.retries() > self.max_retries_with_any_file_context
            and self.file_context.files
        ):
            logger.info(
                "Exceeded max retries, will finish as there are identified files in the file context. Transitioning to finish."
            )
            return ActionResponse.transition("finish")
        else:
            return ActionResponse.retry(message)

    def action_type(self) -> type[BaseModel] | None:
        return Search

    def system_prompt(self) -> str:
        system_prompt = SEARCH_SYSTEM_PROMPT

        instructor_mode = instructor_mode_by_model(self.model)
        if instructor_mode == instructor.Mode.JSON:
            system_prompt += SEARCH_JSON_FEW_SHOT
        elif self.model.startswith("openai"):
            system_prompt += SEARCH_FUNCTIONS_FEW_SHOT_OPENAI_FUNC
        else:
            system_prompt += SEARCH_FUNCTIONS_FEW_SHOT

        if not self.support_test_files:
            system_prompt += IGNORE_TEST_PROMPT
        return system_prompt
--------------------------------------------------------------------------------
Chunk ID: find/search.py::9
Filepath: moatless\find\search.py
Content:
class SearchCode(AgenticState):

    def messages(self) -> list[Message]:
        messages: list[Message] = []

        content = f"<issue>\n{self.initial_message}\n</issue>"

        if self.provide_initial_context:
            logger.info("Search for initial context to provide in the prompt")
            result = self.workspace.code_index.semantic_search(
                query=self.initial_message,
                exact_match_if_possible=False,
                max_spans_per_file=5,
                max_results=100,
            )

            file_context = self.create_file_context(max_tokens=4000)

            for hit in result.hits:
                for span in hit.spans:
                    file_context.add_span_to_context(
                        hit.file_path, span.span_id, tokens=1
                    )

            content += "\n\nHere's some files that might be relevant when formulating the search.\n"
            content += file_context.create_prompt(
                show_span_ids=False,
                show_line_numbers=False,
                exclude_comments=True,
                show_outcommented_code=False,
            )

        previous_states = self.get_previous_states(self)
        for previous_state in previous_states:
            if previous_state.message:
                content += previous_state.message
            messages.append(UserMessage(content=content))
            messages.append(
                AssistantMessage(
                    action=previous_state.last_action.request,
                )
            )
            content = ""

        if self.message:
            content += f"\n\n{self.message}\n"

        if self.file_context.files:
            file_context_str = self.file_context.create_prompt(
                exclude_comments=True,
                show_outcommented_code=True,
                outcomment_code_comment="... rest of the code",
            )
        else:
            file_context_str = "No files found yet."

        content += f"\n\n<file_context>\n{file_context_str}\n</file_context>"

        messages.append(UserMessage(content=content))
        messages.extend(self.retry_messages())

        return messages


def is_test_pattern(file_pattern: str):
    test_patterns = ["test_*.py", "/tests/"]
    for pattern in test_patterns:
        if pattern in file_pattern:
            return True

    if file_pattern.startswith("test"):
        return True

    test_patterns = ["test_*.py"]

    return any(fnmatch.filter([file_pattern], pattern) for pattern in test_patterns)
--------------------------------------------------------------------------------
Chunk ID: index/__init__.py::1
Filepath: moatless\index\__init__.py
Content:
from moatless.index.code_index import CodeIndex
from moatless.index.settings import IndexSettings
from moatless.index.simple_faiss import SimpleFaissVectorStore
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::1
Filepath: moatless\index\code_index.py
Content:
import fnmatch
import json
import logging
import mimetypes
import os
import shutil
import tempfile
from typing import Optional

import requests
from llama_index.core import SimpleDirectoryReader
from llama_index.core.base.embeddings.base import BaseEmbedding
from llama_index.core.ingestion import DocstoreStrategy, IngestionPipeline
from llama_index.core.storage import docstore
from llama_index.core.storage.docstore import DocumentStore, SimpleDocumentStore
from llama_index.core.vector_stores.types import (
    BasePydanticVectorStore,
    FilterCondition,
    MetadataFilter,
    MetadataFilters,
    VectorStoreQuery,
)
from rapidfuzz import fuzz

from moatless.codeblocks import CodeBlock, CodeBlockType
from moatless.index.embed_model import get_embed_model
from moatless.index.epic_split import EpicSplitter
from moatless.index.settings import IndexSettings
from moatless.index.simple_faiss import SimpleFaissVectorStore
from moatless.index.types import (
    CodeSnippet,
    SearchCodeHit,
    SearchCodeResponse,
)
from moatless.repository import FileRepository
from moatless.types import FileWithSpans
from moatless.utils.tokenizer import count_tokens

logger = logging.getLogger(__name__)


def default_vector_store(settings: IndexSettings):
    try:
        import faiss
    except ImportError as e:
        raise ImportError(
            "faiss needs to be installed to set up a default index for CodeIndex. Run 'pip install faiss-cpu'"
        ) from e

    faiss_index = faiss.IndexIDMap(faiss.IndexFlatL2(settings.dimensions))
    return SimpleFaissVectorStore(faiss_index)
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::2
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:
    def __init__(
        self,
        file_repo: FileRepository,
        index_name: Optional[str] = None,
        vector_store: BasePydanticVectorStore | None = None,
        docstore: DocumentStore | None = None,
        embed_model: BaseEmbedding | None = None,
        blocks_by_class_name: Optional[dict] = None,
        blocks_by_function_name: Optional[dict] = None,
        settings: IndexSettings | None = None,
        max_results: int = 25,
        max_hits_without_exact_match: int = 100,
        max_exact_results: int = 5,
    ):
        self._index_name = index_name
        self._settings = settings or IndexSettings()

        self.max_results = max_results
        self.max_hits_without_exact_match = max_hits_without_exact_match
        self.max_exact_results = max_exact_results

        self._file_repo = file_repo

        self._blocks_by_class_name = blocks_by_class_name or {}
        self._blocks_by_function_name = blocks_by_function_name or {}

        self._embed_model = embed_model or get_embed_model(self._settings.embed_model)
        self._vector_store = vector_store or default_vector_store(self._settings)
        self._docstore = docstore or SimpleDocumentStore()

        logger.info(f"Initiated CodeIndex {self._index_name} with:\n"
                    f" * {len(self._blocks_by_class_name)} classes\n"
                    f" * {len(self._blocks_by_function_name)} functions\n"
                    f" * {len(self._docstore.docs)} vectors\n")
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::3
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    @classmethod
    def from_persist_dir(cls, persist_dir: str, file_repo: FileRepository, **kwargs):
        vector_store = SimpleFaissVectorStore.from_persist_dir(persist_dir)
        docstore = SimpleDocumentStore.from_persist_dir(persist_dir)

        settings = IndexSettings.from_persist_dir(persist_dir)

        if os.path.exists(os.path.join(persist_dir, "blocks_by_class_name.json")):
            with open(os.path.join(persist_dir, "blocks_by_class_name.json")) as f:
                blocks_by_class_name = json.load(f)
        else:
            blocks_by_class_name = {}

        if os.path.exists(os.path.join(persist_dir, "blocks_by_function_name.json")):
            with open(os.path.join(persist_dir, "blocks_by_function_name.json")) as f:
                blocks_by_function_name = json.load(f)
        else:
            blocks_by_function_name = {}

        return cls(
            file_repo=file_repo,
            vector_store=vector_store,
            docstore=docstore,
            settings=settings,
            blocks_by_class_name=blocks_by_class_name,
            blocks_by_function_name=blocks_by_function_name,
            **kwargs,
        )
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::4
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    @classmethod
    def from_url(cls, url: str, persist_dir: str, file_repo: FileRepository):
        try:
            response = requests.get(url, stream=True)
            response.raise_for_status()

            with tempfile.TemporaryDirectory() as temp_dir:
                temp_zip_file = os.path.join(temp_dir, url.split("/")[-1])

                with open(temp_zip_file, "wb") as data:
                    for chunk in response.iter_content(chunk_size=8192):
                        data.write(chunk)

                shutil.unpack_archive(temp_zip_file, persist_dir)

        except requests.exceptions.HTTPError as e:
            logger.exception(f"HTTP Error while fetching {url}")
            raise e
        except Exception as e:
            logger.exception(f"Failed to download {url}")
            raise e

        logger.info(f"Downloaded existing index from {url}.")
        return cls.from_persist_dir(persist_dir, file_repo)
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::5
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    @classmethod
    def from_index_name(
        cls,
        index_name: str,
        file_repo: FileRepository,
        index_store_dir: Optional[str] = None,
    ):
        if not index_store_dir:
            index_store_dir = os.getenv("INDEX_STORE_DIR")

        persist_dir = os.path.join(index_store_dir, index_name)
        if os.path.exists(persist_dir):
            logger.info(f"Loading existing index {index_name} from {persist_dir}.")
            return cls.from_persist_dir(persist_dir, file_repo=file_repo)

        if os.getenv("INDEX_STORE_URL"):
            index_store_url = os.getenv("INDEX_STORE_URL")
        else:
            index_store_url = "https://stmoatless.blob.core.windows.net/indexstore/20240522-voyage-code-2"

        store_url = os.path.join(index_store_url, f"{index_name}.zip")
        logger.info(f"Downloading existing index {index_name} from {store_url}.")
        return cls.from_url(store_url, persist_dir, file_repo)

    def dict(self):
        return {"index_name": self._index_name}
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::6
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def search(
        self,
        query: Optional[str] = None,
        code_snippet: Optional[str] = None,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        max_results: int = 25,
    ) -> SearchCodeResponse:
        if class_names or function_names:
            result = self.find_by_name(
                class_names=class_names,
                function_names=function_names,
                file_pattern=file_pattern,
            )

            if len(result.hits) == 0 and class_names and function_names:
                results = []
                results.extend(
                    self.find_by_name(
                        class_names=class_names,
                        file_pattern=file_pattern,
                        include_functions_in_class=False,
                    ).hits
                )
                results.extend(
                    self.find_by_name(
                        function_names=function_names, file_pattern=file_pattern
                    ).hits
                )

                if len(results) > 0 and len(results) <= max_results:
                    return SearchCodeResponse(
                        message=f"Found {len(results)} hits.",
                        hits=results,
                    )

        if query or code_snippet:
            return self.semantic_search(
                query=query,
                code_snippet=code_snippet,
                class_names=class_names,
                function_names=function_names,
                file_pattern=file_pattern,
                max_results=max_results,
            )

        return result
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::7
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def semantic_search(
        self,
        query: Optional[str] = None,
        code_snippet: Optional[str] = None,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        category: str = "implementation",
        max_results: int = 25,
        max_hits_without_exact_match: int = 100,
        max_exact_results: int = 5,
        max_spans_per_file: Optional[int] = None,
        exact_match_if_possible: bool = False,
    ) -> SearchCodeResponse:
        if query is None:
            query = ""

        if class_names:
            query += f", class {class_names}"

        if function_names:
            query += f", function {function_names}"

        message = ""
        if file_pattern:
            if category != "test":
                exclude_files = self._file_repo.matching_files("**/test*/**")
            else:
                exclude_files = []

            matching_files = self._file_repo.matching_files(file_pattern)
            matching_files = [
                file for file in matching_files if file not in exclude_files
            ]

            if not matching_files:
                logger.info(
                    f"semantic_search() No files found for file pattern {file_pattern}. Will search all files..."
                )
                message += f"No files found for file pattern {file_pattern}. Will search all files.\n"
                file_pattern = None

        search_results = self._vector_search(
            query, file_pattern=file_pattern, exact_content_match=code_snippet
        )

        files_with_spans: dict[str, SearchCodeHit] = {}

        span_count = 0
        spans_with_exact_query_match = 0
        filtered_out = 0

        require_exact_query_match = False
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::8
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def semantic_search(
        self,
        query: Optional[str] = None,
        code_snippet: Optional[str] = None,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        category: str = "implementation",
        max_results: int = 25,
        max_hits_without_exact_match: int = 100,
        max_exact_results: int = 5,
        max_spans_per_file: Optional[int] = None,
        exact_match_if_possible: bool = False,
    ) -> SearchCodeResponse:
        # ... other code

        for rank, search_hit in enumerate(search_results):
            file = self._file_repo.get_file(search_hit.file_path)
            if not file:
                logger.warning(
                    f"semantic_search() Could not find file {search_hit.file_path}."
                )
                continue

            spans = []
            for span_id in search_hit.span_ids:
                span = file.module.find_span_by_id(span_id)

                if span:
                    spans.append(span)
                else:
                    logger.debug(
                        f"semantic_search() Could not find span with id {span_id} in file {file.file_path}"
                    )

                    spans_by_line_number = file.module.find_spans_by_line_numbers(
                        search_hit.start_line, search_hit.end_line
                    )

                    for span_by_line_number in spans_by_line_number:
                        spans.append(span_by_line_number)

            names = []
            if class_names:
                names.extend(class_names)

            if function_names:
                names.extend(function_names)

            for span in spans:
                has_exact_query_match = (
                    exact_match_if_possible
                    and query
                    and span.initiating_block.has_content(query, span.span_id)
                )

                if has_exact_query_match:
                    spans_with_exact_query_match += 1

                if has_exact_query_match and not require_exact_query_match:
                    require_exact_query_match = True
                    files_with_spans = {}

                if (
                    not require_exact_query_match and span_count <= max_results
                ) or has_exact_query_match:
                    if search_hit.file_path not in files_with_spans:
                        files_with_spans[search_hit.file_path] = SearchCodeHit(
                            file_path=search_hit.file_path
                        )

                    if files_with_spans[search_hit.file_path].contains_span(
                        span.span_id
                    ):
                        continue

                    if names and not any(
                        name in span.initiating_block.full_path() for name in names
                    ):
                        filtered_out += 1
                        continue

                    span_count += 1
                    files_with_spans[search_hit.file_path].add_span(
                        span_id=span.span_id, rank=rank, tokens=span.tokens
                    )

                    if (
                        max_spans_per_file
                        and len(files_with_spans[search_hit.file_path].spans)
                        >= max_spans_per_file
                    ):
                        break

            if exact_match_if_possible:
                if spans_with_exact_query_match > max_exact_results or (
                    spans_with_exact_query_match == 0
                    and span_count > max_hits_without_exact_match
                ):
                    break
            elif span_count > max_results:
                break

        span_count = sum([len(file.spans) for file in files_with_spans.values()])

        if class_names or function_names:
            logger.info(
                f"semantic_search() Filtered out {filtered_out} spans by class names {class_names} and function names {function_names}."
            )
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::9
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def semantic_search(
        self,
        query: Optional[str] = None,
        code_snippet: Optional[str] = None,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        category: str = "implementation",
        max_results: int = 25,
        max_hits_without_exact_match: int = 100,
        max_exact_results: int = 5,
        max_spans_per_file: Optional[int] = None,
        exact_match_if_possible: bool = False,
    ) -> SearchCodeResponse:
        # ... other code

        if require_exact_query_match:
            logger.info(
                f"semantic_search() Found {spans_with_exact_query_match} code spans with exact match out of {span_count} spans."
            )
            message = f"Found {spans_with_exact_query_match} code spans with code that matches the exact query `{query}`."
        else:
            logger.info(
                f"semantic_search() Found {span_count} code spans in {len(files_with_spans.values())} files."
            )
            message = f"Found {span_count} code spans."

        return SearchCodeResponse(message=message, hits=list(files_with_spans.values()))
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::10
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def find_by_name(
        self,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        include_functions_in_class: bool = True,
        category: str = "implementation",
    ) -> SearchCodeResponse:
        if not class_names and not function_names:
            raise ValueError(
                "At least one of class_name or function_name must be provided."
            )

        paths = []

        if function_names:
            for function_name in function_names:
                paths.extend(self._blocks_by_function_name.get(function_name, []))

        if class_names:
            for class_name in class_names:
                paths.extend(self._blocks_by_class_name.get(class_name, []))

        logger.info(
            f"find_by_name(class_name={class_names}, function_name={function_names}, file_pattern={file_pattern}) {len(paths)} hits."
        )

        if not paths:
            if function_names:
                return SearchCodeResponse(
                    message=f"No functions found with the name {function_names}."
                )
            else:
                return SearchCodeResponse(
                    message=f"No classes found with the name {class_names}."
                )

        if category != "test":
            exclude_files = self._file_repo.matching_files("**/test*/**")

            filtered_paths = []
            for file_path, block_path in paths:
                if file_path not in exclude_files:
                    filtered_paths.append((file_path, block_path))

            filtered_out_test_files = len(paths) - len(filtered_paths)
            if filtered_out_test_files > 0:
                logger.info(
                    f"find_by_name() Filtered out {filtered_out_test_files} test files."
                )

            paths = filtered_paths

        check_all_files = False
        if file_pattern:
            include_files = self._file_repo.matching_files(file_pattern)

            if include_files:
                filtered_paths = []
                for file_path, block_path in paths:
                    if file_path in include_files:
                        filtered_paths.append((file_path, block_path))

                filtered_out_by_file_pattern = len(paths) - len(filtered_paths)
                if filtered_paths:
                    logger.info(
                        f"find_by_name() Filtered out {filtered_out_by_file_pattern} files by file pattern."
                    )
                    paths = filtered_paths
                else:
                    logger.info(
                        f"find_by_name() No files found for file pattern {file_pattern}. Will search all files..."
                    )
                    check_all_files = True

        filtered_out_by_class_name = 0
        invalid_blocks = 0

        files_with_spans = {}
        for file_path, block_path in paths:
            file = self._file_repo.get_file(file_path)
            block = file.module.find_by_path(block_path)

            if not block:
                invalid_blocks += 1
                continue

            if (
                class_names
                and function_names
                and not self._found_class(block, class_names)
            ):
                filtered_out_by_class_name += 1
                continue

            if file_path not in files_with_spans:
                files_with_spans[file_path] = SearchCodeHit(file_path=file_path)

            files_with_spans[file_path].add_span(
                block.belongs_to_span.span_id,
                rank=0,
                tokens=block.belongs_to_span.tokens,
            )
            if include_functions_in_class and not function_names:
                for child in block.children:
                    if (
                        child.belongs_to_span.span_id
                        not in files_with_spans[file_path].span_ids
                    ):
                        files_with_spans[file_path].add_span(
                            child.belongs_to_span.span_id,
                            rank=0,
                            tokens=child.belongs_to_span.tokens,
                        )
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::11
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def find_by_name(
        self,
        class_names: list[str] = None,
        function_names: list[str] = None,
        file_pattern: Optional[str] = None,
        include_functions_in_class: bool = True,
        category: str = "implementation",
    ) -> SearchCodeResponse:
        # ... other code

        if filtered_out_by_class_name > 0:
            logger.info(
                f"find_by_function_name() Filtered out {filtered_out_by_class_name} functions by class name {class_name}."
            )

        if invalid_blocks > 0:
            logger.info(
                f"find_by_function_name() Ignored {invalid_blocks} invalid blocks."
            )

        if check_all_files and len(files_with_spans) > 0:
            message = f"The file pattern {file_pattern} didn't match any files. But I found {len(files_with_spans)} matches in other files."
        elif len(files_with_spans):
            message = f"Found {len(files_with_spans)} hits."
        elif class_names and function_names:
            message = f"No functions found with the names {function_names} in class {class_names}."
        elif class_names:
            message = f"No classes found with the name {class_names}."
        elif function_names:
            message = f"No functions found with the names {function_names}."
        else:
            message = "No results found."

        file_paths = [file.file_path for file in files_with_spans.values()]
        if file_pattern:
            file_paths = _rerank_files(file_paths, file_pattern)

        search_hits = []
        for rank, file_path in enumerate(file_paths):
            file = files_with_spans[file_path]
            for span in file.spans:
                span.rank = rank
            search_hits.append(file)

        return SearchCodeResponse(
            message=message,
            hits=search_hits,
        )
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::12
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def _found_class(self, block: CodeBlock, class_names: list[str]):
        for class_name in class_names:
            parent_class = block.find_type_in_parents(CodeBlockType.CLASS)
            if parent_class and parent_class.identifier == class_name:
                return True
        else:
            return False

    def _create_search_hit(self, file: FileWithSpans, rank: int = 0):
        file_hit = SearchCodeHit(file_path=file.file_path)
        for span_id in file.span_ids:
            file_hit.add_span(span_id, rank)
        return file_hit
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::13
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def _vector_search(
        self,
        query: str = "",
        exact_query_match: bool = False,
        category: str = "implementation",
        file_pattern: Optional[str] = None,
        exact_content_match: Optional[str] = None,
    ):
        if file_pattern:
            query += f" file:{file_pattern}"

        if exact_content_match:
            query += "\n" + exact_content_match

        if not query:
            raise ValueError(
                "At least one of query, span_keywords or content_keywords must be provided."
            )

        logger.info(
            f"vector_search() Searching for query [{query[:50]}...] and file pattern [{file_pattern}]."
        )

        query_embedding = self._embed_model.get_query_embedding(query)

        filters = MetadataFilters(filters=[], condition=FilterCondition.AND)
        if category:
            filters.filters.append(MetadataFilter(key="category", value=category))

        query_bundle = VectorStoreQuery(
            query_str=query,
            query_embedding=query_embedding,
            similarity_top_k=500,  # TODO: Fix paging?
            filters=filters,
        )

        result = self._vector_store.query(query_bundle)

        filtered_out_snippets = 0
        ignored_removed_snippets = 0
        sum_tokens = 0

        sum_tokens_per_file = {}

        if file_pattern:
            include_files = self._file_repo.matching_files(file_pattern)
            if len(include_files) == 0:
                logger.info(
                    f"vector_search() No files found for file pattern {file_pattern}, return empty result..."
                )
                return []
        else:
            include_files = []

        if category != "test":
            exclude_files = self._file_repo.find_files(
                ["**/tests/**", "tests*", "*_test.py", "test_*.py"]
            )
        else:
            exclude_files = set()

        search_results = []

        for node_id, distance in zip(result.ids, result.similarities, strict=False):
            node_doc = self._docstore.get_document(node_id, raise_error=False)
            if not node_doc:
                ignored_removed_snippets += 1
                # TODO: Retry to get top_k results
                continue

            if exclude_files and node_doc.metadata["file_path"] in exclude_files:
                filtered_out_snippets += 1
                continue

            if include_files and node_doc.metadata["file_path"] not in include_files:
                filtered_out_snippets += 1
                continue

            if exact_query_match and query not in node_doc.get_content():
                filtered_out_snippets += 1
                continue

            if exact_content_match and not is_string_in(
                exact_content_match, node_doc.get_content()
            ):
                filtered_out_snippets += 1
                continue

            if node_doc.metadata["file_path"] not in sum_tokens_per_file:
                sum_tokens_per_file[node_doc.metadata["file_path"]] = 0

            sum_tokens += node_doc.metadata["tokens"]
            sum_tokens_per_file[node_doc.metadata["file_path"]] += node_doc.metadata[
                "tokens"
            ]

            code_snippet = CodeSnippet(
                id=node_doc.id_,
                file_path=node_doc.metadata["file_path"],
                distance=distance,
                content=node_doc.get_content(),
                tokens=node_doc.metadata["tokens"],
                span_ids=node_doc.metadata.get("span_ids", []),
                start_line=node_doc.metadata.get("start_line", None),
                end_line=node_doc.metadata.get("end_line", None),
            )

            search_results.append(code_snippet)

        # TODO: Rerank by file pattern if no exact matches on file pattern

        logger.info(
            f"vector_search() Returning {len(search_results)} search results. "
            f"(Ignored {ignored_removed_snippets} removed search results. "
            f"Filtered out {filtered_out_snippets} search results.)"
        )

        return search_results
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::14
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def run_ingestion(
        self,
        repo_path: Optional[str] = None,
        input_files: list[str] | None = None,
        num_workers: Optional[int] = None,
    ):
        repo_path = repo_path or self._file_repo.path

        # Only extract file name and type to not trigger unnecessary embedding jobs
        def file_metadata_func(file_path: str) -> dict:
            file_path = file_path.replace(repo_path, "")
            if file_path.startswith("/"):
                file_path = file_path[1:]

            test_patterns = [
                "**/test/**",
                "**/tests/**",
                "**/test_*.py",
                "**/*_test.py",
            ]
            category = (
                "test"
                if any(fnmatch.fnmatch(file_path, pattern) for pattern in test_patterns)
                else "implementation"
            )

            return {
                "file_path": file_path,
                "file_name": os.path.basename(file_path),
                "file_type": mimetypes.guess_type(file_path)[0],
                "category": category,
            }
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::15
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def run_ingestion(
        self,
        repo_path: Optional[str] = None,
        input_files: list[str] | None = None,
        num_workers: Optional[int] = None,
    ):
        # ... other code

        if self._settings and self._settings.language == "java":
            required_exts = [".java"]
        else:
            required_exts = [".py"]

        try:
            reader = SimpleDirectoryReader(
                input_dir=repo_path,
                file_metadata=file_metadata_func,
                input_files=input_files,
                filename_as_id=True,
                required_exts=required_exts,
                recursive=True,
            )
        except Exception as e:
            logger.exception(f"Failed to create reader with input_dir {repo_path}, input_files {input_files} and required_exts {required_exts}.")
            raise e

        embed_pipeline = IngestionPipeline(
            transformations=[self._embed_model],
            docstore_strategy=DocstoreStrategy.UPSERTS_AND_DELETE,
            docstore=self._docstore,
            vector_store=self._vector_store,
        )

        docs = reader.load_data()
        logger.info(f"Read {len(docs)} documents")

        blocks_by_class_name = {}
        blocks_by_function_name = {}
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::16
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def run_ingestion(
        self,
        repo_path: Optional[str] = None,
        input_files: list[str] | None = None,
        num_workers: Optional[int] = None,
    ):
        # ... other code

        def index_callback(codeblock: CodeBlock):
            if codeblock.type == CodeBlockType.CLASS:
                if codeblock.identifier not in blocks_by_class_name:
                    blocks_by_class_name[codeblock.identifier] = []
                blocks_by_class_name[codeblock.identifier].append(
                    (codeblock.module.file_path, codeblock.full_path())
                )

            if codeblock.type == CodeBlockType.FUNCTION:
                if codeblock.identifier not in blocks_by_function_name:
                    blocks_by_function_name[codeblock.identifier] = []
                blocks_by_function_name[codeblock.identifier].append(
                    (codeblock.module.file_path, codeblock.full_path())
                )
        # ... other code
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::17
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def run_ingestion(
        self,
        repo_path: Optional[str] = None,
        input_files: list[str] | None = None,
        num_workers: Optional[int] = None,
    ):
        # ... other code

        splitter = EpicSplitter(
            language=self._settings.language,
            min_chunk_size=self._settings.min_chunk_size,
            chunk_size=self._settings.chunk_size,
            hard_token_limit=self._settings.hard_token_limit,
            max_chunks=self._settings.max_chunks,
            comment_strategy=self._settings.comment_strategy,
            index_callback=index_callback,
            repo_path=repo_path,
        )

        prepared_nodes = splitter.get_nodes_from_documents(docs, show_progress=True)
        prepared_tokens = sum(
            [
                count_tokens(node.get_content(), self._settings.embed_model)
                for node in prepared_nodes
            ]
        )
        logger.info(
            f"Prepared {len(prepared_nodes)} nodes and {prepared_tokens} tokens"
        )

        embedded_nodes = embed_pipeline.run(
            nodes=list(prepared_nodes), show_progress=True, num_workers=num_workers
        )
        embedded_tokens = sum(
            [
                count_tokens(node.get_content(), self._settings.embed_model)
                for node in embedded_nodes
            ]
        )
        logger.info(
            f"Embedded {len(embedded_nodes)} vectors with {embedded_tokens} tokens"
        )

        self._blocks_by_class_name = blocks_by_class_name
        self._blocks_by_function_name = blocks_by_function_name

        return len(embedded_nodes), embedded_tokens
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::18
Filepath: moatless\index\code_index.py
Content:
class CodeIndex:

    def persist(self, persist_dir: str):
        self._vector_store.persist(persist_dir)
        self._docstore.persist(
            os.path.join(persist_dir, docstore.types.DEFAULT_PERSIST_FNAME)
        )
        self._settings.persist(persist_dir)

        with open(os.path.join(persist_dir, "blocks_by_class_name.json"), "w") as f:
            f.write(json.dumps(self._blocks_by_class_name, indent=2))

        with open(os.path.join(persist_dir, "blocks_by_function_name.json"), "w") as f:
            f.write(json.dumps(self._blocks_by_function_name, indent=2))
--------------------------------------------------------------------------------
Chunk ID: index/code_index.py::19
Filepath: moatless\index\code_index.py
Content:
def _rerank_files(file_paths: list[str], file_pattern: str):
    if len(file_paths) < 2:
        return file_paths

    tokenized_query = file_pattern.replace(".py", "").replace("*", "").split("/")
    tokenized_query = [part for part in tokenized_query if part.strip()]
    query = "/".join(tokenized_query)

    scored_files = []
    for file_path in file_paths:
        cleaned_file_path = file_path.replace(".py", "")
        score = fuzz.partial_ratio(cleaned_file_path, query)
        scored_files.append((file_path, score))

    scored_files.sort(key=lambda x: x[1], reverse=True)

    sorted_file_paths = [file for file, score in scored_files]

    logger.info(
        f"rerank_files() Reranked {len(file_paths)} files with query {tokenized_query}. First hit {sorted_file_paths[0]}"
    )

    return sorted_file_paths


def is_string_in(s1, s2):
    s1_clean = s1.replace(" ", "").replace("\t", "").replace("\n", "")
    s2_clean = s2.replace(" ", "").replace("\t", "").replace("\n", "")
    found_in = s1_clean in s2_clean
    return found_in
--------------------------------------------------------------------------------
Chunk ID: index/code_node.py::1
Filepath: moatless\index\code_node.py
Content:
from hashlib import sha256

from llama_index.core.schema import TextNode


class CodeNode(TextNode):
    # Skip start and end line in metadata to try to lower the number of changes and triggers of new embeddings.
    @property
    def hash(self):
        metadata = self.metadata.copy()
        metadata.pop("start_line", None)
        metadata.pop("end_line", None)
        doc_identity = str(self.text) + str(metadata)
        return str(sha256(doc_identity.encode("utf-8", "surrogatepass")).hexdigest())
--------------------------------------------------------------------------------
Chunk ID: index/embed_model.py::1
Filepath: moatless\index\embed_model.py
Content:
import os

from llama_index.core.base.embeddings.base import BaseEmbedding


def get_embed_model(model_name: str) -> BaseEmbedding:
    if model_name.startswith("voyage"):
        try:
            from llama_index.embeddings.voyageai import VoyageEmbedding
        except ImportError as e:
            raise ImportError(
                "llama-index-embeddings-voyageai is not installed. Please install it using `pip install llama-index-embeddings-voyageai`"
            ) from e

        if "VOYAGE_API_KEY" not in os.environ:
            raise ValueError(
                "VOYAGE_API_KEY environment variable is not set. Please set it to your Voyage API key."
            )

        return VoyageEmbedding(
            model_name=model_name,
            voyage_api_key=os.environ.get("VOYAGE_API_KEY"),
            truncation=True,
            embed_batch_size=50,
        )
    else:
        # Assumes OpenAI otherwise
        try:
            from llama_index.embeddings.openai import OpenAIEmbedding
        except ImportError as e:
            raise ImportError(
                "llama-index-embeddings-openai is not installed. Please install it using `pip install llama-index-embeddings-openai`"
            ) from e

        return OpenAIEmbedding(model_name=model_name)
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::1
Filepath: moatless\index\epic_split.py
Content:
import re
import time
from collections.abc import Callable, Sequence
from typing import Any, Optional

from llama_index.core.bridge.pydantic import Field
from llama_index.core.callbacks import CallbackManager
from llama_index.core.node_parser import NodeParser, TextSplitter, TokenTextSplitter
from llama_index.core.node_parser.node_utils import logger
from llama_index.core.schema import BaseNode, TextNode
from llama_index.core.utils import get_tokenizer, get_tqdm_iterable

from moatless.codeblocks import create_parser
from moatless.codeblocks.codeblocks import CodeBlock, CodeBlockType, PathTree
from moatless.codeblocks.parser.python import PythonParser
from moatless.index.code_node import CodeNode
from moatless.index.settings import CommentStrategy

CodeBlockChunk = list[CodeBlock]


def count_chunk_tokens(chunk: CodeBlockChunk) -> int:
    return sum([block.tokens for block in chunk])


def count_parent_tokens(codeblock: CodeBlock) -> int:
    tokens = codeblock.tokens
    if codeblock.parent:
        tokens += codeblock.parent.tokens
    return tokens


SPLIT_BLOCK_TYPES = [
    CodeBlockType.FUNCTION,
    CodeBlockType.CLASS,
    CodeBlockType.TEST_SUITE,
    CodeBlockType.TEST_CASE,
    CodeBlockType.MODULE,
]
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::2
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):
    language: str = Field(
        default="python", description="Language of the code blocks to parse."
    )

    text_splitter: TextSplitter = Field(
        description="Text splitter to use for splitting non code documents into nodes."
    )

    include_non_code_files: bool = Field(
        default=True, description="Whether or not to include non code files."
    )

    non_code_file_extensions: list[str] = Field(
        default=["md", "txt"],
        description="File extensions to consider as non code files.",
    )

    comment_strategy: CommentStrategy = Field(
        default=CommentStrategy.INCLUDE, description="Comment strategy to use."
    )

    chunk_size: int = Field(
        default=1500, description="Chunk size to use for splitting code documents."
    )

    max_chunks: int = Field(
        default=100, description="Max number of chunks to split a document into."
    )

    min_chunk_size: int = Field(default=256, description="Min tokens to split code.")

    max_chunk_size: int = Field(default=2000, description="Max tokens in one chunk.")

    hard_token_limit: int = Field(
        default=6000, description="Hard token limit for a chunk."
    )

    repo_path: str = Field(default=None, description="Path to the repository.")

    index_callback: Optional[Callable] = Field(
        default=None, description="Callback to call when indexing a code block."
    )

    # _fallback_code_splitter: Optional[TextSplitter] = PrivateAttr() TODO: Implement fallback when tree sitter fails

    def __init__(
        self,
        language: str = "python",
        chunk_size: int = 750,
        min_chunk_size: int = 100,
        max_chunk_size: int = 1500,
        hard_token_limit: int = 6000,
        max_chunks: int = 100,
        include_metadata: bool = True,
        include_prev_next_rel: bool = True,
        text_splitter: TextSplitter | None = None,
        index_callback: Optional[Callable[[CodeBlock], None]] = None,
        repo_path: Optional[str] = None,
        comment_strategy: CommentStrategy = CommentStrategy.ASSOCIATE,
        # fallback_code_splitter: Optional[TextSplitter] = None,
        include_non_code_files: bool = True,
        tokenizer: Optional[Callable] = None,
        non_code_file_extensions: list[str] | None = None,
        callback_manager: CallbackManager | None = None,
    ) -> None:
        if non_code_file_extensions is None:
            non_code_file_extensions = ["md", "txt"]
        callback_manager = callback_manager or CallbackManager([])

        # self._fallback_code_splitter = fallback_code_splitter

        super().__init__(
            language=language,
            chunk_size=chunk_size,
            chunk_overlap=0,
            text_splitter=text_splitter or TokenTextSplitter(),
            min_chunk_size=min_chunk_size,
            max_chunk_size=max_chunk_size,
            hard_token_limit=hard_token_limit,
            max_chunks=max_chunks,
            index_callback=index_callback,
            repo_path=repo_path,
            comment_strategy=comment_strategy,
            include_non_code_files=include_non_code_files,
            non_code_file_extensions=non_code_file_extensions,
            include_metadata=include_metadata,
            include_prev_next_rel=include_prev_next_rel,
            callback_manager=callback_manager,
        )

    @classmethod
    def class_name(cls):
        return "GhostcoderNodeParser"
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::3
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _parse_nodes(
        self,
        nodes: Sequence[BaseNode],
        show_progress: bool = False,
        **kwargs: Any,
    ) -> list[BaseNode]:
        nodes_with_progress = get_tqdm_iterable(nodes, show_progress, "Parsing nodes")

        all_nodes: list[BaseNode] = []

        for node in nodes_with_progress:
            file_path = node.metadata.get("file_path")
            content = node.get_content()

            try:
                starttime = time.time_ns()

                # TODO: Derive language from file extension
                parser = create_parser(language=self.language, index_callback=self.index_callback)
                codeblock = parser.parse(content, file_path=file_path)

                parse_time = time.time_ns() - starttime
                if parse_time > 1e9:
                    logger.warning(
                        f"Parsing file {file_path} took {parse_time / 1e9:.2f} seconds."
                    )

            except Exception as e:
                logger.warning(
                    f"Failed to use epic splitter to split {file_path}. Fallback to treesitter_split(). Error: {e}"
                )
                # TODO: Fall back to treesitter or text split
                continue

            starttime = time.time_ns()
            chunks = self._chunk_contents(codeblock=codeblock, file_path=file_path)
            parse_time = time.time_ns() - starttime
            if parse_time > 1e8:
                logger.warning(
                    f"Splitting file {file_path} took {parse_time / 1e9:.2f} seconds."
                )
            if len(chunks) > 100:
                logger.info(f"Splitting file {file_path} in {len(chunks)} chunks")

            starttime = time.time_ns()
            for chunk in chunks:
                path_tree = self._create_path_tree(chunk)
                content = self._to_context_string(codeblock, path_tree)
                chunk_node = self._create_node(content, node, chunk=chunk)
                if chunk_node:
                    all_nodes.append(chunk_node)
            parse_time = time.time_ns() - starttime
            if parse_time > 1e9:
                logger.warning(
                    f"Create nodes for file {file_path} took {parse_time / 1e9:.2f} seconds."
                )
        return all_nodes
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::4
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _chunk_contents(
        self, codeblock: CodeBlock | None = None, file_path: Optional[str] = None
    ) -> list[CodeBlockChunk]:
        tokens = codeblock.sum_tokens()
        if tokens == 0:
            logger.debug(f"Skipping file {file_path} because it has no tokens.")
            return []

        if codeblock.find_errors():
            logger.warning(
                f"Failed to use spic splitter to split {file_path}. {len(codeblock.find_errors())} codeblocks with type ERROR. Fallback to treesitter_split()"
            )
            # TODO: Fall back to treesitter or text split
            return []

        if tokens > self.hard_token_limit:
            for child in codeblock.children:
                if (
                    child.type == CodeBlockType.COMMENT
                    and "generated" in child.content.lower()
                ):  # TODO: Make a generic solution to detect files that shouldn't be indexed. Maybe ask an LLM?
                    logger.info(
                        f"File {file_path} has {tokens} tokens and the word 'generated' in the first comments,"
                        f" will assume it's a generated file."
                    )
                    return []
                else:
                    break

        if tokens < self.min_chunk_size:
            child_blocks = codeblock.get_all_child_blocks()
            return [[codeblock] + child_blocks]

        return self._chunk_block(codeblock, file_path)
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::5
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _chunk_block(
        self, codeblock: CodeBlock, file_path: Optional[str] = None
    ) -> list[CodeBlockChunk]:
        chunks: list[CodeBlockChunk] = []
        current_chunk = []
        comment_chunk = []

        parent_tokens = count_parent_tokens(codeblock)

        ignoring_comment = False

        for child in codeblock.children:
            if child.type == CodeBlockType.COMMENT:
                if self.comment_strategy == CommentStrategy.EXCLUDE:
                    continue
                elif self._ignore_comment(child) or ignoring_comment:
                    ignoring_comment = True
                    continue
                elif (
                    self.comment_strategy == CommentStrategy.ASSOCIATE
                    and not codeblock.parent
                ):
                    comment_chunk.append(child)
                    continue
            else:
                if child.tokens > self.max_chunk_size:
                    start_content = child.content[:100]
                    logger.warning(
                        f"Skipping code block {child.path_string()} in {file_path} as it has {child.tokens} tokens which is"
                        f" more than chunk size {self.chunk_size}. Content: {start_content}..."
                    )
                    continue

                ignoring_comment = False

            if (
                child.type in SPLIT_BLOCK_TYPES
                and child.sum_tokens() > self.min_chunk_size
            ) or parent_tokens + child.sum_tokens() > self.max_chunk_size:
                if current_chunk:
                    chunks.append(current_chunk)
                    current_chunk = []

                current_chunk.extend(comment_chunk)
                comment_chunk = []
                current_chunk.append(child)

                child_chunks = self._chunk_block(child, file_path=file_path)

                if child_chunks:
                    first_child_chunk = child_chunks[0]

                    if (
                        parent_tokens
                        + child.tokens
                        + count_chunk_tokens(first_child_chunk)
                        < self.max_chunk_size
                    ):
                        current_chunk.extend(first_child_chunk)
                        chunks.append(current_chunk)
                        chunks.extend(child_chunks[1:])
                        current_chunk = []
                    else:
                        chunks.append(current_chunk)
                        chunks.extend(child_chunks)
                        current_chunk = []

                continue

            new_token_count = (
                parent_tokens + count_chunk_tokens(current_chunk) + child.sum_tokens()
            )
            if (
                codeblock.type not in SPLIT_BLOCK_TYPES
                and new_token_count < self.max_chunk_size
                or new_token_count < self.chunk_size
            ):
                current_chunk.extend(comment_chunk)
                current_chunk.append(child)
            else:
                if current_chunk:
                    current_chunk.extend(comment_chunk)
                    chunks.append(current_chunk)
                current_chunk = [child]

            comment_chunk = []
            child_blocks = child.get_all_child_blocks()
            current_chunk.extend(child_blocks)

        if chunks and count_chunk_tokens(current_chunk) < self.min_chunk_size:
            chunks[-1].extend(current_chunk)
        else:
            chunks.append(current_chunk)

        return self._merge_chunks(chunks)
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::6
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _merge_chunks(self, chunks: list[CodeBlockChunk]) -> list[CodeBlockChunk]:
        while True:
            merged_chunks = []
            should_continue = False

            for i, chunk in enumerate(chunks):
                if (
                    count_chunk_tokens(chunk) < self.min_chunk_size
                    or len(chunks) > self.max_chunks
                ):
                    if i == 0 and len(chunks) > 1:
                        if (
                            count_chunk_tokens(chunks[1]) + count_chunk_tokens(chunk)
                            <= self.hard_token_limit
                        ):
                            chunks[1] = chunk + chunks[1]
                            should_continue = True
                        else:
                            merged_chunks.append(chunk)

                    elif i == len(chunks) - 1:
                        if (
                            merged_chunks
                            and count_chunk_tokens(merged_chunks[-1])
                            + count_chunk_tokens(chunk)
                            <= self.hard_token_limit
                        ):
                            merged_chunks[-1] = merged_chunks[-1] + chunk
                            should_continue = True
                        else:
                            merged_chunks.append(chunk)

                    else:
                        if count_chunk_tokens(chunks[i - 1]) < count_chunk_tokens(
                            chunks[i + 1]
                        ):
                            if (
                                merged_chunks
                                and count_chunk_tokens(merged_chunks[-1])
                                + count_chunk_tokens(chunk)
                                <= self.hard_token_limit
                            ):
                                merged_chunks[-1] = merged_chunks[-1] + chunk
                                should_continue = True
                            else:
                                merged_chunks.append(chunk)
                        else:
                            if (
                                count_chunk_tokens(chunks[i + 1])
                                + count_chunk_tokens(chunk)
                                <= self.hard_token_limit
                            ):
                                chunks[i + 1] = chunk + chunks[i + 1]
                                should_continue = True
                            else:
                                merged_chunks.append(chunk)
                else:
                    merged_chunks.append(chunk)

            chunks = merged_chunks + chunks[i + 1 :]

            if len(chunks) < self.max_chunks or not should_continue:
                break

        return chunks

    def _create_path_tree(self, blocks: list[CodeBlock]) -> PathTree:
        path_tree = PathTree()
        for block in blocks:
            path_tree.add_to_tree(block.full_path())
        return path_tree

    def _ignore_comment(self, codeblock: CodeBlock) -> bool:
        return (
            re.search(r"(?i)copyright|license|author", codeblock.content)
            or not codeblock.content
        )
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::7
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _to_context_string(self, codeblock: CodeBlock, path_tree: PathTree) -> str:
        contents = ""

        if codeblock.pre_lines:
            contents += "\n" * (codeblock.pre_lines - 1)
            for i, line in enumerate(codeblock.content_lines):
                if i == 0 and line:
                    contents += "\n" + codeblock.indentation + line
                elif line:
                    contents += "\n" + line
                else:
                    contents += "\n"
        else:
            contents += codeblock.pre_code + codeblock.content

        has_outcommented_code = False
        for _i, child in enumerate(codeblock.children):
            child_tree = path_tree.child_tree(child.identifier)
            if child_tree and child_tree.show:
                if (
                    has_outcommented_code
                    and child.type
                    not in [
                        CodeBlockType.COMMENT,
                        CodeBlockType.COMMENTED_OUT_CODE,
                    ]
                    and codeblock.type
                    not in [
                        CodeBlockType.CLASS,
                        CodeBlockType.MODULE,
                        CodeBlockType.TEST_SUITE,
                    ]
                ):
                    contents += child.create_commented_out_block(
                        "... other code"
                    ).to_string()
                contents += self._to_context_string(
                    codeblock=child, path_tree=child_tree
                )
                has_outcommented_code = False
            elif child_tree:
                contents += self._to_context_string(
                    codeblock=child, path_tree=child_tree
                )
                has_outcommented_code = False
            elif child.type not in [
                CodeBlockType.COMMENT,
                CodeBlockType.COMMENTED_OUT_CODE,
            ]:
                has_outcommented_code = True

        if has_outcommented_code and codeblock.type not in [
            CodeBlockType.CLASS,
            CodeBlockType.MODULE,
            CodeBlockType.TEST_SUITE,
        ]:
            contents += child.create_commented_out_block("... other code").to_string()

        return contents
--------------------------------------------------------------------------------
Chunk ID: index/epic_split.py::8
Filepath: moatless\index\epic_split.py
Content:
class EpicSplitter(NodeParser):

    def _contains_block_paths(self, codeblock: CodeBlock, block_paths: list[list[str]]):
        return [
            block_path
            for block_path in block_paths
            if block_path[: len(codeblock.full_path())] == codeblock.full_path()
        ]

    def _create_node(
        self, content: str, node: BaseNode, chunk: CodeBlockChunk | None = None
    ) -> TextNode | None:
        metadata = {}
        metadata.update(node.metadata)

        node_id = node.id_

        if chunk:
            metadata["start_line"] = chunk[0].start_line
            metadata["end_line"] = chunk[-1].end_line

            # TODO: Change this when EpicSplitter is adjusted to use the span concept natively
            span_ids = set(
                [
                    block.belongs_to_span.span_id
                    for block in chunk
                    if block.belongs_to_span
                ]
            )
            metadata["span_ids"] = list(span_ids)

            node_id += f"_{chunk[0].path_string()}_{chunk[-1].path_string()}"

        content = content.strip("\n")

        tokens = get_tokenizer()(content)
        metadata["tokens"] = len(tokens)

        excluded_embed_metadata_keys = node.excluded_embed_metadata_keys.copy()
        excluded_embed_metadata_keys.extend(["start_line", "end_line", "tokens"])

        return CodeNode(
            id_=node_id,
            text=content,
            metadata=metadata,
            excluded_embed_metadata_keys=excluded_embed_metadata_keys,
            excluded_llm_metadata_keys=node.excluded_llm_metadata_keys,
            metadata_seperator=node.metadata_seperator,
            metadata_template=node.metadata_template,
            text_template=node.text_template,
            # relationships={NodeRelationship.SOURCE: node.as_related_node_info()},
        )

    def _count_tokens(self, text: str):
        tokenizer = get_tokenizer()
        return len(tokenizer(text))
--------------------------------------------------------------------------------
Chunk ID: index/settings.py::1
Filepath: moatless\index\settings.py
Content:
import json
import os
from enum import Enum

from pydantic import BaseModel, Field


class CommentStrategy(Enum):
    # Keep comments
    INCLUDE = "include"

    # Always associate comments before a code block with the code block
    ASSOCIATE = "associate"

    # Exclude comments in parsed chunks
    EXCLUDE = "exclude"


class IndexSettings(BaseModel):
    embed_model: str = Field(
        default="text-embedding-3-small", description="The embedding model to use."
    )
    dimensions: int = Field(
        default=1536, description="The number of dimensions of the vectors."
    )

    language: str = Field(default="python", description="The language of the code.")
    min_chunk_size: int = Field(default=100, description="The minimum chunk size.")
    chunk_size: int = Field(default=750, description="The soft max chunk size.")
    hard_token_limit: int = Field(default=2000, description="The hard token limit.")
    max_chunks: int = Field(
        default=200, description="The maximum number of chunks for one file."
    )
    comment_strategy: CommentStrategy = Field(
        default=CommentStrategy.ASSOCIATE,
        description="Strategy on how comments will be indexed.",
    )

    def to_serializable_dict(self):
        data = self.dict()
        data["comment_strategy"] = data["comment_strategy"].value
        return data

    def persist(self, persist_dir: str):
        with open(os.path.join(persist_dir, "settings.json"), "w") as f:
            json.dump(self.to_serializable_dict(), f, indent=4)

    @classmethod
    def from_persist_dir(cls, persist_dir: str):
        with open(os.path.join(persist_dir, "settings.json")) as f:
            data = json.load(f)
        return cls(**data)
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::1
Filepath: moatless\index\simple_faiss.py
Content:
"""Simple vector store index."""

import json
import logging
import os
from dataclasses import dataclass, field
from typing import Any, cast

import faiss
import fsspec
import numpy as np
from dataclasses_json import DataClassJsonMixin
from fsspec.implementations.local import LocalFileSystem
from llama_index.core.bridge.pydantic import PrivateAttr
from llama_index.core.schema import BaseNode
from llama_index.core.vector_stores.simple import _build_metadata_filter_fn
from llama_index.core.vector_stores.types import (
    DEFAULT_PERSIST_DIR,
    BasePydanticVectorStore,
    VectorStoreQuery,
    VectorStoreQueryMode,
    VectorStoreQueryResult,
)
from llama_index.core.vector_stores.utils import node_to_metadata_dict

logger = logging.getLogger(__name__)

LEARNER_MODES = {
    VectorStoreQueryMode.SVM,
    VectorStoreQueryMode.LINEAR_REGRESSION,
    VectorStoreQueryMode.LOGISTIC_REGRESSION,
}

MMR_MODE = VectorStoreQueryMode.MMR

NAMESPACE_SEP = "__"
DEFAULT_VECTOR_STORE = "default"


@dataclass
class SimpleVectorStoreData(DataClassJsonMixin):
    text_id_to_ref_doc_id: dict[str, str] = field(default_factory=dict)
    vector_id_to_text_id: dict[int, str] = field(default_factory=dict)
    metadata_dict: dict[str, Any] = field(default_factory=dict)
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::2
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):
    """Simple Vector Store using Faiss as .

    In this vector store, embeddings are stored within a simple, in-memory dictionary.

    Args:
        simple_vector_store_data_dict (Optional[dict]): data dict
            containing the embeddings and doc_ids. See SimpleVectorStoreData
            for more details.
    """

    _data: SimpleVectorStoreData = PrivateAttr()
    _fs: fsspec.AbstractFileSystem = PrivateAttr()
    _faiss_index: Any = PrivateAttr()
    _d: int = PrivateAttr()

    _vector_ids_to_delete: list[int] = PrivateAttr(default_factory=list)
    _text_ids_to_delete: set[str] = PrivateAttr(default_factory=set)

    stores_text: bool = False

    def __init__(
        self,
        faiss_index: Any,
        d: int = 1536,
        data: SimpleVectorStoreData | None = None,
        fs: fsspec.AbstractFileSystem | None = None,
        **kwargs: Any,
    ) -> None:
        """Initialize params."""

        import_err_msg = """
            `faiss` package not found. For instructions on
            how to install `faiss` please visit
            https://github.com/facebookresearch/faiss/wiki/Installing-Faiss
        """
        try:
            import faiss
        except ImportError as e:
            raise ImportError(import_err_msg) from e

        self._d = d
        self._faiss_index = cast(faiss.Index, faiss_index)
        self._data = data or SimpleVectorStoreData()
        self._fs = fs or fsspec.filesystem("file")
        super().__init__(**kwargs)

    @classmethod
    def from_defaults(cls, d: int = 1536):
        faiss_index = faiss.IndexIDMap(faiss.IndexFlatL2(1536))
        return cls(faiss_index, d)

    @property
    def client(self) -> Any:
        """Return the faiss index."""
        return self._faiss_index
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::3
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):

    def add(
        self,
        nodes: list[BaseNode],
        **add_kwargs: Any,
    ) -> list[str]:
        """Add nodes to index."""

        if not nodes:
            return []

        vector_id = (
            max([int(k) for k in self._data.vector_id_to_text_id])
            if self._data.vector_id_to_text_id
            else 0
        )

        logger.info(f"Adding {len(nodes)} nodes to index, start at id {vector_id}.")

        embeddings = []
        ids = []
        for node in nodes:
            embeddings.append(node.get_embedding())
            ids.append(int(vector_id))
            self._data.vector_id_to_text_id[vector_id] = node.id_
            self._data.text_id_to_ref_doc_id[node.id_] = node.ref_doc_id or node.id_
            vector_id += 1

            metadata = node_to_metadata_dict(
                node, remove_text=True, flat_metadata=False
            )
            metadata.pop("_node_content", None)
            self._data.metadata_dict[node.node_id] = metadata

        vectors_ndarray = np.array(embeddings)
        ids_ndarray = np.array(ids)

        self._faiss_index.add_with_ids(vectors_ndarray, ids_ndarray)

        return [node.node_id for node in nodes]
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::4
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):

    def delete(self, ref_doc_id: str, **delete_kwargs: Any) -> None:
        """
        Delete nodes using with ref_doc_id.

        Args:
            ref_doc_id (str): The doc_id of the document to delete.

        """

        self._text_ids_to_delete = set()
        for text_id, ref_doc_id_ in self._data.text_id_to_ref_doc_id.items():
            if ref_doc_id == ref_doc_id_:
                self._text_ids_to_delete.add(text_id)

        for vector_id, text_id in self._data.vector_id_to_text_id.items():
            if text_id in self._text_ids_to_delete:
                self._vector_ids_to_delete.append(vector_id)
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::5
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):

    def query(
        self,
        query: VectorStoreQuery,
        **kwargs: Any,
    ) -> VectorStoreQueryResult:
        """Query index for top k most similar nodes.

        Args:
            query_embedding (List[float]): query embedding
            similarity_top_k (int): top k most similar nodes

        """
        query_filter_fn = _build_metadata_filter_fn(
            lambda node_id: self._data.metadata_dict[node_id], query.filters
        )

        query_embedding = cast(list[float], query.query_embedding)
        query_embedding_np = np.array(query_embedding, dtype="float32")[np.newaxis, :]
        dists, indices = self._faiss_index.search(
            query_embedding_np, query.similarity_top_k
        )
        dists = list(dists[0])
        if len(indices) == 0:
            return VectorStoreQueryResult(similarities=[], ids=[])

        node_idxs = indices[0]

        duplicates = 0
        not_found = 0
        filtered_out = 0

        filtered_dists = []
        filtered_node_ids = []
        for dist, idx in zip(dists, node_idxs, strict=False):
            if idx < 0:
                break

            node_id = self._data.vector_id_to_text_id.get(idx)
            if not query_filter_fn(node_id):
                filtered_out += 1
            elif node_id and node_id not in filtered_node_ids:
                filtered_node_ids.append(node_id)
                filtered_dists.append(dist.item())
            elif node_id in filtered_node_ids:
                duplicates += 1
            else:
                not_found += 1

        if not_found or duplicates:
            logger.debug(
                f"Return {len(filtered_node_ids)} nodes ({not_found} not found, {duplicates} duplicates and {filtered_out} nodes)."
            )

        return VectorStoreQueryResult(
            similarities=filtered_dists, ids=filtered_node_ids
        )
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::6
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):

    def persist(
        self,
        persist_dir: str = DEFAULT_PERSIST_DIR,
        fs: fsspec.AbstractFileSystem | None = None,
    ) -> None:
        """Persist the SimpleVectorStore to a directory."""
        fs = fs or self._fs

        # I don't think FAISS supports fsspec, it requires a path in the SWIG interface
        # TODO: write to a temporary file and then copy to the final destination
        if fs and not isinstance(fs, LocalFileSystem):
            raise NotImplementedError("FAISS only supports local storage for now.")
        import faiss

        if not os.path.exists(persist_dir):
            os.makedirs(persist_dir)

        logger.info(f"Deleting {len(self._vector_ids_to_delete)} vectors from index.")

        if self._vector_ids_to_delete:
            ids_to_remove_array = np.array(self._vector_ids_to_delete, dtype=np.int64)
            removed = self._faiss_index.remove_ids(ids_to_remove_array)
            logger.info(f"Removed {removed} vectors from index.")

        if self._text_ids_to_delete:
            for text_id in self._text_ids_to_delete:
                if self._data.metadata_dict is not None:
                    self._data.metadata_dict.pop(text_id, None)

        faiss.write_index(self._faiss_index, f"{persist_dir}/vector_index.faiss")

        for vector_id in self._vector_ids_to_delete:
            text_id = self._data.vector_id_to_text_id.pop(vector_id, None)
            if text_id:
                self._data.text_id_to_ref_doc_id.pop(text_id, None)

        self._vector_ids_to_delete = []

        with fs.open(f"{persist_dir}/vector_index.json", "w") as f:
            json.dump(self._data.to_dict(), f)
--------------------------------------------------------------------------------
Chunk ID: index/simple_faiss.py::7
Filepath: moatless\index\simple_faiss.py
Content:
class SimpleFaissVectorStore(BasePydanticVectorStore):

    @classmethod
    def from_persist_dir(
        cls, persist_dir: str, fs: fsspec.AbstractFileSystem | None = None
    ) -> "SimpleFaissVectorStore":
        """Create a SimpleKVStore from a persist directory."""

        fs = fs or fsspec.filesystem("file")
        if not fs.exists(persist_dir):
            raise ValueError(f"No existing index store found at {persist_dir}.")

        # I don't think FAISS supports fsspec, it requires a path in the SWIG interface
        # TODO: copy to a temp file and load into memory from there
        if fs and not isinstance(fs, LocalFileSystem):
            raise NotImplementedError("FAISS only supports local storage for now.")

        faiss_index = faiss.read_index(f"{persist_dir}/vector_index.faiss")

        logger.debug(f"Loading {__name__} from {persist_dir}.")
        with fs.open(f"{persist_dir}/vector_index.json", "rb") as f:
            data_dict = json.load(f)
            data = SimpleVectorStoreData.from_dict(data_dict)

        logger.info(f"Loading {__name__} from {persist_dir}.")

        return cls(faiss_index=faiss_index, data=data)

    @classmethod
    def from_index(cls, faiss_index: Any):
        return cls(faiss_index)

    def to_dict(self) -> dict:
        return self._data.to_dict()
--------------------------------------------------------------------------------
Chunk ID: index/types.py::1
Filepath: moatless\index\types.py
Content:
from dataclasses import dataclass
from typing import Optional

from pydantic import BaseModel, Field


@dataclass
class CodeSnippet:
    id: str
    file_path: str
    content: str = None
    distance: float = 0.0
    tokens: int = None
    language: str = "python"
    span_ids: list[str] = None
    start_line: Optional[int] = None
    end_line: Optional[int] = None
    start_block: Optional[str] = None
    end_block: Optional[str] = None


class SpanHit(BaseModel):
    span_id: str = Field(description="The span id of the relevant code in the file")
    rank: int = Field(
        default=0,
        description="The rank of relevance of the span in the file. 0 is highest.",
    )
    tokens: int = Field(default=0, description="The number of tokens in the span.")
--------------------------------------------------------------------------------
Chunk ID: index/types.py::2
Filepath: moatless\index\types.py
Content:
class SearchCodeHit(BaseModel):
    file_path: str = Field(
        description="The file path where the relevant code is found."
    )
    spans: list[SpanHit] = Field(
        default_factory=list,
        description="The spans of the relevant code in the file",
    )

    @property
    def span_ids(self):
        return [span.span_id for span in self.spans]

    def add_span(self, span_id: str, rank: int = 0, tokens: int = 0):
        if span_id not in [span.span_id for span in self.spans]:
            self.spans.append(SpanHit(span_id=span_id, rank=rank, tokens=tokens))

    def contains_span(self, span_id: str) -> bool:
        return span_id in [span.span_id for span in self.spans]

    def add_spans(self, span_ids: list[str], rank: int = 0):
        for span_id in span_ids:
            self.add_span(span_id, rank)


class SearchCodeResponse(BaseModel):
    message: Optional[str] = Field(
        default=None, description="A message to return to the user."
    )

    hits: list[SearchCodeHit] = Field(
        default_factory=list,
        description="Search results.",
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::1
Filepath: moatless\loop.py
Content:
import json
import logging
import os
import random
import string
import sys
import traceback
from collections.abc import Callable
from datetime import datetime
from typing import Any, Optional, Type, Tuple
import subprocess

import instructor
import litellm
from anthropic import Anthropic
from litellm import completion_cost, cost_per_token, token_counter
from pydantic import BaseModel, Field, PrivateAttr, ConfigDict

from moatless.repository import GitRepository
from moatless.state import (
    AgenticState,
    Finished,
    NoopState,
    Pending,
    Rejected,
    get_state_class,
)
from moatless.trajectory import Trajectory
from moatless.transition_rules import TransitionRule, TransitionRules
from moatless.types import (
    ActionRequest,
    AssistantMessage,
    Content,
    Message,
    Response,
    Usage,
    UserMessage,
)
from moatless.utils.llm_utils import instructor_mode_by_model
from moatless.workspace import Workspace

logger = logging.getLogger("Loop")
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::2
Filepath: moatless\loop.py
Content:
class AgenticLoop:
    def __init__(
        self,
        transition_rules: TransitionRules,
        workspace: Workspace,
        input_data: dict[str, Any] | None = None,
        initial_message: str | None = None,
        trajectory: Trajectory | None = None,
        mocked_actions: list[dict] | None = None,
        expected_states: list[Type[AgenticState]] | None = None,
        reset_mocks_at_state: Optional[str] = None,
        verify_state_func: Optional[Callable] = None,
        max_cost: float = 0.25,
        max_actions: int = 2,
        max_transitions: int = 25,
        max_message_tokens: Optional[int] = None,
        max_retries: int = 2,
        max_rejections: int = 2,
        instructor_mode: instructor.Mode | None = None,
        metadata: dict[str, Any] | None = None,
        trajectory_path: Optional[str] = None,
        prompt_log_dir: Optional[str] = None,
        **kwargs,
    ):
        """
        Initialize the Loop instance.

        Args:

        """

        self._workspace = workspace

        self._input_data = input_data

        if trajectory_path:
            parent_dir = os.path.dirname(trajectory_path)
            if not os.path.exists(parent_dir):
                os.makedirs(parent_dir)
        self._trajectory_path = trajectory_path

        if not trajectory:
            self._trajectory = Trajectory(
                "MoatlessTools",
                initial_message=initial_message,
                persist_path=self._trajectory_path,
                workspace=self._workspace,
                transition_rules=transition_rules,
            )
            pending_state = Pending()
            self._trajectory.save_state(pending_state)
            self._set_current_state(pending_state)
        else:
            self._trajectory = trajectory
            self._current_state = trajectory.get_current_state()

        self._initial_message = initial_message

        if prompt_log_dir and not os.path.exists(prompt_log_dir):
            os.makedirs(prompt_log_dir)
        self._prompt_log_dir = prompt_log_dir

        if expected_states and not verify_state_func:

            def verify_state_func(state: AgenticState):
                nonlocal expected_states
                if not expected_states:
                    raise ValueError(
                        f"No more expected states, but got {state.__class__}"
                    )
                expected_state = expected_states.pop(0)
                if isinstance(expected_state, str):
                    if state.name != expected_state:
                        raise ValueError(
                            f"Expected state {expected_state} but got {state.__class__.__name__}"
                        )
                elif isinstance(expected_state, AgenticState) and not isinstance(state, expected_state):
                    raise ValueError(
                        f"Expected state {expected_state} but got {state.__class__.__name__}"
                    )

                self.log_info(f"Verified expected next state {expected_state}")

        self._verify_state_func = verify_state_func
        self._mocked_actions = mocked_actions
        self._reset_mocks_at_state = reset_mocks_at_state

        self._max_cost = max_cost
        self._max_message_tokens = max_message_tokens
        self._max_transitions = max_transitions
        self._max_actions = max_actions
        self._max_retries = max_retries
        self._max_rejections = max_rejections
        self._instructor_mode = instructor_mode

        self._transition_count = 0
        self._rejections = 0

        self._transition_rules = transition_rules
        self._metadata = metadata

    @classmethod
    def from_trajectory_file(cls, trajectory_path: str, **kwargs):
        trajectory = Trajectory.load(trajectory_path)
        return cls(
            transition_rules=trajectory.transitions,
            trajectory=trajectory,
            workspace=trajectory.workspace,
            **kwargs,
        )

    def persist(self, trajectory_path: str):
        self.trajectory.persist(trajectory_path)
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::3
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def run(self, message: Optional[str] = None) -> Response:
        """
        Executes the entire loop until completion or termination.

        This method initializes the loop if it hasn't started, and then repeatedly
        calls run_until_transition() until the loop is finished. It handles the
        overall flow of the loop, including initialization and final state processing.

        Args:
            message (Optional[str]): An optional initial message to start the loop with.

        Returns:
            Response: An object containing the final status and message of the loop.
                The status will be either "finished" or "rejected".

        Raises:
            RuntimeError: If an unexpected state or condition occurs during execution.
                This includes cases where the loop is already running, exits with an 
                unknown state, or encounters other unexpected runtime conditions.

        Note:
            This method will continue running until a Finished or Rejected state is reached,
            or until an exception occurs. It's designed to be the main entry point for
            executing the entire loop process.
        """
        if self.is_running():
            raise RuntimeError("Loop is already running.")

        # TODO: Move to always set this when the Loop is created instead
        if message:
            logger.warning("Setting initial message in run is deprecated. Set in contructor.")
            self._initial_message = message
            self._trajectory._initial_message = message

        if not isinstance(self._current_state, Pending):
            self._trajectory.update_workspace_to_current_state()

        while not self.is_finished():
            self._execute_state_until_transition()

        if isinstance(self.state, Finished):
            return Response(status="finished", message=self.state.message or "")
        elif isinstance(self.state, Rejected):
            return Response(status="rejected", message=self.state.message or "")

        raise RuntimeError(f"Loop exited with unknown state {self.state.name}.")
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::4
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def _execute_state_until_transition(self) -> AgenticState | None:
        """
        Executes the state until a transition to a new state occurs.

        This method executes the state, processing actions and handling
        state changes until one of the following conditions is met:
        1. A transition to a new state occurs
        2. Maximum cost, retries, or transitions are exceeded

        Returns:
            AgenticState: The new state after a transition occurs

        Raises:
            RuntimeError: If the loop exits without a transition or if the maximum cost is exceeded
            ValueError: If the maximum number of retries is reached
        """
        while not self.state.executed:
            total_cost = self.total_cost()
            if total_cost > self._max_cost:
                self.log_info(f"Max cost reached ({total_cost} > {self._max_cost}). Exiting.")
                self.trajectory.save_info({"error": "Max cost reached."})
                raise RuntimeError("The loop was aborted because the cost exceeded the limit.")

            self.log_info(f"Running transition {len(self._trajectory.states)}. Current total cost: {total_cost}")

            try:
                state = self._execute_state()
                if state:
                    return state
            except Exception as e:
                self.log_info(f"Failed to run loop. Error: {e}")
                raise

            if self.state.retries() > self._max_retries:
                self.log_info(f"Max retries reached ({self._max_retries}). Exiting.")
                self.trajectory.save_info({"error": "Max retries reached."})
                return self.transition_to(Rejected(message="Max retries reached."))

        raise RuntimeError("Loop exited without a transition.")
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::5
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def _execute_state(self) -> AgenticState | None:
        """
        Execute one iteration of the current state and handle potential transitions.

        Processes the next action, updates the trajectory, and determines if a state
        transition should occur based on the action's response.

        Returns:
            AgenticState | None: The next state if transitioning, or None if remaining in the current state.

        Raises:
            ValueError: 
        """
        if self.state.executed:
            raise ValueError("Tried to execute already executed state.")

        if isinstance(self.state, Pending):
            logger.info("Initializing first state.")
            trigger = "init"
            output = {}

        else:
            action, usage = self._next_action()

            self.log_info(f"Received new action {action.action_name}.")
            response = self.state.handle_action(action, usage)

            if not response.trigger:
                self.log_info(
                    f"{self.state.name}: No trigger in action response. Staying in the same state."
                )
                return None

            self.log_info(f"Received response with trigger {response.trigger}")

            if response.trigger == "retry":
                self.log_info(f"Retry requested. {response.retry_message}")
                return None

            trigger = response.trigger
            output = response.output

        transition_rule = self._transition_rules.get_next_rule(
            self.state,
            trigger,
            output,
        )
        if not transition_rule:
            raise RuntimeError(
                f"No transition rule found for {self.state.name} with trigger {response.trigger} and output {response.output}"
            )

        next_state = self._create_state(transition_rule, output)
        return self.transition_to(next_state)
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::6
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def _create_state(self, transition_rule: TransitionRule, output: dict) -> AgenticState:
        params = {}
        params.update(self._transition_rules.params(transition_rule))

        for k, v in output.items():
            if transition_rule.excluded_fields and k in transition_rule.excluded_fields:
                continue

            params[k] = v

        params["id"] = self.state_count()

        next_state_type = transition_rule.dest
        if next_state_type not in [Finished, Rejected]:

            if self.state_count() >= self._max_transitions:
                self.log_info(f"Max transitions exceeded ({self._max_transitions}). Transitioning to Rejected.")
                next_state_type = Rejected
                params["message"] = "Max transitions exceeded."
            if (
                params.get("max_iterations")
                and self.state_count(next_state_type) >= params["max_iterations"]
            ):
                self.log_info(f"Max iterations exceeded ({params['max_iterations']}). Transitioning to Rejected.")
                next_state_type = Rejected
                params["message"] = f"Max iterations exceeded ({params['max_iterations']})."

        self.log_info(f"Creating state {next_state_type.__name__} with params {params}")

        try:
            next_state = next_state_type.model_validate(params)
            next_state.previous_state = self._current_state
            next_state._workspace = self._workspace
            next_state._initial_message = self._initial_message
        except Exception as e:
            logger.error(f"Failed to create state {next_state_type.__name__} with params {params}")
            raise e

        self._trajectory.save_state(next_state)
        self._current_state.next_states.append(next_state)
        return next_state
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::7
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def total_cost(self):
        total_cost = 0
        for state in self._trajectory.transitions:
            total_cost += state.state.total_cost()
        return total_cost

    def is_running(self) -> bool:
        return not isinstance(self.state, NoopState)

    def is_finished(self) -> bool:
        return isinstance(self.state, (Finished, Rejected))

    def _set_current_state(self, state: AgenticState):
        self._current_state = state
        self._trajectory.set_current_state(state)

    def transition_to(self, new_state: AgenticState) -> AgenticState:
        self.log_info(f"Transitioning from {self.state.name} to {new_state.name}")

        self._trajectory.save_state(new_state)
        self._set_current_state(new_state)

        return new_state
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::8
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def _next_action(
        self,
    ) -> Tuple[ActionRequest, Usage | None]:
        messages = self._to_completion_messages()
        self.log_info(f"Create completion with {len(messages)} messages")

        if self._verify_state_func:
            self._verify_state_func(self.state)

        mocked_action = self._next_mock_action()
        if mocked_action:
            return mocked_action, None

        metadata = {}
        if self._metadata:
            metadata.update(self._metadata)
        metadata["generation_name"] = self.state.name

        tokens = token_counter(messages=messages[-1:])
        if self._max_message_tokens and tokens > self._max_message_tokens:
            raise ValueError(f"Too many tokens in the new message: {tokens}")

        self.log_info(f"Do completion request to {self.state.model}")

        if self.state.model.startswith("claude") and self.state.action_type():
            try:
                anthropic_client = instructor.from_anthropic(
                    Anthropic(),
                    mode=self.instructor_mode,
                )

                action_request, completion_response = (
                    anthropic_client.chat.completions.create_with_completion(
                        model=self.state.model,
                        max_tokens=self.state.max_tokens,
                        temperature=self.state.temperature,
                        # stop=self.state.stop_words(),
                        response_model=self.state.action_type(),
                        messages=messages,
                    )
                )

                self.log_info(
                    f"Input tokens: {completion_response.usage.input_tokens}, Output tokens: {completion_response.usage.output_tokens}"
                )
                (
                    prompt_tokens_cost_usd_dollar,
                    completion_tokens_cost_usd_dollar,
                ) = cost_per_token(
                    model=self.state.model,
                    prompt_tokens=completion_response.usage.input_tokens,
                    completion_tokens=completion_response.usage.output_tokens,
                )
                _final_cost = (
                    prompt_tokens_cost_usd_dollar + completion_tokens_cost_usd_dollar
                )
            except Exception as e:
                self._log_prompt(messages, error=traceback.format_exc())
                raise e


            self._log_prompt(messages, completion_response.content)

            usage = Usage(
                completion_cost=_final_cost,
                completion_tokens=completion_response.usage.output_tokens,
                prompt_tokens=completion_response.usage.input_tokens,
            )

            return action_request, usage

        if self.state.action_type() is None:
            completion_response = litellm.completion(
                model=self.state.model,
                max_tokens=self.state.max_tokens,
                temperature=self.state.temperature,
                stop=self.state.stop_words(),
                metadata=metadata,
                messages=messages,
            )
            action_request = Content(
                content=completion_response.choices[0].message.content
            )
        else:
            client = instructor.from_litellm(
                litellm.completion, mode=self.instructor_mode
            )

            try:
                action_request, completion_response = (
                    client.chat.completions.create_with_completion(
                        model=self.state.model,
                        max_tokens=self.state.max_tokens,
                        temperature=self.state.temperature,
                        stop=self.state.stop_words(),
                        response_model=self.state.action_type(),
                        metadata=metadata,
                        messages=messages,
                    )
                )
            except Exception as e:
                self._log_prompt(messages, error=traceback.format_exc())
                raise e

        try:
            cost = completion_cost(
                completion_response=completion_response,
                model=self.state.model,
            )
        except Exception as e:
            self.log_info(f"Error calculating completion cost: {e}")
            cost = 0

        self._log_prompt(
            messages, [completion_response.choices[0].message.model_dump()], error=None
        )
        prompt_tokens = completion_response.get("usage", {}).get("prompt_tokens", 0)
        completion_tokens = completion_response.get("usage", {}).get(
            "completion_tokens", 0
        )
        usage = Usage(
            completion_cost=cost,
            completion_tokens=completion_tokens,
            prompt_tokens=prompt_tokens,
        )
        return action_request, usage
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::9
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    def state_count(self, state: AgenticState | None = None) -> int:
        if not state:
            return len(self._trajectory.transitions)

        return len(
            [s for s in self._trajectory.transitions if s.state.name == state.name]
        )

    @property
    def state(self):
        return self._current_state

    @property
    def workspace(self) -> Workspace:
        return self._workspace

    @property
    def trajectory(self):
        return self._trajectory

    def _to_completion_messages(self) -> list[dict]:
        messages = [{"role": "system", "content": self.state.system_prompt()}]

        tool_call_id = None
        state_messages = self.state.messages()
        for message in state_messages:
            if message.role == "user":
                if tool_call_id and self.instructor_mode == instructor.Mode.TOOLS:
                    messages.append(
                        {
                            "role": "tool",
                            "tool_call_id": tool_call_id,
                            "content": message.content,
                        }
                    )
                elif (
                    tool_call_id
                    and self.instructor_mode == instructor.Mode.ANTHROPIC_TOOLS
                ):
                    messages.append(
                        {
                            "role": "user",
                            "content": [
                                {
                                    "tool_use_id": tool_call_id,
                                    "content": message.content,
                                    "type": "tool_result",
                                }
                            ],
                        }
                    )
                else:
                    messages.append({"role": "user", "content": message.content})
            elif message.role == "assistant":
                if message.action:
                    tool_call_id = generate_call_id()
                    if self.instructor_mode == instructor.Mode.ANTHROPIC_TOOLS:
                        messages.append(
                            {
                                "role": "assistant",
                                "content": [
                                    {
                                        "id": tool_call_id,
                                        "input": message.action.model_dump(),
                                        "type": "tool_use",
                                        "name": message.action.action_name,
                                    }
                                ],
                            }
                        )
                    elif self.instructor_mode == instructor.Mode.TOOLS:
                        messages.append(
                            {
                                "role": "assistant",
                                "tool_calls": [
                                    {
                                        "id": tool_call_id,
                                        "type": "function",
                                        "function": {
                                            "name": message.action.action_name,
                                            "arguments": message.action.model_dump_json(
                                                exclude_none=True
                                            ),
                                        },
                                    }
                                ],
                            }
                        )
                    else:
                        json_content = message.action.model_dump_json(indent=2)

                        if self.state.model.startswith("deepseek"):
                            json_content = f"```json\n{json_content}\n```"

                        messages.append(
                            {
                                "role": "assistant",
                                "content": json_content,
                            }
                        )

                else:
                    tool_call_id = None
                    messages.append({"role": "assistant", "content": message.content})

        return messages
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::10
Filepath: moatless\loop.py
Content:
class AgenticLoop:

    @property
    def instructor_mode(self):
        if self._instructor_mode:
            return self._instructor_mode

        return instructor_mode_by_model(self.state.model)

    def _next_mock_action(
        self,
    ) -> ActionRequest | None:
        if not self._mocked_actions:
            return None

        if self._reset_mocks_at_state and self.state.name == self._reset_mocks_at_state:
            self.log_info(f"Resetting mocked actions at state {self.state.name}")
            self._mocked_actions = []
            return None

        action = self._mocked_actions.pop(0)

        if self.state.action_type():
            try:
                self.log_info(
                    f"Return mocked response with type {self.state.action_type().__name__} ({len(self._mocked_actions)} left)."
                )
                return self.state.action_type().model_validate(action)

            except Exception:
                logger.error(
                    f"{self.transition_name}: Failed to parse {action} to {self.state.action_type().__name__} in state {self.state.name}"
                )
                raise
        elif "content" in action:
            self.log_info(f"Return mocked response ({len(self._mocked_actions)} left).")
            return Content(content=action["content"])

        else:
            raise ValueError(f"Mocked action {action} does not have 'content' field.")
--------------------------------------------------------------------------------
Chunk ID: moatless/loop.py::11
Filepath: moatless\loop.py
Content:
class AgenticLoop:


    def _log_prompt(
        self,
        messages: list[dict],
        completion: Any | None = None,
        error: Optional[str] = None,
    ):
        if not self._prompt_log_dir:
            return

        time_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        prompt_path = (
            f"{self._prompt_log_dir}/{self._current_state.id}_{self._current_state.name}"
        )
        if self.state.retries() > 0:
            prompt_path += f"_retry_{self.state.retries()}"

        prompt_path += f"_{time_str}.md"

        with open(prompt_path, "w") as f:
            f.write("\n\n# Completion\n")

            f.write("\n\n## Input\n")
            for message in messages:
                f.write(f"\n\n### {message['role']}\n\n")

                if "content" in message:
                    if isinstance(message["content"], str):
                        f.write(message["content"])
                    elif isinstance(message["content"], list):
                        for content in message["content"]:
                            if isinstance(content, str):
                                f.write(content)
                            if isinstance(content, dict) and "content" in content:
                                f.write(content["content"])
                            else:
                                f.write(
                                    f"\n\n```json\n{json.dumps(content, indent=2)}\n```"
                                )
                elif isinstance(message.get("content"), list):
                    for block in message["content"]:
                        f.write(f"\n\n### {block['tool_use_id']}\n")
                        f.write(block["content"])
                else:
                    f.write(f"\n\n```json\n{json.dumps(message, indent=2)}\n```")

            if completion:
                f.write("\n\n## Output\n")

                if isinstance(completion, list):
                    for block in completion:
                        if isinstance(block, BaseModel):
                            block = block.model_dump()

                        if isinstance(block, dict):
                            if block.get("content"):
                                f.write(f"{block.get('content')}\n")
                            else:
                                f.write(f"```json\n{json.dumps(block, indent=2)}\n```")
                        else:
                            f.write(f"```json\n{json.dumps(block, indent=2)}\n```")
                else:
                    f.write(f"```json\n{json.dumps(completion, indent=2)}\n```")

            if error:
                f.write("\n\n# Error\n")
                f.write(f"\n```\n{error}\n```\n")

    def log_info(self, message: str):
        logger.info(f"{self.transition_name}: {message}")

    @property
    def transition_name(self):
        if self._current_state:
            return f"{self._current_state.name}:{self._current_state.id}"
        else:
            return "No state"


def generate_call_id():
    prefix = "call_"
    chars = string.ascii_letters + string.digits
    length = 24

    random_chars = "".join(random.choices(chars, k=length))

    random_string = prefix + random_chars

    return random_string
--------------------------------------------------------------------------------
Chunk ID: repository/__init__.py::1
Filepath: moatless\repository\__init__.py
Content:
from moatless.repository.file import CodeFile, FileRepository, UpdateResult
from moatless.repository.git import GitRepository
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::1
Filepath: moatless\repository\file.py
Content:
import difflib
import glob
import logging
import os
from dataclasses import dataclass
from typing import Optional

from pydantic import BaseModel, ConfigDict

from moatless.codeblocks import get_parser_by_path
from moatless.codeblocks.codeblocks import CodeBlockType, CodeBlockTypeGroup
from moatless.codeblocks.module import Module
from moatless.codeblocks.parser.python import PythonParser

logger = logging.getLogger(__name__)


@dataclass
class UpdateResult:
    file_path: str
    updated: bool
    diff: Optional[str] = None
    error: Optional[str] = None
    new_span_ids: set[str] | None = None
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::2
Filepath: moatless\repository\file.py
Content:
class CodeFile(BaseModel):
    file_path: str
    content: str
    module: Module | None = None
    dirty: bool = False

    model_config = ConfigDict(exclude={"module", "dirty"})

    @classmethod
    def from_file(cls, repo_path: str, file_path: str):
        with open(os.path.join(repo_path, file_path)) as f:
            parser = get_parser_by_path(file_path)
            if parser:
                content = f.read()
                module = parser.parse(content)
            else:
                module = None
            return cls(file_path=file_path, content=content, module=module)

    @classmethod
    def from_content(cls, file_path: str, content: str):
        parser = PythonParser()
        module = parser.parse(content)
        return cls(file_path=file_path, content=content, module=module)

    @property
    def supports_codeblocks(self):
        return self.module is not None
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::3
Filepath: moatless\repository\file.py
Content:
class CodeFile(BaseModel):

    def update_content_by_line_numbers(
        self, start_line_index: int, end_line_index: int, replacement_content: str
    ) -> UpdateResult:
        replacement_lines = replacement_content.split("\n")

        # Strip empty lines from the start and end
        while replacement_lines and replacement_lines[0].strip() == "":
            replacement_lines.pop(0)

        while replacement_lines and replacement_lines[-1].strip() == "":
            replacement_lines.pop()

        original_lines = self.content.split("\n")

        replacement_lines = remove_duplicate_lines(
            replacement_lines, original_lines[end_line_index:]
        )

        updated_lines = (
            original_lines[:start_line_index]
            + replacement_lines
            + original_lines[end_line_index:]
        )
        updated_content = "\n".join(updated_lines)
        logger.info(
            f"Updating content for {self.file_path} from line {start_line_index} to {end_line_index} with {len(replacement_lines)} lines. The updated file has {len(updated_lines)} lines."
        )

        return self.update_content(updated_content)
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::4
Filepath: moatless\repository\file.py
Content:
class CodeFile(BaseModel):

    def update_content(self, updated_content: str) -> UpdateResult:
        diff = do_diff(self.file_path, self.content, updated_content)
        if diff:
            parser = get_parser_by_path(self.file_path)
            if parser:
                module = parser.parse(updated_content)
                if not module.children:
                    return UpdateResult(
                        file_path=self.file_path,
                        updated=False,
                        diff=diff,
                        error="The updated code is invalid.",
                    )

                # TODO: Move the prompt instructions to the loop
                error_blocks = module.find_errors()
                validation_errors = module.find_validation_errors()
                existing_placeholders = self.module.find_blocks_with_type(
                    CodeBlockType.COMMENTED_OUT_CODE
                )
                new_placeholders = (
                    module.find_blocks_with_type(CodeBlockType.COMMENTED_OUT_CODE)
                    if not existing_placeholders
                    else []
                )
                if error_blocks or validation_errors or new_placeholders:
                    error_response = ""
                    if error_blocks:
                        for error_block in error_blocks:
                            parent_block = error_block.find_type_group_in_parents(
                                CodeBlockTypeGroup.STRUCTURE
                            )
                            if (
                                parent_block
                                and parent_block.type != CodeBlockType.MODULE
                            ):
                                error_response += f"{parent_block.type.name} has invalid code:\n\n```{parent_block.to_string()}\n```.\n"
                            else:
                                error_response += f"This code is invalid: \n```{error_block.to_string()}\n```.\n"

                    if new_placeholders:
                        for new_placeholder in new_placeholders:
                            parent_block = new_placeholder.find_type_group_in_parents(
                                CodeBlockTypeGroup.STRUCTURE
                            )
                            if parent_block:
                                error_response += f"{parent_block.identifier} has a placeholder `{new_placeholder.content}` indicating that it's not fully implemented. Implement the full {parent_block.type.name} or reject the request.: \n\n```{parent_block.to_string()}```\n\n"
                            else:
                                error_response += f"There is a placeholder indicating out commented code : \n```{new_placeholder.to_string()}\n```. Do the full implementation or reject the request.\n"

                    for validation_error in validation_errors:
                        error_response += f"{validation_error}\n"

                    logger.warning(
                        f"Errors in updated file {self.file_path}:\n{error_response}"
                    )

                    return UpdateResult(
                        file_path=self.file_path,
                        updated=False,
                        diff=diff,
                        error=error_response,
                    )

                new_span_ids = module.get_all_span_ids() - set(
                    self.module.get_all_span_ids()
                )

                logger.info(
                    f"Updated content for {self.file_path} with {len(new_span_ids)} new span ids."
                )
                self.module = module
            else:
                new_span_ids = []

            self.dirty = True
            self.content = updated_content

            return UpdateResult(
                file_path=self.file_path,
                updated=True,
                diff=diff,
                new_span_ids=new_span_ids,
            )

        return UpdateResult(file_path=self.file_path, updated=False)
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::5
Filepath: moatless\repository\file.py
Content:
class FileRepository:
    def __init__(self, repo_path: str):
        self._repo_path = repo_path
        self._files: dict[str, CodeFile] = {}

    @property
    def repo_dir(self):
        return self._repo_path

    def dict(self):
        return {"type": "file", "path": self._repo_path}

    def snapshot(self) -> dict:
        return {}

    def restore_from_snapshot(self, snapshot: dict):
        pass

    def restore_from_disk(self):
        for file_path in self._files.keys():
            self.get_file(file_path, refresh=True)

    @property
    def path(self):
        return self._repo_path
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::6
Filepath: moatless\repository\file.py
Content:
class FileRepository:

    def get_file(
        self, file_path: str, refresh: bool = False, from_origin: bool = False
    ):
        """
        Get a file from the repository.

        Args:

        """
        existing_file = self._files.get(file_path)
        if not existing_file or refresh or from_origin:
            full_file_path = os.path.join(self._repo_path, file_path)
            if not os.path.exists(full_file_path):
                logger.warning(f"File not found: {full_file_path}")
                return None
            if not os.path.isfile(full_file_path):
                logger.warning(f"{full_file_path} is not a file")
                return None

            with open(full_file_path) as f:
                parser = get_parser_by_path(file_path)
                if parser:
                    content = f.read()
                    module = parser.parse(content)
                    found_file = CodeFile(file_path=file_path, content=content, module=module)
                else:
                    found_file = CodeFile(file_path=file_path, content=f.read())

            if not existing_file:
                existing_file = found_file
                self._files[file_path] = existing_file
            elif refresh or not from_origin:
                existing_file.content = found_file.content
                existing_file.module = found_file.module
                existing_file.dirty = False

        return existing_file
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::7
Filepath: moatless\repository\file.py
Content:
class FileRepository:

    def save_file(self, file_path: str, updated_content: Optional[str] = None):
        file = self._files.get(file_path)
        full_file_path = os.path.join(self._repo_path, file_path)
        with open(full_file_path, "w") as f:
            updated_content = updated_content or file.module.to_string()
            f.write(updated_content)

        file.dirty = False

    def save(self):
        for file in self._files.values():
            if file.dirty:
                self.save_file(file.file_path, file.content)

    def matching_files(self, file_pattern: str):
        matched_files = []
        for matched_file in glob.iglob(
            file_pattern, root_dir=self._repo_path, recursive=True
        ):
            matched_files.append(matched_file)

        if not matched_files and not file_pattern.startswith("*"):
            return self.matching_files(f"**/{file_pattern}")

        return matched_files

    def find_files(self, file_patterns: list[str]) -> set[str]:
        found_files = set()
        for file_pattern in file_patterns:
            matched_files = self.matching_files(file_pattern)
            found_files.update(matched_files)

        return found_files

    def has_matching_files(self, file_pattern: str):
        for _matched_file in glob.iglob(
            file_pattern, root_dir=self._repo_path, recursive=True
        ):
            return True
        return False

    def file_match(self, file_pattern: str, file_path: str):
        match = False
        for matched_file in glob.iglob(
            file_pattern, root_dir=self._repo_path, recursive=True
        ):
            if matched_file == file_path:
                match = True
                break
        return match
--------------------------------------------------------------------------------
Chunk ID: repository/file.py::8
Filepath: moatless\repository\file.py
Content:
def remove_duplicate_lines(replacement_lines, original_lines):
    """
    Removes overlapping lines at the end of replacement_lines that match the beginning of original_lines.
    """
    if not replacement_lines or not original_lines:
        return replacement_lines

    max_overlap = min(len(replacement_lines), len(original_lines))

    for overlap in range(max_overlap, 0, -1):
        if replacement_lines[-overlap:] == original_lines[:overlap]:
            return replacement_lines[:-overlap]

    return replacement_lines


def do_diff(
    file_path: str, original_content: str, updated_content: str
) -> Optional[str]:
    return "".join(
        difflib.unified_diff(
            original_content.strip().splitlines(True),
            updated_content.strip().splitlines(True),
            fromfile=file_path,
            tofile=file_path,
            lineterm="\n",
        )
    )
--------------------------------------------------------------------------------
Chunk ID: repository/git.py::1
Filepath: moatless\repository\git.py
Content:
import logging
from typing import Optional

import litellm
from git import Repo

from moatless.repository.file import FileRepository
from moatless.settings import Settings
from moatless.utils.repo import maybe_clone, checkout_commit

logger = logging.getLogger(__name__)


class GitRepository(FileRepository):
    def __init__(
        self, repo_path: str, git_repo_url: Optional[str], commit: Optional[str] = None
    ):
        super().__init__(repo_path)
        self._repo_path = repo_path
        self._repo_url = git_repo_url
        self._repo = Repo(path=repo_path)
        if not self._repo.heads:
            raise Exception(
                "Git repository has no heads, you need to do an initial commit."
            )

        # TODO: Add support for branches
        # self._current_branch = self._repo.active_branch.name

        # TODO: Check if current branch is mainline

        # TODO: Check if repo is dirty

        if commit:
            checkout_commit(repo_path, commit)

        self._current_commit = self._repo.head.commit.hexsha
        self._initial_commit = self._current_commit

    @classmethod
    def from_repo(cls, git_repo_url: str, repo_path: str, commit: Optional[str] = None):
        logger.info(
            f"Create GitRepository for {git_repo_url} with commit {commit} on path {repo_path} "
        )

        maybe_clone(git_repo_url, repo_path)

        return cls(repo_path=repo_path, git_repo_url=git_repo_url, commit=commit)

    @classmethod
    def from_dict(cls, data: dict):
        return cls.from_repo(
            git_repo_url=data["repo_url"],
            repo_path=data["path"],
            commit=data["commit"],
        )

    def restore_from_snapshot(self, snapshot: dict):
        self._current_commit = snapshot["commit"]


        self._repo.git.checkout(self._current_commit)

        # TODO: Check diff and only reset changed files

        self.restore_from_disk()

    def dict(self):
        return {
            "type": "git",
            "repo_path": self._repo_path,
            "git_repo_url": self._repo_url,
            "commit": self._initial_commit,
        }

    def snapshot(self) -> dict:
        return {
            "commit": self._current_commit,
        }

    def save_file(self, file_path: str, updated_content: Optional[str] = None):
        super().save_file(file_path, updated_content)
        self.commit(file_path)

    def save(self):
        super().save()
        self.commit()

    def commit(self, file_path: str | None = None):
        commit_message = self.commit_message(file_path)

        if file_path:
            self._repo.index.add(file_path)
        else:
            self._repo.index.add("*")
        self._repo.index.commit(commit_message)
        self._current_commit = self._repo.head.commit.hexsha

        logger.info(f"Committed changes to git with message '{commit_message}' and commit hash '{self._current_commit}'")
--------------------------------------------------------------------------------
Chunk ID: repository/git.py::2
Filepath: moatless\repository\git.py
Content:
class GitRepository(FileRepository):

    def commit_message(self, file_path: str | None = None) -> str:
        if file_path:
            diff = self._repo.git.diff("HEAD", file_path)
        else:
            diff = self._repo.git.diff("HEAD")

        if not diff:
            return "No changes."

        if Settings.cheap_model:
            prompt = f"Generate a concise commit message for the following git diff"
            if file_path:
                prompt += f" of file {file_path}"
            prompt += f":\n\n{diff}\n\nCommit message:"

            try:
                response = litellm.completion(
                    model=Settings.cheap_model,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=50,
                )
                return response.choices[0].message.content.strip()
            except Exception as e:
                logging.error(f"Error generating commit message: {e}")

        return "Automated commit by Moatless Tools"

    def diff(self):
        return self._repo.git.diff(self._initial_commit, self._current_commit)
--------------------------------------------------------------------------------
Chunk ID: moatless/settings.py::1
Filepath: moatless\settings.py
Content:
import os
from dataclasses import dataclass


@dataclass
class _Settings:
    _default_model: str = os.environ.get("DEFAULT_MODEL", "gpt-4o-2024-05-13")
    _cheap_model: str | None = os.environ.get("CHEAP_MODEL", "gpt-4o-mini-2024-07-18")
    _embed_model: str = "text-embedding-3-small"

    _max_context_tokens: int = 8000
    _max_message_tokens: int = 16000

    @property
    def default_model(self) -> str:
        return self._default_model

    @default_model.setter
    def default_model(self, default_model: str) -> None:
        self._default_model = default_model

    @property
    def cheap_model(self) -> str | None:
        return self._cheap_model

    @cheap_model.setter
    def cheap_model(self, cheap_model: str | None) -> None:
        self._cheap_model = cheap_model

    @property
    def embed_model(self) -> str:
        return self._embed_model

    @embed_model.setter
    def embed_model(self, embed_model: str) -> None:
        self._embed_model = embed_model

    @property
    def max_context_tokens(self) -> int:
        return self._max_context_tokens

    @max_context_tokens.setter
    def max_context_tokens(self, max_context_tokens: int) -> None:
        self._max_context_tokens = max_context_tokens

    @property
    def max_message_tokens(self) -> int:
        return self._max_message_tokens

    @max_message_tokens.setter
    def max_message_tokens(self, max_message_tokens: int) -> None:
        self._max_message_tokens = max_message_tokens


Settings = _Settings()
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::1
Filepath: moatless\state.py
Content:
import logging
import sys
import importlib
from abc import ABC, abstractmethod
from typing import Any, Optional, List
from copy import deepcopy

from pydantic import BaseModel, Field, PrivateAttr, ConfigDict, model_validator

from moatless.file_context import FileContext
from moatless.repository import FileRepository
from moatless.types import (
    ActionRequest,
    ActionResponse,
    ActionTransaction,
    FileWithSpans,
    Message, Content, AssistantMessage,
    Usage, UserMessage,
)
from moatless.workspace import Workspace

logger = logging.getLogger(__name__)
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::2
Filepath: moatless\state.py
Content:
class AgenticState(ABC, BaseModel):
    id: int = Field(..., description="The unique identifier of the state")
    previous_state: Optional["AgenticState"] = Field(
        default=None, description="The state that led to this state"
    )
    next_states: List["AgenticState"] = Field(
        default_factory=list, description="The states this state transitioned to"
    )
    model: Optional[str] = Field(
        default=None, description="The model to use for completion"
    )
    temperature: float = Field(0.0, description="The temperature to use for completion")
    max_tokens: int = Field(
        1000, description="The maximum number of tokens to generate"
    )
    include_message_history: bool = Field(
        default=False,
        description="The message history from previous initations should be included in the completion request",
    )
    max_iterations: Optional[int] = Field(
        None, description="The maximum number of transitions to this state."
    )

    _workspace: Optional[Workspace] = PrivateAttr(None)
    _initial_message: Optional[str] = PrivateAttr(None)

    _executed: bool = PrivateAttr(False)
    _actions: List[ActionTransaction] = PrivateAttr(default_factory=list)

    model_config = ConfigDict(
        arbitrary_types_allowed=True,
        exclude={"previous_state", "next_states"}
    )

    def __init__(self, **data):
        super().__init__(**data)
        self._workspace = data.get('_workspace')
        self._initial_message = data.get('_initial_message')

    def handle_action(self, action: ActionRequest, usage: Usage | None) -> ActionResponse:
        if self._executed:
            raise ValueError(f"State has already been executed")

        response = self._execute_action(action)
        self._actions.append(ActionTransaction(request=action, response=response, usage=usage))

        if response.trigger and response.trigger != "retry":
            self._executed = True

        return response

    @abstractmethod
    def _execute_action(self, action: ActionRequest) -> ActionResponse:
        raise NotImplementedError

    @property
    def name(self):
        return self.__class__.__name__

    @property
    def executed(self):
        return self._executed

    @property
    def last_action(self) -> Optional[ActionTransaction]:
        return self._actions[-1] if self._actions else None

    @property
    def response(self) -> Optional[ActionResponse]:
        return self._actions[-1].response if self._actions else None

    @property
    def workspace(self) -> Workspace:
        return self._workspace

    @property
    def file_repo(self) -> FileRepository:
        return self._workspace.file_repo

    @property
    def file_context(self) -> FileContext:
        return self._workspace.file_context

    @property
    def initial_message(self) -> str:
        return self._initial_message

    def create_file_context(
        self, files: list[FileWithSpans] = None, **kwargs
    ) -> FileContext:
        if files is None:
            files = []
        return self.workspace.create_file_context(files, **kwargs)

    def init(self):
        """Initialization logic for the state."""
        pass

    def finish(self, message: str):
        # TODO!!
        logger.info(message)

    def messages(self) -> list[Message]:
        return []

    @classmethod
    def required_fields(cls) -> set[str]:
        return set()
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::3
Filepath: moatless\state.py
Content:
class AgenticState(ABC, BaseModel):

    def get_previous_states(self, state: Optional["AgenticState"] = None) -> list["AgenticState"]:
        """
        Retrieves previous states of the same type as the given state.
        If no state is provided, it returns all previous states.

        Args:
            state (AgenticState | None): The state to filter by. If None, all previous states are returned.

        Returns:
            list: A list of previous states, filtered by type if a state is provided.
        """
        previous_states = []
        current_state = self

        while current_state and current_state.previous_state:
            current_state = current_state.previous_state
            if not state or isinstance(current_state, type(state)):
                previous_states.insert(0, current_state)

        logger.debug(
            f"Found {len(previous_states)} previous states of type {state.__class__.__name__ if state else 'all types'}"
        )

        return previous_states
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::4
Filepath: moatless\state.py
Content:
class AgenticState(ABC, BaseModel):

    def retries(self) -> int:
        retries = 0
        for action in reversed(self._actions):
            if action.response.trigger == "retry":
                retries += 1
            else:
                return retries

        return retries

    def retry_messages(self) -> list[Message]:
        messages: list[Message] = []

        for action in self._actions:
            if isinstance(action.request, Content):
                messages.append(
                    AssistantMessage(
                        content=action.request.content,
                    )
                )
            else:
                messages.append(AssistantMessage(action=action.request))

            if action.response.retry_message:
                messages.append(
                    UserMessage(
                        content=action.response.retry_message,
                    )
                )

        return messages

    def system_prompt(self) -> str:
        return ""

    def action_type(self) -> type[ActionRequest] | None:
        """
        The type of the action to expect in the completion response.
        If not set a content string is expected.
        """
        raise NotImplementedError

    def stop_words(self) -> list[str] | None:
        return None

    def model_dump(self, **kwargs):
        if 'exclude' not in kwargs:
            kwargs['exclude'] = {"previous_state", "next_states"}

        data = super().model_dump(**kwargs)
        return data

    @classmethod
    @model_validator(mode="before")
    def validate_previous_state(cls, values):
        if isinstance(obj, dict) and "previous_state_id" in obj:
            obj = obj.copy()
            obj["previous_state"] = None
        return super().model_validate(obj)

    def clone(self) -> "AgenticState":
        new_state = self.__class__(**self.model_dump())
        if hasattr(self, '_workspace'):
            new_state._workspace = self._workspace
        return new_state

    def total_cost(self):
        total_cost = 0
        for action in self._actions:
            if action.usage:
                total_cost += action.usage.completion_cost

        return total_cost

    def __eq__(self, other):
        if not isinstance(other, AgenticState):
            return NotImplemented
        if self.model_dump() != other.model_dump():
            return False
        return True
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::5
Filepath: moatless\state.py
Content:
class NoopState(AgenticState):

    def _execute_action(self, action: ActionRequest):
        raise ValueError("NoopState cannot handle actions")


class Finished(NoopState):
    message: Optional[str] = None
    output: dict[str, Any] | None = None


class Rejected(NoopState):
    message: Optional[str] = None


class Pending(NoopState):
    def __init__(self, **data):
        if 'id' not in data:
            data['id'] = 0
        super().__init__(**data)
--------------------------------------------------------------------------------
Chunk ID: moatless/state.py::6
Filepath: moatless\state.py
Content:
def get_state_class(name: str) -> type[AgenticState]:
    builtin_states = {
        "NoopState": NoopState,
        "Finished": Finished,
        "Rejected": Rejected,
        "Pending": Pending,
    }
    if name in builtin_states:
        return builtin_states[name]

    # If not a built-in state, try to import dynamically
    possible_modules = [
        "moatless.edit",
        "moatless.find",
    ]

    for module_name in possible_modules:

        try:
            module = importlib.import_module(module_name)
            if hasattr(module, name):
                cls = getattr(module, name)
                if isinstance(cls, type) and issubclass(cls, AgenticState):
                    return cls
        except ImportError:
            logger.debug(f"Could not import module {module_name}")

    # If still not found, try sys.modules as a fallback
    for module in sys.modules.values():
        if hasattr(module, name):
            cls = getattr(module, name)
            if isinstance(cls, type) and issubclass(cls, AgenticState):
                return cls

    raise ValueError(f"State {name} not found")
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::1
Filepath: moatless\trajectory.py
Content:
import json
import logging
from datetime import datetime
from typing import Any, Optional, List

from pydantic import BaseModel, Field
from pydantic_core import to_jsonable_python

from moatless.workspace import Workspace
from moatless.transition_rules import TransitionRules
from moatless.state import AgenticState, get_state_class
from moatless.types import ActionRequest, ActionTransaction, ActionResponse, Usage, Content

logger = logging.getLogger(__name__)



class TrajectoryState(BaseModel):
    id: int
    timestamp: datetime = Field(default_factory=datetime.now)
    snapshot: Optional[dict] = None
    state: AgenticState

    @property
    def name(self):
        return self.state.name if self.state else None

    def model_dump(self, **kwargs):
        data = {
            "id": self.id,
            "name": self.state.name,
            "timestamp": self.timestamp,
        }

        if self.snapshot:
            data["snapshot"] = self.snapshot

        if self.state.previous_state:
            data["previous_state_id"] = self.state.previous_state.id

        properties = self.state.model_dump(exclude={"previous_state", "next_states", "id"}, **kwargs) if self.state else None
        if properties:
            data["properties"] = properties

        if self.state._actions:
            data["actions"] = [a.model_dump(**kwargs) for a in self.state._actions]

        return data
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::2
Filepath: moatless\trajectory.py
Content:
class Trajectory:
    def __init__(
        self,
        name: str,
        workspace: Workspace,
        initial_message: Optional[str] = None,
        persist_path: Optional[str] = None,
        transition_rules: Optional[TransitionRules] = None,
    ):
        self._name = name
        self._persist_path = persist_path
        self._initial_message = initial_message
        self._workspace = workspace

        # Workaround to set to keep the current initial workspace state when loading an existing trajectory.
        # TODO: Remove this when we have a better way to handle this.
        self._initial_workspace_state = self._workspace.dict()

        self._transition_rules = transition_rules

        self._current_transition_id = 0
        self._transitions: dict[int, TrajectoryState] = {}

        self._info: dict[str, Any] = {}
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::3
Filepath: moatless\trajectory.py
Content:
class Trajectory:

    @classmethod
    def load(cls, file_path: str):
        with open(file_path, "r") as f:
            data = json.load(f)

        if "transition_rules" in data:
            transition_rules = TransitionRules.model_validate(data["transition_rules"])
        else:
            transition_rules = None

        workspace = Workspace.from_dict(data["workspace"])
        trajectory = cls(
            name=data["name"],
            initial_message=data["initial_message"],
            transition_rules=transition_rules,
            workspace=workspace
        )

        trajectory._info = data.get("info", {})

        trajectory._transitions = {}
        trajectory._current_transition_id = data.get("current_transition_id", 0)

        for t in data["transitions"]:
            state_class = get_state_class(t["name"])
            state_data = t["properties"]
            state_data["id"] = t["id"]
            state = state_class.model_validate(state_data)

            state._workspace = trajectory._workspace
            state._initial_message = trajectory._initial_message
            state._actions = []
            if "actions" in t:
                for a in t["actions"]:
                    try:
                        if state.action_type() is None:
                            request = Content.model_validate(a["request"])
                        else:
                            request = state.action_type().model_validate(a["request"])
                        response = ActionResponse.model_validate(a.get("response"))
                        if a.get("usage"):
                            usage = Usage.model_validate(a.get("usage"))
                        else:
                            usage = None
                        state._actions.append(ActionTransaction(request=request, response=response, usage=usage))
                    except Exception as e:
                        logger.exception(f"Error loading action for state {state.name}: {a}")
                        raise e

            trajectory_state = TrajectoryState(
                id=t["id"],
                timestamp=datetime.fromisoformat(t["timestamp"]),
                snapshot=t.get("snapshot"),
                state=state
            )

            trajectory._transitions[t["id"]] = trajectory_state

        # Set previous_state and next_states
        for t in data["transitions"]:
            try:
                current_state = trajectory._transitions[t["id"]].state
                if t.get("previous_state_id") is not None:
                    current_state.previous_state = trajectory._transitions.get(t["previous_state_id"]).state
            except KeyError as e:
                logger.exception(f"Missing key {e}, existing keys: {trajectory._transitions.keys()}")
                raise

        trajectory._info = data.get("info", {})

        logger.info(f"Loaded trajectory {trajectory._name} with {len(trajectory._transitions)} transitions")

        return trajectory
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::4
Filepath: moatless\trajectory.py
Content:
class Trajectory:

    @property
    def initial_message(self):
        return self._initial_message

    @property
    def info(self):
        return self._info

    @property
    def states(self) -> List[dict]:
        return [t.state.model_dump() for t in self.transitions]

    @property
    def transition_rules(self) -> TransitionRules:
        return self._transition_rules

    @property
    def workspace(self) -> Workspace:
        return self._workspace

    @property
    def transitions(self) -> List[TrajectoryState]:
        return sorted(self._transitions.values(), key=lambda x: x.id)

    def set_current_state(self, state: AgenticState):
        self._current_transition_id = state.id
        self._maybe_persist()

    def get_current_state(self) -> AgenticState:
        return self._transitions.get(self._current_transition_id).state

    def update_workspace_to_current_state(self):
        self.restore_from_snapshot(self._transitions[self._current_transition_id])
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::5
Filepath: moatless\trajectory.py
Content:
class Trajectory:

    def restore_from_snapshot(self, state: TrajectoryState):
        if not state.snapshot:
            logger.info(f"restore_from_snapshot(state: {state.id}:{state.name}) No snapshot found")
            return

        logger.info(f"restore_from_snapshot(starte: {state.id}:{state.name}) Restoring from snapshot")

        if state.snapshot.get("repository"):
            self._workspace.file_repo.restore_from_snapshot(state.snapshot["repository"])

        if state.snapshot.get("file_context"):
            self._workspace.file_context.restore_from_snapshot(state.snapshot["file_context"])
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::6
Filepath: moatless\trajectory.py
Content:
class Trajectory:

    def save_state(self, state: AgenticState):
        if state.id in self._transitions:
            self._transitions[state.id].state = state
        else:
            transition = TrajectoryState(
                id=state.id,
                state=state,
                snapshot=state.workspace.snapshot() if state.workspace else None,
            )
            self._transitions[state.id] = transition

        self._maybe_persist()

    def get_state(self, state_id: int) -> TrajectoryState | None:
        return self._transitions.get(state_id)

    def save_info(self, info: dict):
        self._info = info
        self._maybe_persist()

    def get_mocked_actions(self) -> List[dict]:
        """
        Return a list of actions that can be used to mock the trajectory.
        """
        actions = []

        for transition in self.transitions:
            for action in transition.state._actions:
                actions.append(action.request.model_dump())
        return actions

    def get_expected_states(self) -> List[str]:
        """
        Return a list of expected states in the trajectory to use for verification when rerunning the trajectory.
        """
        return [transition.state.name for transition in self.transitions[1:]]
--------------------------------------------------------------------------------
Chunk ID: moatless/trajectory.py::7
Filepath: moatless\trajectory.py
Content:
class Trajectory:

    def to_dict(self):
        return {
            "name": self._name,
            "transition_rules": self._transition_rules.model_dump(
                exclude_none=True
            )
            if self._transition_rules
            else None,
            "workspace": self._initial_workspace_state,
            "initial_message": self._initial_message,
            "current_transition_id": self._current_transition_id,
            "transitions": [t.model_dump(exclude_none=True) for t in self.transitions],
            "info": self._info,
        }

    def _maybe_persist(self):
        if self._persist_path:
            self.persist(self._persist_path)

    def persist(self, file_path: str):
        with open(f"{file_path}", "w") as f:
            f.write(
                json.dumps(
                    self.to_dict(),
                    indent=2,
                    default=to_jsonable_python,
                )
            )
--------------------------------------------------------------------------------
Chunk ID: moatless/transition_rules.py::1
Filepath: moatless\transition_rules.py
Content:
import logging

from pydantic import BaseModel, Field, PrivateAttr, model_validator
from typing import Any, Type, Optional

from moatless.settings import Settings
from moatless.state import AgenticState, get_state_class
from moatless.workspace import Workspace


logger = logging.getLogger(__name__)


class TransitionRule(BaseModel):
    trigger: str = Field(
        ...,
        description="The trigger from the current state that causes the transition to fire.",
    )
    source: type[AgenticState] = Field(
        ..., description="The source state that the transition rule is defined for."
    )
    dest: type[AgenticState] = Field(
        ...,
        description="The destination state that the transition rule is defined for.",
    )
    required_fields: Optional[set[str]] = Field(
        default=None,
        description="The fields that are required for the transition to fire.",
    )
    excluded_fields: Optional[set[str]] = Field(
        default=None, description="The fields that are excluded from the transition."
    )

    def get(self, key: str, default: Any = None) -> Any:
        return getattr(self, key, default)

    def model_dump(self, **kwargs):
        data = super().model_dump(**kwargs)
        data["source"] = self.source.__name__
        data["dest"] = self.dest.__name__

        if data.get("required_fields"):
            data["required_fields"] = list(data.get("required_fields"))

        if data.get("excluded_fields"):
            data["excluded_fields"] = list(data.get("excluded_fields"))

        return data

    @model_validator(mode="before")
    @classmethod
    def validate_state_classes(cls, data: Any) -> Any:
        if isinstance(data, dict):
            if isinstance(data.get("source"), str):
                data["source"] = get_state_class(data["source"])
            if isinstance(data.get("dest"), str):
                data["dest"] = get_state_class(data["dest"])

        if data["source"] == data["dest"]:
            raise ValueError("Source and destination states cannot be the same.")

        return data
--------------------------------------------------------------------------------
Chunk ID: moatless/transition_rules.py::2
Filepath: moatless\transition_rules.py
Content:
class TransitionRules(BaseModel):
    initial_state: type[AgenticState] | None = Field(
        default=None, 
        description="The initial state for the loop.",
        deprecated="Initial state should be set in transition_rules instead."
    )
    transition_rules: list[TransitionRule] = Field(
        ..., description="The transition rules for the loop."
    )
    global_params: dict[str, Any] = Field(
        default_factory=dict, description="Global parameters used by all transitions."
    )
    state_params: dict[type[AgenticState], dict[str, Any]] = Field(
        default_factory=dict, description="State-specific parameters."
    )

    _source_trigger_index: dict[
        tuple[type[AgenticState], str], list[TransitionRule]
    ] = PrivateAttr(default_factory=dict)

    def __init__(self, **data):
        super().__init__(**data)
        self._build_source_trigger_index()

    def model_dump(self, **kwargs):
        data = {
            "global_params": self.global_params,
            "state_params": {k.__name__: v for k, v in self.state_params.items()},
            "transition_rules": [
                rule.model_dump(**kwargs) for rule in self.transition_rules
            ],
        }

        if self.initial_state:
            data["initial_state"] = self.initial_state.__name__

        return data
--------------------------------------------------------------------------------
Chunk ID: moatless/transition_rules.py::3
Filepath: moatless\transition_rules.py
Content:
class TransitionRules(BaseModel):

    @model_validator(mode="before")
    @classmethod
    def validate_before_init(cls, data: Any) -> Any:
        if isinstance(data, dict):
            if isinstance(data.get("initial_state"), str):
                data["initial_state"] = get_state_class(data["initial_state"])

            if "state_params" in data:
                data["state_params"] = {
                    get_state_class(k) if isinstance(k, str) else k: v
                    for k, v in data["state_params"].items()
                }

        if "global_params" not in data:
            data["global_params"] = {}

        if "model" not in data["global_params"]:
            logger.info(f"No model specified in global_params. Using default model: {Settings.default_model}")
            data["global_params"]["model"] = Settings.default_model

        return data
--------------------------------------------------------------------------------
Chunk ID: moatless/transition_rules.py::4
Filepath: moatless\transition_rules.py
Content:
class TransitionRules(BaseModel):

    def _build_source_trigger_index(self):
        for rule in self.transition_rules:
            key = (rule.source, rule.trigger)
            if key not in self._source_trigger_index:
                self._source_trigger_index[key] = []
            self._source_trigger_index[key].append(rule)

    def find_transition_rule_by_source_and_trigger(
        self, source: type[AgenticState], trigger: str
    ) -> list[TransitionRule]:
        return self._source_trigger_index.get((source, trigger), [])

    def params(self, rule: TransitionRule) -> dict[str, Any]:
        params = {}
        params.update(self.global_params)
        params.update(self.state_params.get(rule.dest, {}))
        return params
--------------------------------------------------------------------------------
Chunk ID: moatless/transition_rules.py::5
Filepath: moatless\transition_rules.py
Content:
class TransitionRules(BaseModel):

    def get_next_rule(
        self, source: AgenticState, trigger: str, data: dict[str, Any]
    ) -> TransitionRule | None:

        if trigger == "init" and self.initial_state:
            logger.warning("Using deprecated 'initial_state'. Set initial state in transition_rules instead.")
            return TransitionRule(
                trigger="init",
                source=source.__class__,
                dest=self.initial_state,
            )

        transition_rules = self.find_transition_rule_by_source_and_trigger(
            source.__class__, trigger
        )
        for transition_rule in transition_rules:
            if (
                transition_rule.required_fields
                and not transition_rule.required_fields.issubset(data.keys())
            ):
                logger.info(f"Missing required fields for transition {transition_rule}")
                continue

            return transition_rule

        return None
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::1
Filepath: moatless\transitions.py
Content:
import logging
from typing import Optional

from moatless.edit.clarify import ClarifyCodeChange
from moatless.edit.edit import EditCode
from moatless.edit.plan import PlanToCode
from moatless.edit.plan_lines import PlanToCodeWithLines
from moatless.find.decide import DecideRelevance
from moatless.find.identify import IdentifyCode
from moatless.find.search import SearchCode
from moatless.transition_rules import TransitionRule, TransitionRules
from moatless.state import Finished, Rejected, Pending

CODE_TRANSITIONS = [
    TransitionRule(
        source=PlanToCode,
        dest=EditCode,
        trigger="edit_code",
        required_fields=EditCode.required_fields(),
    ),
    TransitionRule(
        source=PlanToCode,
        dest=ClarifyCodeChange,
        trigger="edit_code",
        required_fields=ClarifyCodeChange.required_fields(),
    ),
    TransitionRule(source=PlanToCode, dest=Finished, trigger="finish"),
    TransitionRule(source=PlanToCode, dest=Rejected, trigger="reject"),
    TransitionRule(
        source=ClarifyCodeChange,
        dest=EditCode,
        trigger="edit_code",
        required_fields=EditCode.required_fields(),
    ),
    TransitionRule(source=ClarifyCodeChange, dest=PlanToCode, trigger="reject"),
    TransitionRule(source=EditCode, dest=PlanToCode, trigger="finish"),
    TransitionRule(source=EditCode, dest=PlanToCode, trigger="reject"),
]


logger = logging.getLogger(__name__)
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::2
Filepath: moatless\transitions.py
Content:
def code_transitions(
    global_params: Optional[dict] = None,
    state_params: Optional[dict] = None,
    max_prompt_file_tokens: Optional[int] = 16000,
    max_tokens_in_edit_prompt: Optional[int] = 500,
) -> TransitionRules:
    state_params = state_params or {}
    state_params.setdefault(
        PlanToCode,
        {
            "max_prompt_file_tokens": max_prompt_file_tokens,
            "max_tokens_in_edit_prompt": max_tokens_in_edit_prompt,
        },
    )

    return TransitionRules(
        global_params=global_params or {},
        state_params=state_params,
        initial_state=PlanToCode,
        transition_rules=CODE_TRANSITIONS,
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::3
Filepath: moatless\transitions.py
Content:
def code_transitions_use_line_numbers(
    global_params: Optional[dict] = None, state_params: Optional[dict] = None
) -> TransitionRules:
    return TransitionRules(
        global_params=global_params or {},
        state_params=state_params or {},
        initial_state=PlanToCodeWithLines,
        transition_rules=[
            TransitionRule(
                source=PlanToCodeWithLines,
                dest=EditCode,
                trigger="edit_code",
                required_fields=PlanToCodeWithLines.required_fields(),
            ),
            TransitionRule(source=PlanToCodeWithLines, dest=Finished, trigger="finish"),
            TransitionRule(source=PlanToCodeWithLines, dest=Rejected, trigger="reject"),
            TransitionRule(source=EditCode, dest=PlanToCodeWithLines, trigger="finish"),
            TransitionRule(source=EditCode, dest=PlanToCodeWithLines, trigger="reject"),
        ],
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::4
Filepath: moatless\transitions.py
Content:
def edit_code_transitions(
    global_params: Optional[dict] = None, state_params: Optional[dict] = None
) -> TransitionRules:
    return TransitionRules(
        global_params=global_params or {},
        state_params=state_params or {},
        initial_state=EditCode,
        transition_rules=[
            TransitionRule(source=EditCode, dest=Finished, trigger="finish"),
            TransitionRule(source=EditCode, dest=Rejected, trigger="reject"),
        ],
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::5
Filepath: moatless\transitions.py
Content:
def search_transitions(
    model: Optional[str] = None,
    max_prompt_file_tokens: Optional[int] = None,
    max_search_results: Optional[int] = None,
    max_maybe_finish_iterations: int = 5,
    global_params: Optional[dict] = None,
    state_params: Optional[dict] = None,
) -> TransitionRules:
    global_params = global_params or {}

    if model is not None:
        global_params["model"] = model

    if state_params is None:
        state_params = {}

    if max_search_results is not None:
        state_params.setdefault(SearchCode, {"max_search_results": max_search_results})

    if max_prompt_file_tokens is not None:
        state_params.setdefault(
            IdentifyCode, {"max_prompt_file_tokens": max_prompt_file_tokens}
        )

    state_params.setdefault(
        DecideRelevance, {"max_iterations": max_maybe_finish_iterations}
    )

    logger.info(state_params)

    return TransitionRules(
        global_params=global_params,
        state_params=state_params,
        initial_state=SearchCode,
        transition_rules=[
            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger="did_search"),
            TransitionRule(source=SearchCode, dest=Finished, trigger="finish"),
            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger="search"),
            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger="finish"),
            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger="search"),
            TransitionRule(source=DecideRelevance, dest=Finished, trigger="finish"),
        ],
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::6
Filepath: moatless\transitions.py
Content:
def identify_directly_transition(
    model: Optional[str] = None,
    max_prompt_file_tokens: Optional[int] = 30000,
    max_search_results: Optional[int] = 100,
    global_params: Optional[dict] = None,
    state_params: Optional[dict] = None,
) -> TransitionRules:
    global_params = global_params or {}

    if model is not None:
        global_params["model"] = model

    if state_params is None:
        state_params = {}

    if max_search_results is not None:
        state_params.setdefault(SearchCode, {"max_search_results": max_search_results})

    if max_prompt_file_tokens is not None:
        state_params.setdefault(
            IdentifyCode, {"max_prompt_file_tokens": max_prompt_file_tokens}
        )

    logger.info(state_params)

    return TransitionRules(
        global_params=global_params,
        state_params=state_params,
        initial_state=IdentifyCode,
        transition_rules=[
            TransitionRule(source=IdentifyCode, dest=Finished, trigger="search"),
            TransitionRule(source=IdentifyCode, dest=Finished, trigger="finish"),
        ],
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::7
Filepath: moatless\transitions.py
Content:
def search_and_code_transitions(
    max_tokens_in_edit_prompt: Optional[int] = 500,
    global_params: Optional[dict] = None,
    state_params: Optional[dict] = None,
) -> TransitionRules:
    state_params = state_params or {}
    if max_tokens_in_edit_prompt is not None:
        state_params.setdefault(
            PlanToCode, {"max_tokens_in_edit_prompt": max_tokens_in_edit_prompt}
        )
    return TransitionRules(
        global_params=global_params,
        state_params=state_params,
        transition_rules=[
            TransitionRule(source=Pending, dest=SearchCode, trigger="init"),
            TransitionRule(source=SearchCode, dest=IdentifyCode, trigger="did_search"),
            TransitionRule(source=SearchCode, dest=PlanToCode, trigger="finish"),
            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger="search"),
            TransitionRule(source=IdentifyCode, dest=DecideRelevance, trigger="finish"),
            TransitionRule(source=DecideRelevance, dest=SearchCode, trigger="search"),
            TransitionRule(
                source=DecideRelevance,
                dest=PlanToCode,
                trigger="finish",
                exclude_fields={"message"},
            ),
        ]
        + CODE_TRANSITIONS,
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/transitions.py::8
Filepath: moatless\transitions.py
Content:
def identify_and_code_transitions(
    model: Optional[str] = None,
    max_prompt_file_tokens: Optional[int] = 16000,
    max_tokens_in_edit_prompt: Optional[int] = 500,
    max_search_results: Optional[int] = 100,
    global_params: Optional[dict] = None,
    state_params: Optional[dict] = None,
) -> TransitionRules:
    global_params = global_params or {}

    if model is not None:
        global_params["model"] = model

    if state_params is None:
        state_params = {}

    if max_search_results is not None:
        state_params.setdefault(SearchCode, {"max_search_results": max_search_results})

    if max_prompt_file_tokens is not None:
        state_params.setdefault(
            IdentifyCode, {"max_prompt_file_tokens": max_prompt_file_tokens}
        )

    if max_tokens_in_edit_prompt is not None:
        state_params.setdefault(
            PlanToCode,
            {
                "max_prompt_file_tokens": max_prompt_file_tokens,
                "max_tokens_in_edit_prompt": max_tokens_in_edit_prompt,
            },
        )

    return TransitionRules(
        global_params=global_params,
        state_params=state_params or {},
        initial_state=IdentifyCode,
        transition_rules=[
            TransitionRule(source=IdentifyCode, dest=SearchCode, trigger="search"),
            TransitionRule(source=IdentifyCode, dest=PlanToCode, trigger="finish"),
        ]
        + CODE_TRANSITIONS,
    )
--------------------------------------------------------------------------------
Chunk ID: moatless/types.py::1
Filepath: moatless\types.py
Content:
from typing import Any, Optional

from pydantic import BaseModel, Field


class FileWithSpans(BaseModel):
    file_path: str = Field(
        description="The file path where the relevant code is found."
    )
    span_ids: list[str] = Field(
        default_factory=list,
        description="The span ids of the relevant code in the file",
    )

    def add_span_id(self, span_id):
        if span_id not in self.span_ids:
            self.span_ids.append(span_id)

    def add_span_ids(self, span_ids: list[str]):
        for span_id in span_ids:
            self.add_span_id(span_id)

class ActionRequest(BaseModel):
    pass

    @property
    def action_name(self):
        return self.__class__.__name__
--------------------------------------------------------------------------------
Chunk ID: moatless/types.py::2
Filepath: moatless\types.py
Content:
class ActionResponse(BaseModel):
    trigger: Optional[str] = Field(
        default=None,
        description="Trigger to transition to the next state. If None, no transition is made.",
    )
    output: Optional[dict[str, Any]] = Field(
        default=None,
        description="Output data to be passed to the next state.",
    )

    retry_message: Optional[str] = Field(
        default=None,
        description="Message to use in retry."
    )

    @classmethod
    def retry(cls, retry_message: str):
        return cls(trigger="retry", retry_message=retry_message)

    @classmethod
    def transition(cls, trigger: str, output: dict[str, Any] | None = None):
        output = output or {}
        return cls(trigger=trigger, output=output)

    @classmethod
    def no_transition(cls, output: dict[str, Any]):
        return cls(output=output)
--------------------------------------------------------------------------------
Chunk ID: moatless/types.py::3
Filepath: moatless\types.py
Content:
class Usage(BaseModel):
    completion_cost: float
    completion_tokens: int
    prompt_tokens: int


class ActionTransaction(BaseModel):
    request: ActionRequest
    response: Optional[ActionResponse] = None
    usage: Optional[Usage] = None

    def model_dump(self, **kwargs):
        data = super().model_dump(**kwargs)
        data["request"] = self.request.model_dump(**kwargs)
        data["response"] = self.response.model_dump(**kwargs) if self.response else None
        return data


class EmptyRequest(ActionRequest):
    pass


class Finish(ActionRequest):
    thoughts: str = Field(..., description="The reason to finishing the request.")


class Reject(ActionRequest):
    thoughts: str = Field(..., description="The reason for rejecting the request.")


class Content(ActionRequest):
    content: str


class Message(BaseModel):
    role: str
    content: Optional[str] = None
    action: Optional[ActionRequest] = Field(default=None)


class AssistantMessage(Message):
    role: str = "assistant"
    content: Optional[str] = None
    action: Optional[ActionRequest] = Field(default=None)


class UserMessage(Message):
    role: str = "user"
    content: Optional[str] = None


class Response(BaseModel):
    status: str
    message: str
    output: Optional[dict[str, Any]] = None


class VerificationError(BaseModel):
    code: str
    file_path: str
    message: str
    line: int


class CodeChange(BaseModel):
    instructions: str = Field(..., description="Instructions to do the code change.")
    file_path: str = Field(..., description="The file path of the code to be updated.")
    span_id: str = Field(..., description="The span id of the code to be updated.")
--------------------------------------------------------------------------------
Chunk ID: utils/colors.py::1
Filepath: moatless\utils\colors.py
Content:
class Colors:
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    MAGENTA = "\033[95m"
    CYAN = "\033[96m"
    WHITE = "\033[97m"
    GRAY = "\033[90m"
    RESET = "\033[0m"
--------------------------------------------------------------------------------
Chunk ID: utils/llm_utils.py::1
Filepath: moatless\utils\llm_utils.py
Content:
import instructor


def instructor_mode_by_model(model: str) -> instructor.Mode | None:
    if "gpt" in model:
        return instructor.Mode.TOOLS

    if "claude" in model:
        return instructor.Mode.TOOLS

    if model.startswith("claude"):
        return instructor.Mode.ANTHROPIC_TOOLS

    if model.startswith("openrouter/anthropic/claude"):
        return instructor.Mode.TOOLS

    return instructor.Mode.JSON
--------------------------------------------------------------------------------
Chunk ID: utils/repo.py::1
Filepath: moatless\utils\repo.py
Content:
import logging
import os
import subprocess

logger = logging.getLogger(__name__)


def setup_github_repo(repo: str, base_commit: str, base_dir: str = "/tmp/repos") -> str:
    repo_name = get_repo_dir_name(repo)
    repo_url = f"https://github.com/{repo}.git"
    path = f"{base_dir}/{repo_name}"
    logger.info(
        f"Clone Github repo {repo_url} to {path} and checkout commit {base_commit}"
    )
    if not os.path.exists(path):
        os.makedirs(path)
        logger.info(f"Directory '{path}' was created.")
    maybe_clone(repo_url, path)
    checkout_commit(path, base_commit)
    return path


def get_repo_dir_name(repo: str):
    return repo.replace("/", "_")
--------------------------------------------------------------------------------
Chunk ID: utils/repo.py::2
Filepath: moatless\utils\repo.py
Content:
def maybe_clone(repo_url, repo_dir):
    if not os.path.exists(f"{repo_dir}/.git"):
        logger.info(f"Cloning repo '{repo_url}'")
        # Clone the repo if the directory doesn't exist
        result = subprocess.run(
            ["git", "clone", repo_url, repo_dir],
            check=True,
            text=True,
            capture_output=True,
        )

        if result.returncode == 0:
            logger.info(f"Repo '{repo_url}' was cloned to '{repo_dir}'")
        else:
            logger.info(f"Failed to clone repo '{repo_url}' to '{repo_dir}'")
            raise ValueError(f"Failed to clone repo '{repo_url}' to '{repo_dir}'")
--------------------------------------------------------------------------------
Chunk ID: utils/repo.py::3
Filepath: moatless\utils\repo.py
Content:
def pull_latest(repo_dir):
    subprocess.run(
        ["git", "pull"],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )


def clean_and_reset_state(repo_dir):
    subprocess.run(
        ["git", "clean", "-fd"],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )
    subprocess.run(
        ["git", "reset", "--hard"],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )


def create_branch(repo_dir, branch_name):
    try:
        subprocess.run(
            ["git", "branch", branch_name],
            cwd=repo_dir,
            check=True,
            text=True,
            capture_output=True,
        )
    except subprocess.CalledProcessError as e:
        logger.error(e.stderr)
        raise e
--------------------------------------------------------------------------------
Chunk ID: utils/repo.py::4
Filepath: moatless\utils\repo.py
Content:
def create_and_checkout_branch(repo_dir, branch_name):
    try:
        branches = subprocess.run(
            ["git", "branch"],
            cwd=repo_dir,
            check=True,
            text=True,
            capture_output=True,
        ).stdout.split("\n")
        branches = [branch.strip() for branch in branches]
        if branch_name in branches:
            subprocess.run(
                ["git", "checkout", branch_name],
                cwd=repo_dir,
                check=True,
                text=True,
                capture_output=True,
            )
        else:
            subprocess.run(
                ["git", "checkout", "-b", branch_name],
                cwd=repo_dir,
                check=True,
                text=True,
                capture_output=True,
            )
    except subprocess.CalledProcessError as e:
        logger.error(e.stderr)
        raise e
--------------------------------------------------------------------------------
Chunk ID: utils/repo.py::5
Filepath: moatless\utils\repo.py
Content:
def commit_changes(repo_dir, commit_message):
    subprocess.run(
        ["git", "commit", "-m", commit_message, "--no-verify"],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )


def checkout_branch(repo_dir, branch_name):
    subprocess.run(
        ["git", "checkout", branch_name],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )


def push_branch(repo_dir, branch_name):
    subprocess.run(
        ["git", "push", "origin", branch_name, "--no-verify"],
        cwd=repo_dir,
        check=True,
        text=True,
        capture_output=True,
    )


def get_diff(repo_dir):
    output = subprocess.run(
        ["git", "diff"], cwd=repo_dir, check=True, text=True, capture_output=True
    )

    return output.stdout


def stage_all_files(repo_dir):
    subprocess.run(
        ["git", "add", "."], cwd=repo_dir, check=True, text=True, capture_output=True
    )


def checkout_commit(repo_dir, commit_hash):
    try:
        subprocess.run(
            ["git", "reset", "--hard", commit_hash],
            cwd=repo_dir,
            check=True,
            text=True,
            capture_output=True,
        )
    except subprocess.CalledProcessError as e:
        logger.error(e.stderr)
        raise e


def create_and_checkout_new_branch(repo_dir: str, branch_name: str):
    try:
        subprocess.run(
            ["git", "checkout", "-b", branch_name],
            cwd=repo_dir,
            check=True,
            text=True,
            capture_output=True,
        )
    except subprocess.CalledProcessError as e:
        logger.error(e.stderr)
        raise e


def setup_repo(repo_url, repo_dir, branch_name="master"):
    maybe_clone(repo_url, repo_dir)
    clean_and_reset_state(repo_dir)
    checkout_branch(repo_dir, branch_name)
    pull_latest(repo_dir)


def clean_and_reset_repo(repo_dir, branch_name="master"):
    clean_and_reset_state(repo_dir)
    checkout_branch(repo_dir, branch_name)
    pull_latest(repo_dir)
--------------------------------------------------------------------------------
Chunk ID: utils/tokenizer.py::1
Filepath: moatless\utils\tokenizer.py
Content:
import os

_enc = None

_voyageai = None


def count_tokens(content: str, model: str = "gpt-3.5-turbo") -> int:
    global _enc, _voyageai

    if model.startswith("voyage"):
        if _voyageai is None:
            voyageai_import_err = (
                "`voyageai` package not found, please run `pip install voyageai`"
            )
            try:
                import voyageai
            except ImportError as e:
                raise ImportError(voyageai_import_err) from e

            _voyageai = voyageai.Client()

        return _voyageai.count_tokens([content])

    if _enc is None:
        tiktoken_import_err = (
            "`tiktoken` package not found, please run `pip install tiktoken`"
        )
        try:
            import tiktoken
        except ImportError as e:
            raise ImportError(tiktoken_import_err) from e

        # set tokenizer cache temporarily
        should_revert = False
        if "TIKTOKEN_CACHE_DIR" not in os.environ:
            should_revert = True
            os.environ["TIKTOKEN_CACHE_DIR"] = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "_static/tiktoken_cache",
            )

        _enc = tiktoken.encoding_for_model(model)

        if should_revert:
            del os.environ["TIKTOKEN_CACHE_DIR"]

    return len(_enc.encode(content, allowed_special="all"))
--------------------------------------------------------------------------------
Chunk ID: utils/xml.py::1
Filepath: moatless\utils\xml.py
Content:
import re


def extract_between_tags(tag: str, string: str, strip: bool = False) -> list[str]:
    ext_list = re.findall(f"<{tag}>(.+?)</{tag}>", string, re.DOTALL)
    if strip:
        ext_list = [e.strip() for e in ext_list]
    return ext_list


def contains_tag(tag: str, string: str) -> bool:
    return bool(re.search(f"<{tag}>", string, re.DOTALL))


# def contains_tag(tag: str, string: str) -> bool:
#    return bool(re.search(f"<{tag}>(.+?)</{tag}>", string, re.DOTALL))

--------------------------------------------------------------------------------
Chunk ID: verify/lint.py::1
Filepath: moatless\verify\lint.py
Content:
import logging

from astroid import MANAGER
from pylint.lint import Run
from pylint.testutils import MinimalTestReporter

from moatless.repository import CodeFile
from moatless.types import VerificationError
from moatless.verify.verify import Verifier

logger = logging.getLogger(__name__)


class PylintVerifier(Verifier):
    def __init__(self, repo_dir: str, run_tests: bool = True):
        self.repo_dir = repo_dir
        self.run_tests = run_tests

    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:
        if not file:
            logger.warning("No file to verify")
            return []

        try:
            MANAGER.astroid_cache.clear()
            results = Run(
                [f"{self.repo_dir}/{file.file_path}"],
                exit=False,
                reporter=MinimalTestReporter(),
            )

            for msg in results.linter.reporter.messages:
                logger.debug(f"Message: {msg.msg_id} {msg.msg} {msg.line}")

            return [
                VerificationError(
                    code=msg.msg_id,
                    file_path=msg.path.replace(f"{self.repo_dir}/", ""),
                    message=msg.msg,
                    line=msg.line,
                )
                for msg in results.linter.reporter.messages
                if msg.msg_id[0] in ["E", "F"]
            ]
        except Exception:
            logger.exception("Error running pylint")
            return []
--------------------------------------------------------------------------------
Chunk ID: verify/maven.py::1
Filepath: moatless\verify\maven.py
Content:
import logging
import os
import re
import subprocess

from moatless.repository import CodeFile
from moatless.types import VerificationError
from moatless.verify.verify import Verifier

logger = logging.getLogger(__name__)


class MavenVerifier(Verifier):
    def __init__(self, repo_dir: str, run_tests: bool = True):
        self.repo_dir = repo_dir
        self.run_tests = run_tests

    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:
        try:
            # os.environ["JAVA_HOME"] = "/home/albert/.sdkman/candidates/java/17.0.8-tem"

            version = "21-tem"

            sdkman_cmd = (
                f"source $HOME/.sdkman/bin/sdkman-init.sh && sdk use java {version}"
            )

            if self.run_tests:
                mvn_cmd = "./mvnw clean test"
            else:
                mvn_cmd = "./mvnw clean compile test-compile"

            logger.info(
                f"Running Maven command: {mvn_cmd} with Java version {version} in {self.repo_dir}"
            )
            result = subprocess.run(
                f"{sdkman_cmd} && {mvn_cmd}",
                cwd=self.repo_dir,
                check=False,
                text=True,
                shell=True,
                capture_output=True,
            )

            stdout = result.stdout
            stderr = result.stderr

            combined_output = stdout + "\n" + stderr
            compilation_errors = self.parse_compilation_errors(combined_output)
            if compilation_errors or not self.run_tests:
                return compilation_errors

            test_failures = self.parse_test_failures(combined_output)
            return test_failures

        except subprocess.CalledProcessError as e:
            logger.warning("Error running Maven command:")
            logger.warning(e.stderr)
--------------------------------------------------------------------------------
Chunk ID: verify/maven.py::2
Filepath: moatless\verify\maven.py
Content:
class MavenVerifier(Verifier):

    def parse_compilation_errors(self, output: str) -> list[VerificationError]:
        error_pattern = re.compile(r"\[ERROR\] (.*?):\[(\d+),(\d+)\] (.*)")
        matches = error_pattern.findall(output)

        errors = []
        for match in matches:
            file_path, line, column, message = match

            file_path = file_path.replace(f"{self.repo_dir}/", "")
            error = VerificationError(
                code="COMPILATION_ERROR",
                file_path=file_path.strip(),
                message=message.strip(),
                line=int(line),
            )
            errors.append(error)
        return errors
--------------------------------------------------------------------------------
Chunk ID: verify/maven.py::3
Filepath: moatless\verify\maven.py
Content:
class MavenVerifier(Verifier):

    def find_file(self, class_name: str) -> str:
        for root, _, files in os.walk(self.repo_dir):
            for file in files:
                if file == f"{class_name}.java":
                    absolute_path = os.path.join(root, file)
                    return os.path.relpath(absolute_path, self.repo_dir)
        return ""

    def parse_test_failures(self, output: str) -> list[VerificationError]:
        failure_pattern = re.compile(r"\[ERROR\]   (.*?):(\d+) (.*)")
        matches = failure_pattern.findall(output)

        errors = []
        for match in matches:
            test_case, line, message = match

            class_name = test_case.split(".")[0]

            file_path = self.find_file(class_name)

            error = VerificationError(
                code="TEST_FAILURE",
                file_path=file_path.strip(),
                message=message.strip(),
                line=int(line),
            )
            errors.append(error)
        return errors
--------------------------------------------------------------------------------
Chunk ID: verify/verify.py::1
Filepath: moatless\verify\verify.py
Content:
from abc import ABC, abstractmethod

from moatless.repository import CodeFile
from moatless.types import VerificationError


class Verifier(ABC):
    @abstractmethod
    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:
        pass
--------------------------------------------------------------------------------
Chunk ID: moatless/workspace.py::1
Filepath: moatless\workspace.py
Content:
import logging
from typing import Any, Optional, Dict

from moatless.codeblocks.parser.python import PythonParser
from moatless.file_context import FileContext
from moatless.index import IndexSettings
from moatless.index.code_index import CodeIndex
from moatless.repository import CodeFile, FileRepository, GitRepository
from moatless.types import FileWithSpans, VerificationError
from moatless.verify.lint import PylintVerifier
from moatless.verify.maven import MavenVerifier

_parser = PythonParser()

logger = logging.getLogger(__name__)
--------------------------------------------------------------------------------
Chunk ID: moatless/workspace.py::2
Filepath: moatless\workspace.py
Content:
class Workspace:
    def __init__(
        self,
        file_repo: FileRepository,
        index_dir: Optional[str] = None,
        index_settings: IndexSettings | None = None,
        max_results: int = 25,
        code_index: CodeIndex | None = None,
        verification_job: Optional[str] = "pylint",
        max_file_context_tokens: int = 4000,
        file_context: FileContext | None = None,
    ):
        self.file_repo = file_repo

        if code_index:
            self.code_index = code_index
        elif index_dir:
            try:
                self.code_index = CodeIndex.from_persist_dir(
                    index_dir, file_repo=file_repo, max_results=max_results
                )
            except FileNotFoundError:
                logger.info("No index found. Creating a new index.")
                code_index = CodeIndex(
                    file_repo=file_repo,
                    settings=index_settings,
                    max_results=max_results,
                )
                code_index.run_ingestion()
                code_index.persist(index_dir)
                self.code_index = code_index
        else:
            self.code_index = None

        if verification_job == "maven":
            self.verifier = MavenVerifier(self.file_repo.path)
        elif verification_job == "pylint":
            self.verifier = PylintVerifier(self.file_repo.path)
        else:
            self.verifier = None

        if file_context:
            self._file_context = file_context
        else:
            self._file_context = self.create_file_context(
                max_tokens=max_file_context_tokens
            )
--------------------------------------------------------------------------------
Chunk ID: moatless/workspace.py::3
Filepath: moatless\workspace.py
Content:
class Workspace:

    @classmethod
    def from_dirs(
        cls,
        git_repo_url: Optional[str] = None,
        commit: Optional[str] = None,
        repo_path: Optional[str] = None,
        max_file_context_tokens: int = 4000,
        **kwargs,
    ):
        if git_repo_url:
            file_repo = GitRepository.from_repo(
                git_repo_url=git_repo_url, repo_path=repo_path, commit=commit
            )
        elif repo_path:
            file_repo = FileRepository(repo_path)
        else:
            raise ValueError("Either git_repo_url or repo_dir must be provided.")

        return cls(
            file_repo=file_repo,
            max_file_context_tokens=max_file_context_tokens,
            **kwargs,
        )
--------------------------------------------------------------------------------
Chunk ID: moatless/workspace.py::4
Filepath: moatless\workspace.py
Content:
class Workspace:

    @classmethod
    def from_dict(cls, data: dict, **kwargs):
        if "repository" not in data:
            raise ValueError("Missing repository key")

        if data["repository"].get("git_repo_url"):
            file_repo = GitRepository.from_repo(
                git_repo_url=data["repository"].get("git_repo_url"),
                repo_path=data["repository"].get("repo_path"),
                commit=data["repository"].get("commit"),
            )
        elif data["repository"].get("repo_path"):
            file_repo = FileRepository(data["repository"].get("repo_path"))
        else:
            raise ValueError("Either git_repo_url or repo_dir must be provided.")

        file_context = FileContext(
            repo=file_repo, max_tokens=data["file_context"].get("max_tokens")
        )
        file_context.load_files_from_dict(data["file_context"].get("files", []))

        if data.get("code_index", {}).get("index_name"):
            code_index = CodeIndex.from_index_name(
                data["code_index"].get("index_name"), file_repo=file_repo
            )
        else:
            code_index = None

        return cls(
            file_repo=file_repo,
            file_context=file_context,
            code_index=code_index,
            **kwargs,
        )
--------------------------------------------------------------------------------
Chunk ID: moatless/workspace.py::5
Filepath: moatless\workspace.py
Content:
class Workspace:

    def restore_from_snapshot(self, snapshot: dict):
        self.file_repo.restore_from_snapshot(snapshot["repository"])
        self._file_context.restore_from_snapshot(snapshot["file_context"])

    def dict(self):
        return {
            "repository": self.file_repo.dict(),
            "file_context": self.file_context.model_dump(
                exclude_none=True, exclude_unset=True
            ),
            "code_index": self.code_index.dict() if self.code_index else None,
        }

    def snapshot(self) -> Dict[str, Any]:
        return {
            "repository": self.file_repo.snapshot(),
            "file_context": self.file_context.snapshot(),
        }

    def create_file_context(
        self,
        files_with_spans: list[FileWithSpans] | None = None,
        max_tokens: int = 4000,
    ):
        file_context = FileContext(self.file_repo, max_tokens=max_tokens)
        if files_with_spans:
            file_context.add_files_with_spans(files_with_spans)
        return file_context

    @property
    def file_context(self):
        return self._file_context

    def get_file(self, file_path, refresh: bool = False, from_origin: bool = False):
        return self.file_repo.get_file(
            file_path, refresh=refresh, from_origin=from_origin
        )

    def save(self):
        self.file_repo.save()

    def verify(self, file: CodeFile | None = None) -> list[VerificationError]:
        if self.verifier:
            return self.verifier.verify(file)

        logger.info("No verifier configured.")
        return []
--------------------------------------------------------------------------------
Chunk ID: benchmark/test_evaluation.py::1
Filepath: tests\benchmark\test_evaluation.py
Content:
import os
from datetime import datetime

import pytest
from dotenv import load_dotenv

from moatless.benchmark.evaluation import Evaluation
from moatless.edit import PlanToCode, EditCode
from moatless.find import SearchCode, IdentifyCode, DecideRelevance
from moatless.transitions import search_and_code_transitions

load_dotenv()
moatless_dir = os.getenv("MOATLESS_DIR", "/tmp/moatless")
index_store_dir = os.getenv("INDEX_STORE_DIR", "/tmp/index_store")
repo_dir = os.getenv("REPO_DIR", "/tmp/repo")

global_params = {
    "model": "gpt-4o-mini-2024-07-18",  # "azure/gpt-4o",
    "temperature": 0.5,
    "max_tokens": 2000,
    "max_prompt_file_tokens": 8000,
}

state_params = {
    SearchCode: {
        "provide_initial_context": True,
        "max_search_results": 75,
        "initial_context_tokens": 6000,
        "initial_search_results": 100,
        "initial_context_spans_per_file": 5,
    },
    IdentifyCode: {"expand_context": True},
    DecideRelevance: {
        "finish_after_relevant_count": 1,
    },
    PlanToCode: {
        "max_tokens_in_edit_prompt": 750,
        "expand_context_with_related_spans": False,
        "finish_on_review": True,
    },
    EditCode: {
        "chain_of_thought": False,
        "show_file_context": False,
        "max_prompt_file_tokens": 8000,
    },
}

search_and_code = search_and_code_transitions(
    global_params=global_params, state_params=state_params
)

pytest.mark.llm_integration = pytest.mark.skipif(
    "not config.getoption('--run-llm-integration')",
    reason="need --run-llm-integration option to run tests that call LLMs",
)
--------------------------------------------------------------------------------
Chunk ID: benchmark/test_evaluation.py::2
Filepath: tests\benchmark\test_evaluation.py
Content:
@pytest.mark.llm_integration
def test_run_single_evaluation_mcts():
    datestr = datetime.now().strftime("%Y%m%d-%H%M%S")
    dir = f"{moatless_dir}/eval_test"
    evaluation_name = f"{datestr}_mcts"

    evaluation = Evaluation(
        transitions=search_and_code,
        evaluations_dir=dir,
        evaluation_name=evaluation_name,
        index_store_dir=index_store_dir,
        repo_base_dir=repo_dir,
        max_file_context_tokens=16000,
        num_workers=1,
        detailed_report=True,
    )

    result = evaluation.run_single_instance("django__django-16379")

    assert result["instance_id"] == "django__django-16379"
    assert result["status"] == "edited"
    assert result["edited"]
    assert result["identified"]
    assert result["found_in_search"]
    assert result["file_identified"]
--------------------------------------------------------------------------------
Chunk ID: benchmark/test_report_v2.py::1
Filepath: tests\benchmark\test_report_v2.py
Content:
import json
from pathlib import Path

import pytest

from moatless.benchmark.report_v2 import to_result
from moatless.trajectory import Trajectory


@pytest.fixture
def django_trajectory():
    file_path = Path("tests/trajectories/django__django_16379.json")
    return Trajectory.load(str(file_path))


@pytest.fixture
def dataset():
    with open("moatless/benchmark/swebench_lite_all_evaluations.json") as f:
        return json.load(f)

@pytest.fixture
def django_instance(dataset):
    for instance in dataset:
        if instance["instance_id"] == "django__django-16379":
            return instance

    return None


def test_to_result(django_trajectory, django_instance):
    result = to_result(django_instance, django_trajectory)

    assert result["instance_id"] == "django__django-16379"
    assert result["status"] == "edited"
    assert result["transitions"] == len(django_trajectory.transitions)
    assert result["edited"]
    assert result["identified"]
    assert result["found_in_search"]
    assert result["file_identified"]
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_codeblocks.py::1
Filepath: tests\codeblocks\test_codeblocks.py
Content:
from moatless.codeblocks.parser.python import PythonParser


def scikit_learn_10297():
    with open(
        "../data/python/regressions/scikit-learn__scikit-learn-10297/original.py", "r"
    ) as f:
        content = f.read()
    parser = PythonParser(debug=False)

    return parser.parse(content)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_java_parser.py::1
Filepath: tests\codeblocks\test_java_parser.py
Content:
from moatless.codeblocks import JavaParser


def _verify_parsing(content, assertion, apply_gpt_tweaks=True, debug=True):
    parser = JavaParser(apply_gpt_tweaks=apply_gpt_tweaks, debug=debug)

    codeblock = parser.parse(content)

    print(codeblock.to_tree(include_references=True, show_spans=True, show_tokens=True))

    assert codeblock.to_string() == content

    assertion(codeblock)


def test_override_function():
    content = """public class Foo {
    @Override
    public void helloWorld() {
        // comment
        System.out.println("Hello World!");
    }
}"""

    def assertion(codeblock):
        print(
            codeblock.to_tree(
                include_references=True,
                show_spans=True,
                show_tokens=True,
                only_identifiers=False,
            )
        )

    _verify_parsing(content, assertion)


def test_interface():
    content = """public interface Foo {
    /**
     * Prints "Hello World!" to the console.
     */
    // TODO: Test
    void helloWorld();
}
"""

    def assertion(codeblock):
        print(
            codeblock.to_tree(
                include_references=True, show_spans=True, show_tokens=True
            )
        )

    _verify_parsing(content, assertion)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::1
Filepath: tests\codeblocks\test_python_parser.py
Content:
from moatless.benchmark.swebench import setup_swebench_repo, load_instance
from moatless.codeblocks import CodeBlockType
from moatless.codeblocks.codeblocks import (
    Relationship,
    RelationshipType,
    ReferenceScope,
    SpanType,
)
from moatless.codeblocks.parser.python import PythonParser


def _verify_parsing(content, assertion, apply_gpt_tweaks=True, debug=True):
    parser = PythonParser(apply_gpt_tweaks=apply_gpt_tweaks, debug=debug)

    codeblock = parser.parse(content)

    print(codeblock.to_tree(include_references=True, show_spans=True, show_tokens=True))

    assert codeblock.to_string() == content

    assertion(codeblock)


def test_function():
    content = """def foo():
    # ... existing code
    print('hello world')"""

    def assertion(codeblock):
        assert len(codeblock.children) == 1
        assert codeblock.children[0].identifier == "foo"
        assert len(codeblock.children[0].children) == 2

    _verify_parsing(content, assertion)


def test_outcommented_function():
    content = """def foo():
    # ... existing code"""

    def assertion(codeblock):
        assert len(codeblock.children) == 1
        assert codeblock.children[0].identifier == "foo"
        assert codeblock.children[0].type == CodeBlockType.COMMENTED_OUT_CODE

    _verify_parsing(content, assertion)


def test_function_followed_by_comment():
    content = """def foo():
    print('hello world')

# comment
"""

    def assertion(codeblock):
        assert len(codeblock.children) == 3

    _verify_parsing(content, assertion)


def test_outcommented_function_with_decorator():
    content = """@pytest.hookimpl(trylast=True)
def pytest_configure(config):
    # ... existing code"""

    def assertion(codeblock):
        assert len(codeblock.children) == 1
        assert codeblock.children[0].identifier == "pytest_configure"
        assert codeblock.children[0].type == CodeBlockType.COMMENTED_OUT_CODE

    _verify_parsing(content, assertion)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::2
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_outcommented_functions():
    content = """@pytest.hookimpl(trylast=True)
def pytest_configure(config):
    # ... existing code

def pytest_unconfigure(config):
    # ... existing code

def create_new_paste(contents):
    import re

def pytest_terminal_summary(terminalreporter):
    # ... existing code"""

    def assertion(codeblock):
        assert len(codeblock.children) == 4
        assert [child.identifier for child in codeblock.children] == [
            "pytest_configure",
            "pytest_unconfigure",
            "create_new_paste",
            "pytest_terminal_summary",
        ]
        assert [child.type for child in codeblock.children] == [
            CodeBlockType.COMMENTED_OUT_CODE,
            CodeBlockType.COMMENTED_OUT_CODE,
            CodeBlockType.FUNCTION,
            CodeBlockType.COMMENTED_OUT_CODE,
        ]

    _verify_parsing(content, assertion)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::3
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_function_in_function():
    content = """def foo():
    def bar():
        print('hello world')
        return 42

    print("hello")
    return bar()"""

    def assertion(codeblock):
        assert len(codeblock.children) == 1

    _verify_parsing(content, assertion)


def test_class_with_comment():
    content = """class BaseSchema(base.SchemaABC):
    # ... other code

    def _invoke_field_validators(self, unmarshal, data, many):
        foo
    bar = 1"""

    def assertion(codeblock):
        assert len(codeblock.children) == 1

    _verify_parsing(content, assertion)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::4
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_raise_string_line_break():
    content = """def foo():
    raise ValueError(
                     \"""
FITS WCS distortion paper lookup tables and SIP distortions only work
in 2 dimensions.  However, WCSLIB has detected {0} dimensions in the
core WCS keywords.  To use core WCS in conjunction with FITS WCS
distortion paper lookup tables or SIP distortion, you must select or
reduce these to 2 dimensions using the naxis kwarg.
\""".format(wcsprm.naxis))
"""

    def assertion(codeblock):
        print(codeblock.to_tree())
        print(codeblock.to_string())

    _verify_parsing(content, assertion)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::5
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_referenced_blocks():
    content = """class Event:
    def __init__(self, name):
        self.name = name

class EventLogger:
    def __init__(self):
        self.events = []

    def log_event(self, event: Event):
        self.events.append(event)
        self.show_last_event()

    def show_last_event(self):
        if self.events:
            print(f"Last event: {self.events[-1]}")
"""

    def assertion(codeblock):
        # TODO: Verify!
        pass

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::6
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_decoratated_function():
    content = """class Foo:
    @classmethod
    def bar(cls):
        return 42
"""

    def assertion(codeblock):
        assert content == codeblock.to_string()
        func = codeblock.find_by_path(["Foo", "bar"])
        assert func is not None
        assert len(func.children) == 1
        assert func.children[0].type == CodeBlockType.STATEMENT

    _verify_parsing(content, assertion, debug=False)


def test_decoratated_function_with_comment():
    content = """class Foo:
    @classmethod
    def bar(cls):
        # ... other code
        return 42
"""

    def assertion(codeblock):
        func = codeblock.find_by_path(["Foo", "bar"])
        assert func is not None
        assert len(func.children) == 2
        assert func.children[0].type == CodeBlockType.COMMENTED_OUT_CODE

    _verify_parsing(content, assertion, apply_gpt_tweaks=True, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::7
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_decorated_function():
    content = """@property
def identity(self):
    foo = 1
    return super().identity + (
        self.through
    )"""

    def assertion(codeblock):
        pass

    _verify_parsing(content, assertion, debug=True)


def test_parse_function_with_class_relationship():
    content = """class Foo:

    def _reset(self):
        self.bar = None
"""

    def assertion(codeblock):
        pass

    _verify_parsing(content, assertion, debug=True, apply_gpt_tweaks=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::8
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_parse_function_with_relationship():
    content = """import time

def print_reset():
    print('reset1')

class Base:

    def baz():
        pass

class Foo(Base):

    def __init__(self, bar):
        self.bar = bar

    def reset(self):
        self._reset()
        print_reset()

    def _reset(self):
        time.sleep(0.1)
        self.bar = None
"""

    def assertion(codeblock):
        foo_class = codeblock.find_by_path(["Foo"])
        relationships = foo_class.get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.IS_A,
            path=["Base"],
        )

        init_func = codeblock.find_by_path(["Foo", "__init__"])
        relationships = init_func.get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.CLASS,
            identifier="self.bar",
            type=RelationshipType.USES,  # TODO: Change?
            path=["Foo", "bar"],
        )

        reset_func = codeblock.find_by_path(["Foo", "reset"])
        relationships = reset_func.get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.CLASS,
            identifier="",
            type=RelationshipType.CALLS,  # TODO: Change?
            path=["Foo", "_reset"],
        )

        assert relationships[1] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.CALLS,  # TODO: Change?
            path=["print_reset"],
        )

    _verify_parsing(content, assertion, debug=False, apply_gpt_tweaks=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::9
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_parse_class_relationships():
    content = """class ForeignObjectRel(FieldCacheMixin):

    def __init__(self, field):
        self.field = field

    @property
    def identity(self):
        return (
            self.field
        )

class ManyToManyRel(ForeignObjectRel):

    def __init__(self, field, through):
        super().__init__(
            field
        )
        self.through = through

    @property
    def identity(self):
        return super().identity + (
            self.through
        )
"""
    # ... other code
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::10
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_parse_class_relationships():
    # ... other code

    def assertion(codeblock):
        m2m_class = codeblock.find_by_path(["ManyToManyRel"])
        relationships = m2m_class.get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.IS_A,
            path=["ForeignObjectRel"],
        )

        init_func = codeblock.find_by_path(["ManyToManyRel", "__init__"])
        relationships = init_func.get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.LOCAL,
            type=RelationshipType.USES,
            path=["ForeignObjectRel", "__init__"],
        )

        id_func = codeblock.find_by_path(["ManyToManyRel", "identity"])
        relationships = id_func.get_all_relationships()
        # TODO: Support and assert relationships to super and self!

    _verify_parsing(content, assertion, debug=True, apply_gpt_tweaks=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::11
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_parse_class_with_method_mixin():
    content = """class SuperClass:
    pass

class SubClass(SuperClass):
    pass

class SubClassWithMultipleClasses(SuperClass, AnotherClass):
    pass

class SubClassWithMethod(foo.bar(SuperClass, AnotherClass)):
    pass
"""

    def assertion(codeblock):
        assert codeblock.find_by_path(["SuperClass"]).type == CodeBlockType.CLASS
        assert codeblock.find_by_path(["SubClass"]).type == CodeBlockType.CLASS
        assert (
            codeblock.find_by_path(["SubClassWithMultipleClasses"]).type
            == CodeBlockType.CLASS
        )
        assert (
            codeblock.find_by_path(["SubClassWithMethod"]).type == CodeBlockType.CLASS
        )

        relationships = codeblock.find_by_path(["SubClass"]).get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.IS_A,
            path=["SuperClass"],
        )
        relationships = codeblock.find_by_path(
            ["SubClassWithMultipleClasses"]
        ).get_all_relationships()
        assert relationships[0] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.IS_A,
            path=["SuperClass"],
        )
        assert relationships[1] == Relationship(
            scope=ReferenceScope.LOCAL,
            identifier="",
            type=RelationshipType.IS_A,
            path=["AnotherClass"],
        )
        relationships = codeblock.find_by_path(
            ["SubClassWithMethod"]
        ).get_all_relationships()
        # TODO: Support method calls

    _verify_parsing(content, assertion, debug=True, apply_gpt_tweaks=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::12
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_init_spans():
    content = """\"""
"Rel objects" for related fields.
\"""

from django.core import exceptions

class ForeignObjectRel(FieldCacheMixin):
    \"""
    Used by ForeignObject to store information about the relation.
    \"""

    # Field flags
    auto_created = True

    def __init__(self, field, to):
        self.field = field

    # Some of the following cached_properties can't be initialized in
    @cached_property
    def hidden(self):
        return self.is_hidden()
"""

    def assertion(codeblock):
        pass  # TODO

    _verify_parsing(content, assertion, debug=False, apply_gpt_tweaks=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::13
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_spans():
    content = """def foo():
    row_1 = 1
    row_2 = 2
    row_3 = 3

bar = 42
"""

    parser = PythonParser(max_tokens_in_span=12)

    codeblock = parser.parse(content)

    print(codeblock.to_tree(include_references=True, show_spans=True, show_tokens=True))

    assert codeblock.to_string() == content


def test_assignment_with_line_break():
    content = """BAR = \\
42

_FOO = \\
    r\"""
foo
\"""
"""

    def assertion(codeblock):
        print(codeblock.to_prompt(show_span_id=True))

    _verify_parsing(content, assertion, debug=True)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::14
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_init_span():
    content = """class UserChangeForm(forms.ModelForm):
    password = ReadOnlyPasswordHashField()

    class Meta:
        model = User

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def foo(self):
        pass
"""

    def assertion(codeblock):
        assert (
            codeblock.find_by_path(["UserChangeForm"]).belongs_to_span.span_type
            == SpanType.INITATION
        )
        assert (
            codeblock.find_by_path(["UserChangeForm", "Meta"]).belongs_to_span.span_type
            == SpanType.INITATION
        )
        assert codeblock.find_by_path(
            ["UserChangeForm", "Meta"]
        ).belongs_to_span.parent_block_path == ["UserChangeForm", "Meta"]
        assert (
            codeblock.find_by_path(
                ["UserChangeForm", "__init__"]
            ).belongs_to_span.span_type
            == SpanType.INITATION
        )
        assert codeblock.find_by_path(
            ["UserChangeForm", "__init__"]
        ).belongs_to_span.parent_block_path == ["UserChangeForm", "__init__"]
        assert (
            codeblock.find_by_path(["UserChangeForm", "foo"]).belongs_to_span.span_type
            == SpanType.IMPLEMENTATION
        )
        assert codeblock.find_by_path(
            ["UserChangeForm", "foo"]
        ).belongs_to_span.parent_block_path == ["UserChangeForm", "foo"]

        print(codeblock.to_prompt(show_span_id=True))

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::15
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_class_with_methods_spans():
    content = """class Q(tree.Node):

    def __and__(self, other):
        return self._combine(other, self.AND)

    def __rand__(self, other):
        return self.__and__(other)"""

    def assertion(codeblock):
        class_span = codeblock.find_span_by_id("Q")
        assert class_span is not None
        assert class_span.parent_block_path == ["Q"]
        assert codeblock.find_span_by_id("Q.__and__") is not None
        assert codeblock.find_span_by_id("Q.__rand__") is not None

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::16
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_spans():
    content = """def uniq(seq, result=None):
    def check():
        # check that size of seq did not change during iteration;
        if n is not None and len(seq) != n:
            raise RuntimeError('sequence changed size during iteration')
    try:
        seen = set()
    except TypeError:
        yield s
"""
    parser = PythonParser(max_tokens_in_span=2000, debug=True)

    codeblock = parser.parse(content)

    print(codeblock.to_tree(include_references=True, show_spans=True, show_tokens=True))

    assert codeblock.to_string() == content
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::17
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_with_line_numbers():
    content = """foo = 42

link = add_domain(
    current_site.domain,
    self._get_dynamic_attr('item_link', item),
    request.is_secure())

def foo():
    line_1 = 9
    line_2 = 10
    line_3 = 11
"""

    def assertion(codeblock):
        print("Tree:\n", codeblock.to_tree())

        prompt = codeblock.to_prompt()
        print("Prompt:\n", prompt)

        prompt_with_line_numbers = codeblock.to_prompt(show_line_numbers=True)
        print("Prompt with line numbers:\n", prompt_with_line_numbers)

        for line in prompt_with_line_numbers.split("\n"):
            assert line[0].isdigit()

        prompt_with_line_10_11 = codeblock.to_prompt(
            start_line=10,
            end_line=11,
            show_outcommented_code=True,
            outcomment_code_comment="... other code",
        ).strip()
        print("Prompt line 10-11:\n", prompt_with_line_10_11)

        assert (
            prompt_with_line_10_11
            == """# ... other code

def foo():
    # ... other code
    line_2 = 10
    line_3 = 11"""
        )

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::18
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_if_else_clause():
    content = """if foo == 42:
        bar = 42
    elif foo == 43:
        bar = 43
    else:
        bar = 44
"""

    def assertion(codeblock):
        assert codeblock.children[0].type == CodeBlockType.COMPOUND

    _verify_parsing(content, assertion, debug=True)


def test_commented_out_if_else_clause():
    content = """if foo == 42:
    pass
else:
    bar = 44"""

    def assertion(codeblock):
        assert codeblock.children[0].type == CodeBlockType.COMPOUND

    _verify_parsing(content, assertion, apply_gpt_tweaks=True, debug=True)


def test_query_match():
    content = """if foo == 42:
    return True
"""

    parser = PythonParser()
    content_in_bytes = bytes(content, "utf8")
    tree = parser.tree_parser.parse(content_in_bytes)

    for label, node_type, query in parser.queries:
        if label == "python.scm:17":
            print(label, node_type, query)
            break

    captured = query.captures(tree.walk().node.children[0])
    print(captured)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::19
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_find_nested_blocks_by_line_numbers():
    content = """def foo():
    if True:
        line_1 = 9
    else:
        line_3 = 11
        while True:
            line_2 = 10
    return False"""

    def assertion(codeblock):
        prompt_with_line_numbers = codeblock.to_prompt(show_line_numbers=True)
        print(prompt_with_line_numbers)

        for line in prompt_with_line_numbers.split("\n"):
            assert line[0].isdigit()

        prompt_with_line_numbers = codeblock.to_prompt(
            start_line=7,
            end_line=8,
            show_outcommented_code=True,
            outcomment_code_comment="... other code",
        ).strip()
        print(prompt_with_line_numbers)

        # prompt_with_line_numbers = codeblock.to_prompt(start_line=5, end_line=5, show_outcommented_code=False).strip()
        # print(prompt_with_line_numbers)

        assert (
            prompt_with_line_numbers
            == """def foo():
    if True:
    # ... other code
    else:
        # ... other code
        while True:
            line_2 = 10
    return False"""
        )

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::20
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_next_and_previous():
    content = """class Foo:

    def __init__(self):
        self.bar = 42
        self.baz = 43

    def foo(self):
        return self.bar

    def bar(self):
        self.baz = 44
        return self.baz
"""

    def assertion(codeblock):
        expected_block_order = [
            "",
            "Foo",
            "Foo.__init__",
            "Foo.__init__.self.bar",
            "Foo.__init__.self.bar.42",
            "Foo.__init__.self.baz",
            "Foo.__init__.self.baz.43",
            "Foo.foo",
            "Foo.foo.return",
            "Foo.foo.return.self_bar",
            "Foo.bar",
            "Foo.bar.self.baz",
            "Foo.bar.self.baz.44",
            "Foo.bar.return",
            "Foo.bar.return.self_baz",
        ]

        next_block_order = []
        first_block = codeblock
        while first_block:
            next_block_order.append(first_block.path_string())
            first_block = first_block.next

        assert next_block_order == expected_block_order

        last_block = codeblock.last()

        previous_block_order = []
        while last_block:
            previous_block_order.append(last_block.path_string())
            last_block = last_block.previous

        assert previous_block_order == list(reversed(expected_block_order))

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: codeblocks/test_python_parser.py::21
Filepath: tests\codeblocks\test_python_parser.py
Content:
def test_new_spans():
    content = """class PsBackendHelper:
    def __init__(self):
        self._cached = {}

ps_backend_helper = PsBackendHelper()

papersize = {'letter': (8.5, 11)}
"""

    def assertion(codeblock):
        print(codeblock.to_tree(show_spans=True, include_types=True))

        assert len(codeblock.span_ids) == 3

    _verify_parsing(content, assertion, debug=False)


def test_invalid_content():
    content = """evalcache_key = StoreKey[Dict[str, Any]]()

    # ...
    def _istrue(self) -> bool:
        if hasattr(self, "result"):
            result = getattr(self, "result")  # type: bool
            return result
        self._marks = self._get_marks()


        return False
    # ...
"""

    def assertion(codeblock):
        print(codeblock.to_tree(show_spans=True))

        placeholders = codeblock.find_blocks_with_type(CodeBlockType.COMMENTED_OUT_CODE)

        assert len(placeholders) == 2

    _verify_parsing(content, assertion, debug=False)


def test_ignored_spans():
    instance = load_instance("psf__requests-2674")
    repo_dir = setup_swebench_repo(instance)
    file_path = f"{repo_dir}/requests/adapters.py"
    with open(file_path, "r") as file:
        content = file.read()

    def assertion(codeblock):
        print(codeblock.to_tree(show_spans=True))

    _verify_parsing(content, assertion, debug=False)
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::1
Filepath: tests\edit\test_clarify.py
Content:
import pytest
from unittest.mock import Mock, patch
from moatless.edit.clarify import ClarifyCodeChange, LineNumberClarification
from moatless.types import ActionResponse, FileWithSpans
from moatless.workspace import Workspace
from moatless.file_context import FileContext
from moatless.repository import CodeFile
from moatless.codeblocks.codeblocks import BlockSpan, CodeBlock
from moatless.codeblocks import CodeBlockType

class TestClarifyCodeChange:
    @pytest.fixture
    def clarify_code_change(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)
        mock_file_context = Mock(spec=FileContext)

        return ClarifyCodeChange(
            id=2,
            instructions="Update function",
            file_path="test.py",
            span_id="span1",
            _workspace=mock_workspace,
            file_context=mock_file_context
        )

    def test_action_type(self, clarify_code_change: ClarifyCodeChange):
        assert clarify_code_change.action_type() == LineNumberClarification
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::2
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:

    @patch('moatless.edit.clarify.ClarifyCodeChange._verify_line_numbers')
    def test_execute_action_reject(self, mock_verify, clarify_code_change: ClarifyCodeChange):
        action = LineNumberClarification(
            scratch_pad="Cannot complete the task",
            start_line=1,
            end_line=5,
            reject=True
        )

        response = clarify_code_change._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "reject"
        assert response.output["message"] == "Cannot complete the task"
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::3
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:

    @patch('moatless.edit.clarify.ClarifyCodeChange._verify_line_numbers')
    @patch('moatless.edit.clarify.ClarifyCodeChange.get_line_span')
    def test_execute_action_edit_code(self, mock_get_line_span, mock_verify, clarify_code_change: ClarifyCodeChange):
        action = LineNumberClarification(
            scratch_pad="Updating lines",
            start_line=2,
            end_line=4
        )

        mock_verify.return_value = None
        mock_get_line_span.return_value = (2, 4)

        response = clarify_code_change._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "edit_code"
        assert response.output["instructions"] == "Update function\n\nUpdating lines"
        assert response.output["file_path"] == "test.py"
        assert response.output["span_id"] == "span1"
        assert response.output["start_line"] == 2
        assert response.output["end_line"] == 4
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::4
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:

    @patch('moatless.edit.clarify.ClarifyCodeChange._verify_line_numbers')
    def test_execute_action_retry(self, mock_verify, clarify_code_change: ClarifyCodeChange):
        action = LineNumberClarification(
            scratch_pad="Retry needed",
            start_line=1,
            end_line=10
        )

        mock_verify.return_value = "Invalid line numbers"

        response = clarify_code_change._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "retry"
        assert response.retry_message == "Invalid line numbers"
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::5
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:

    def test_required_fields(self, clarify_code_change: ClarifyCodeChange):
        assert clarify_code_change.required_fields() == {"instructions", "file_path", "span_id"}

    def test_messages(self, clarify_code_change: ClarifyCodeChange):
        # TODO: Test init() properly
        clarify_code_change._file_context_str = "Mock file context"
        messages = clarify_code_change.messages()

        assert len(messages) == 1
        assert "<instructions>" in messages[0].content
        assert "Update function" in messages[0].content
        assert "<code>" in messages[0].content
        assert "Mock file context" in messages[0].content
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::6
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:


    @patch('moatless.repository.CodeFile')
    @patch('moatless.codeblocks.codeblocks.BlockSpan')
    def test_verify_line_numbers_valid(self, mock_span, mock_file, clarify_code_change: ClarifyCodeChange):
        mock_file.content = "line1\nline2\nline3\nline4\nline5"
        mock_span.start_line = 1
        mock_span.end_line = 5
        clarify_code_change._file = mock_file
        clarify_code_change._span = mock_span

        action = LineNumberClarification(
            scratch_pad="Valid lines",
            start_line=2,
            end_line=4
        )

        result = clarify_code_change._verify_line_numbers(action)

        assert result is None
--------------------------------------------------------------------------------
Chunk ID: edit/test_clarify.py::7
Filepath: tests\edit\test_clarify.py
Content:
class TestClarifyCodeChange:

    @patch('moatless.repository.CodeFile')
    @patch('moatless.codeblocks.codeblocks.BlockSpan')
    def test_verify_line_numbers_invalid(self, mock_span, mock_file, clarify_code_change: ClarifyCodeChange):
        mock_file.content = "line1\nline2\nline3\nline4\nline5"
        mock_span.start_line = 1
        mock_span.end_line = 5
        clarify_code_change._file = mock_file
        clarify_code_change._span = mock_span

        action = LineNumberClarification(
            scratch_pad="Invalid lines",
            start_line=1,
            end_line=5
        )

        result = clarify_code_change._verify_line_numbers(action)

        assert result is not None
        assert "covers the whole code span" in result
--------------------------------------------------------------------------------
Chunk ID: edit/test_edit.py::1
Filepath: tests\edit\test_edit.py
Content:
import pytest
from unittest.mock import Mock, patch
from moatless.edit.edit import EditCode
from moatless.repository.file import UpdateResult
from moatless.types import ActionResponse, Content
from moatless.workspace import Workspace
from moatless.file_context import FileContext
from moatless.repository import CodeFile

class TestEditCode:

    @pytest.fixture
    def edit_code(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)

        return EditCode(
            id=1,
            instructions="Update function",
            file_path="test.py",
            span_id="span1",
            verify=False,
            start_line=1,
            end_line=5,
            _workspace=mock_workspace,
            model="gpt-3.5-turbo"
        )

    def test_required_fields(self, edit_code: EditCode):
        assert edit_code.required_fields() == {"instructions", "file_path", "span_id", "start_line", "end_line"}
--------------------------------------------------------------------------------
Chunk ID: edit/test_edit.py::2
Filepath: tests\edit\test_edit.py
Content:
class TestEditCode:

    @patch('moatless.edit.edit.EditCode.file_context')
    def test_init(self, mock_file_context, edit_code: EditCode):
        mock_file = Mock(spec=CodeFile)
        mock_file.content = "line1\nline2\nline3\nline4\nline5"
        mock_file_wrapper = Mock(file=mock_file)
        mock_file_context.get_file.return_value = mock_file_wrapper

        edit_code.init()

        assert edit_code._code_to_replace == "line1\nline2\nline3\nline4\nline5"

    @patch('moatless.edit.edit.EditCode.file_context')
    def test_execute_action_reject(self, mock_file_context, edit_code: EditCode):
        content = Content(content="<reject>Cannot complete the task</reject>")

        response = edit_code._execute_action(content)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "reject"
        assert response.output["message"] == "Cannot complete the task"
--------------------------------------------------------------------------------
Chunk ID: edit/test_edit.py::3
Filepath: tests\edit\test_edit.py
Content:
class TestEditCode:

    @patch('moatless.edit.edit.EditCode.file_context')
    def test_execute_action_edit_code(self, mock_file_context, edit_code: EditCode):
        update_result = UpdateResult(diff="diff", updated=True, file_path="test.py")

        mock_file = Mock(spec=CodeFile)
        mock_file.update_content_by_line_numbers.return_value = update_result

        mock_context_file = Mock()
        mock_context_file.file = mock_file
        mock_context_file.update_content_by_line_numbers.return_value = update_result

        mock_file_context.get_file.return_value = mock_context_file

        content = Content(content="<replace>updated code</replace>")

        response = edit_code._execute_action(content)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"
        assert "Applied the change to test.py." in response.output["message"]
        assert response.output["diff"] == "diff"

        mock_context_file.update_content_by_line_numbers.assert_called_once()
--------------------------------------------------------------------------------
Chunk ID: edit/test_edit.py::4
Filepath: tests\edit\test_edit.py
Content:
class TestEditCode:

    @patch('moatless.edit.edit.EditCode.file_context')
    def test_execute_action_retry(self, mock_file_context, edit_code: EditCode):
        mock_file = Mock(spec=CodeFile)
        mock_file.update_content_by_line_numbers.return_value = Mock(diff=None, updated=False)
        mock_context_file = Mock()
        mock_context_file.file = mock_file
        mock_context_file.update_content_by_line_numbers.return_value = Mock(diff=None, updated=False)
        mock_file_context.get_file.return_value = mock_context_file

        content = Content(content="<replace>unchanged code</replace>")

        response = edit_code._execute_action(content)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "retry"
        assert "The code in the replace tag is the same as in the search" in response.retry_message

    def test_system_prompt(self, edit_code: EditCode):
        system_prompt = edit_code.system_prompt()

        assert "You are autonomous AI assisistant with superior programming skills." in system_prompt
--------------------------------------------------------------------------------
Chunk ID: edit/test_edit.py::5
Filepath: tests\edit\test_edit.py
Content:
class TestEditCode:

    @patch('moatless.edit.edit.EditCode.file_context')
    def test_messages(self, mock_file_context, edit_code: EditCode):
        mock_file_context.create_prompt.return_value = "Mock file context"
        edit_code._code_to_replace = "code to replace"

        messages = edit_code.messages()

        assert len(messages) == 1
        assert "<instructions>" in messages[0].content
        assert "Update function" in messages[0].content
        assert "<file_context>" in messages[0].content
        assert "Mock file context" in messages[0].content
        assert "<search>" in messages[0].content
        assert "code to replace" in messages[0].content

    def test_action_type(self, edit_code: EditCode):
        assert edit_code.action_type() is None

    def test_stop_words(self, edit_code: EditCode):
        assert edit_code.stop_words() == ["</replace>"]
--------------------------------------------------------------------------------
Chunk ID: edit/test_plan.py::1
Filepath: tests\edit\test_plan.py
Content:
import pytest
from unittest.mock import Mock, patch
from moatless.edit.plan import PlanToCode, ApplyChange
from moatless.types import ActionResponse, ActionTransaction
from moatless.workspace import Workspace
from moatless.file_context import FileContext

class TestPlanToCode:
    @pytest.fixture
    def plan_to_code(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)
        mock_file_context = Mock(spec=FileContext)

        return PlanToCode(
            id=1,
            _workspace=mock_workspace,
            _initial_message="Test initial message",
            file_context=mock_file_context
        )

    def test_action_type(self, plan_to_code):
        assert plan_to_code.action_type() == ApplyChange

    def test_execute_action_finish(self, plan_to_code):
        action = ApplyChange(
            scratch_pad="Finished",
            action="finish",
            finish="Task completed successfully"
        )

        response = plan_to_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"
        assert response.output["message"] == "Task completed successfully"

    def test_execute_action_reject(self, plan_to_code):
        action = ApplyChange(
            scratch_pad="Rejected",
            action="reject",
            reject="Cannot complete the task"
        )

        response = plan_to_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "reject"
        assert response.output["message"] == "Cannot complete the task"

    def test_execute_action_review(self, plan_to_code):
        action = ApplyChange(
            scratch_pad="Review needed",
            action="review"
        )

        response = plan_to_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "retry"
        assert "Review isn't possible" in response.retry_message
--------------------------------------------------------------------------------
Chunk ID: edit/test_plan.py::2
Filepath: tests\edit\test_plan.py
Content:
class TestPlanToCode:

    @patch('moatless.edit.plan.PlanToCode._request_for_change')
    def test_execute_action_apply_change(self, mock_request_for_change, plan_to_code):
        action = ApplyChange(
            scratch_pad="Applying change",
            action="modify",
            file_path="test.py",
            span_id="span1",
            instructions="Update function"
        )

        mock_request_for_change.return_value = ActionResponse(trigger="edit_code")

        response = plan_to_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "edit_code"
        mock_request_for_change.assert_called_once_with(action)
--------------------------------------------------------------------------------
Chunk ID: edit/test_plan.py::3
Filepath: tests\edit\test_plan.py
Content:
class TestPlanToCode:

    @patch('moatless.file_context.FileContext.create_prompt')
    def test_messages(self, mock_create_prompt, plan_to_code):
        mock_create_prompt.return_value = "Mock file context"

        messages = plan_to_code.messages()

        assert len(messages) == 1
        assert "<issue>" in messages[0].content
        assert "Test initial message" in messages[0].content
        assert "<file_context>" in messages[0].content
        assert "Mock file context" in messages[0].content

        mock_create_prompt.assert_called_once()
--------------------------------------------------------------------------------
Chunk ID: edit/test_plan.py::4
Filepath: tests\edit\test_plan.py
Content:
class TestPlanToCode:

    @patch('moatless.file_context.FileContext.get_file')
    @patch('moatless.file_context.FileContext.get_spans')
    def test_request_for_change_file_not_found(self, mock_get_spans, mock_get_file, plan_to_code):
        mock_get_file.return_value = None
        mock_get_spans.return_value = []

        action = ApplyChange(
            scratch_pad="Change request",
            action="modify",
            file_path="nonexistent.py",
            span_id="span1",
            instructions="Update function"
        )

        response = plan_to_code._request_for_change(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "retry"
        assert "File nonexistent.py is not found in the file context" in response.retry_message

    # Add more tests for other scenarios in _request_for_change method
--------------------------------------------------------------------------------
Chunk ID: find/test_decide.py::1
Filepath: tests\find\test_decide.py
Content:
import pytest
from moatless.find.decide import DecideRelevance, Decision
from moatless.find.identify import Identify, IdentifyCode
from moatless.types import ActionResponse, ActionTransaction
from moatless.workspace import Workspace
from moatless.file_context import FileContext
from unittest.mock import Mock, MagicMock, patch

class TestDecideRelevance:
    @pytest.fixture
    def decide_relevance(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)
        mock_file_context = Mock(spec=FileContext)

        return DecideRelevance(
            id=1,
            _workspace=mock_workspace,
            _initial_message="Test initial message",
            expand_context=False,
            file_context=mock_file_context
        )

    def test_action_type(self, decide_relevance):
        assert decide_relevance.action_type() == Decision

    def test_execute_action_complete_and_relevant(self, decide_relevance):
        action = Decision(
            scratch_pad="Complete and relevant",
            relevant=True,
            complete=True
        )

        response = decide_relevance._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"

    def test_execute_action_relevant_but_not_complete(self, decide_relevance):
        decide_relevance.finish_after_relevant_count = 1
        decide_relevance._relevant_count = Mock(return_value=1)
        action = Decision(
            scratch_pad="Relevant but not complete",
            relevant=True,
            complete=False
        )

        response = decide_relevance._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"

    def test_execute_action_not_relevant_not_complete(self, decide_relevance):
        action = Decision(
            scratch_pad="Not relevant, not complete",
            relevant=False,
            complete=False,
            search_suggestions="Try searching for X"
        )

        response = decide_relevance._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "search"
        assert response.output["message"] == "Try searching for X"
--------------------------------------------------------------------------------
Chunk ID: find/test_decide.py::2
Filepath: tests\find\test_decide.py
Content:
class TestDecideRelevance:

    def test_relevant_count(self, decide_relevance: DecideRelevance):
        state3 = DecideRelevance(id=3, expand_context=False, file_context=Mock())
        state3._actions = [ActionTransaction(request=Decision(scratch_pad="Test", relevant=True), response=ActionResponse(trigger="finish"))]
        state2 = DecideRelevance(id=2, expand_context=False, file_context=Mock())
        state2._actions = [ActionTransaction(request=Decision(scratch_pad="Test", relevant=False), response=ActionResponse(trigger="finish"))]
        state2.previous_state = state3
        state1 = DecideRelevance(id=1, expand_context=False, file_context=Mock())
        state1._actions = [ActionTransaction(request=Decision(scratch_pad="Test", relevant=True), response=ActionResponse(trigger="finish"))]
        state1.previous_state = state2

        decide_relevance.previous_state = state1
        assert len(decide_relevance.get_previous_states(decide_relevance)) == 3
        assert decide_relevance._relevant_count() == 2
--------------------------------------------------------------------------------
Chunk ID: find/test_decide.py::3
Filepath: tests\find\test_decide.py
Content:
class TestDecideRelevance:

    @patch('moatless.file_context.FileContext.create_prompt')
    def test_messages(self, mock_create_prompt, decide_relevance):
        mock_create_prompt.return_value = "Mock file context"

        messages = decide_relevance.messages()

        assert len(messages) == 1
        assert "<issue>" in messages[0].content
        assert "Test initial message" in messages[0].content
        assert "<file_context>" in messages[0].content
        assert "Mock file context" in messages[0].content

        mock_create_prompt.assert_called_once()
--------------------------------------------------------------------------------
Chunk ID: find/test_decide.py::4
Filepath: tests\find\test_decide.py
Content:
class TestDecideRelevance:

    @patch('moatless.file_context.FileContext.create_prompt')
    def test_messages_with_last_scratch_pad(self, mock_create_prompt, decide_relevance):
        mock_create_prompt.return_value = "Mock file context"

        previous_state = IdentifyCode(id=3)
        previous_state._actions = [ActionTransaction(request=Identify(scratch_pad="Previous scratch pad", relevant=True))]
        decide_relevance.previous_state = previous_state

        messages = decide_relevance.messages()

        assert len(messages) == 1
        assert "<scratch_pad>" in messages[0].content
        assert "Previous scratch pad" in messages[0].content

    def test_system_prompt(self, decide_relevance):
        system_prompt = decide_relevance.system_prompt()

        assert "You will be provided a reported issue and the file context" in system_prompt
        assert "Analyze the Issue:" in system_prompt
        assert "Analyze File Context:" in system_prompt
        assert "Make a Decision:" in system_prompt
--------------------------------------------------------------------------------
Chunk ID: find/test_identify.py::1
Filepath: tests\find\test_identify.py
Content:
import pytest
from moatless.codeblocks.codeblocks import BlockSpan, SpanType
from moatless.find.identify import IdentifyCode, Identify, is_test_pattern
from moatless.file_context import RankedFileSpan
from moatless.repository.file import CodeFile
from moatless.types import FileWithSpans, ActionResponse
from moatless.workspace import Workspace
from unittest.mock import Mock, MagicMock

class TestIdentifyCode:
    @pytest.fixture
    def identify_code(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)

        mock_module = Mock()
        mock_module.find_span_by_id.side_effect = lambda span_id: BlockSpan(
            span_type=SpanType.IMPLEMENTATION,
            span_id=span_id,
            start_line=0,
            end_line=10,
        )

        mock_code_file = MagicMock(spec=CodeFile)
        mock_code_file.content = "Mock file content"
        mock_code_file.file_path = "test.py"
        mock_code_file.module = mock_module

        mock_file_repo.get_file.side_effect = lambda path: mock_code_file

        return IdentifyCode(id=1, _workspace=mock_workspace, _initial_message="Test initial message")
--------------------------------------------------------------------------------
Chunk ID: find/test_identify.py::2
Filepath: tests\find\test_identify.py
Content:
class TestIdentifyCode:

    def test_action_type(self, identify_code):
        assert identify_code.action_type() == Identify

    def test_system_prompt(self, identify_code):
        assert isinstance(identify_code.system_prompt(), str)
        assert "You are an autonomous AI assistant" in identify_code.system_prompt()

    def test_execute_action_with_identified_spans(self, identify_code):
        action = Identify(
            scratch_pad="Test scratch pad",
            identified_spans=[
                FileWithSpans(file_path="test.py", span_ids=["span1", "span2"])
            ]
        )

        response = identify_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"

        # Verify that the file was added to the file context
        assert "test.py" in identify_code.file_context._file_context
        context_file = identify_code.file_context._file_context["test.py"]
        assert context_file.file_path == "test.py"
        assert set(context_file.span_ids) == {"span1", "span2"}
--------------------------------------------------------------------------------
Chunk ID: find/test_identify.py::3
Filepath: tests\find\test_identify.py
Content:
class TestIdentifyCode:

    def test_execute_action_without_identified_spans(self, identify_code):
        identify_code.ranked_spans = [RankedFileSpan(file_path="test.py", span_id="span1", rank=1)]
        action = Identify(scratch_pad="No relevant spans found")

        response = identify_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "search"
        assert "The search returned 1 results" in response.output["message"]

    def test_messages(self, identify_code):
        messages = identify_code.messages()

        assert len(messages) == 1
        assert "<issue>" in messages[0].content
        assert "Test initial message" in messages[0].content
        assert "<file_context>" in messages[0].content
        assert "<search_results>" in messages[0].content

    def test_initial_message(self, identify_code):
        assert identify_code.initial_message == "Test initial message"

    def test_workspace_initialization(self, identify_code):
        assert identify_code._workspace is not None
        assert isinstance(identify_code._workspace, Workspace)

def test_is_test_pattern():
    assert is_test_pattern("test_file.py") == True
    assert is_test_pattern("file_test.py") == False
    assert is_test_pattern("/tests/some_file.py") == True
    assert is_test_pattern("src/main.py") == False
    assert is_test_pattern("test_utils/helper.py") == True
--------------------------------------------------------------------------------
Chunk ID: find/test_search.py::1
Filepath: tests\find\test_search.py
Content:
import pytest
from moatless.find.search import SearchCode, Search, SearchRequest
from moatless.types import ActionResponse
from moatless.workspace import Workspace
from unittest.mock import Mock, MagicMock
from pydantic import ValidationError

class TestSearchCode:
    @pytest.fixture
    def search_code(self):
        mock_file_repo = Mock()
        mock_workspace = Workspace(file_repo=mock_file_repo)
        mock_code_index = MagicMock()
        mock_workspace.code_index = mock_code_index

        return SearchCode(id=1, _workspace=mock_workspace, _initial_message="Test initial message")

    def test_action_type(self, search_code):
        assert search_code.action_type() == Search

    def test_execute_action_complete(self, search_code):
        action = Search(
            scratch_pad="Search complete",
            search_requests=[],
            complete=True
        )

        response = search_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "finish"
        assert response.output["message"] == "Search complete"

    def test_validate_search_without_search_attributes(self):
        with pytest.raises(ValidationError) as excinfo:
            Search(
                scratch_pad="Invalid search",
                search_requests=[]
            )

        assert "At least one search request must exist." in str(excinfo.value)
--------------------------------------------------------------------------------
Chunk ID: find/test_search.py::2
Filepath: tests\find\test_search.py
Content:
class TestSearchCode:

    def test_execute_action_with_search_results(self, search_code):
        mock_code_index = MagicMock()
        mock_code_index.search.return_value.hits = [
            MagicMock(file_path="test.py", spans=[MagicMock(span_id="span1", rank=1, tokens=10)])
        ]
        search_code.workspace.code_index = mock_code_index

        action = Search(
            scratch_pad="Valid search",
            search_requests=[SearchRequest(query="test query")]
        )

        response = search_code._execute_action(action)

        assert isinstance(response, ActionResponse)
        assert response.trigger == "did_search"
        assert "ranked_spans" in response.output
        assert len(response.output["ranked_spans"]) == 1

    def test_messages(self, search_code):
        messages = search_code.messages()

        assert len(messages) == 1
        assert "<issue>" in messages[0].content
        assert "Test initial message" in messages[0].content
        assert "<file_context>" in messages[0].content
--------------------------------------------------------------------------------
